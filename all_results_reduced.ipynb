{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset_name         method trial best_epoch       train_loss  \\\n",
      "                                count        min   max       mean   \n",
      "0          actor            GAT    20         25    33   0.000390   \n",
      "1          actor        GAT-MAS    20         25    37   0.000406   \n",
      "2          actor        GAT-TAS    20         25    36   0.000404   \n",
      "3          actor            GCN    20         57    68   0.000372   \n",
      "4          actor        GCN-MAS    20         62    73   0.000390   \n",
      "5          actor        GCN-TAS    20         60    69   0.000391   \n",
      "6          actor      GraphSAGE    20         51    54   0.000294   \n",
      "7          actor  GraphSAGE-MAS    20         54    57   0.000294   \n",
      "8          actor  GraphSAGE-TAS    20         53    56   0.000294   \n",
      "9      chameleon            GAT    20         31    49   0.000733   \n",
      "10     chameleon        GAT-MAS    20         37    58   0.000789   \n",
      "11     chameleon        GAT-TAS    20         38    62   0.000775   \n",
      "12     chameleon            GCN    20         66    91   0.000723   \n",
      "13     chameleon        GCN-MAS    20         89   128   0.000696   \n",
      "14     chameleon        GCN-TAS    20         83   150   0.000697   \n",
      "15     chameleon      GraphSAGE    20         51    57   0.000255   \n",
      "16     chameleon  GraphSAGE-MAS    20         52    57   0.000308   \n",
      "17     chameleon  GraphSAGE-TAS    20         52    57   0.000314   \n",
      "18      citeseer            GAT    20         66    73   0.000270   \n",
      "19      citeseer        GAT-MAS    20         67    73   0.000371   \n",
      "20      citeseer        GAT-TAS    20         62    72   0.000317   \n",
      "21      citeseer            GCN    20        109   117   0.000229   \n",
      "22      citeseer        GCN-MAS    20        110   118   0.000318   \n",
      "23      citeseer        GCN-TAS    20        109   118   0.000273   \n",
      "24      citeseer      GraphSAGE    20         87    96   0.000188   \n",
      "25      citeseer  GraphSAGE-MAS    20         88    98   0.000223   \n",
      "26      citeseer  GraphSAGE-TAS    20         90   100   0.000200   \n",
      "27     community            GAT    20        102   182   0.000923   \n",
      "28     community        GAT-MAS    20         63   158   0.001523   \n",
      "29     community        GAT-TAS    20         74   193   0.001234   \n",
      "30     community            GCN    20        167   229   0.001046   \n",
      "31     community        GCN-MAS    20        153   204   0.001439   \n",
      "32     community        GCN-TAS    20        149   209   0.001435   \n",
      "33     community      GraphSAGE    20         99   144   0.000736   \n",
      "34     community  GraphSAGE-MAS    20         72   107   0.001209   \n",
      "35     community  GraphSAGE-TAS    20         59   108   0.001337   \n",
      "36      computer            GCN    20        134   266   0.000038   \n",
      "37      computer        GCN-MAS    20        124   252   0.000047   \n",
      "38      computer        GCN-TAS    20        143   240   0.000045   \n",
      "39      computer      GraphSAGE    20         90   151   0.000022   \n",
      "40      computer  GraphSAGE-MAS    20         96   140   0.000025   \n",
      "41      computer  GraphSAGE-TAS    20         87   142   0.000024   \n",
      "42          cora            GAT    20         78   100   0.000152   \n",
      "43          cora        GAT-MAS    20         78   102   0.000266   \n",
      "44          cora        GAT-TAS    20         78   102   0.000190   \n",
      "45          cora            GCN    20        136   157   0.000126   \n",
      "46          cora        GCN-MAS    20        133   165   0.000206   \n",
      "47          cora        GCN-TAS    20        137   150   0.000165   \n",
      "48          cora      GraphSAGE    20         99   127   0.000071   \n",
      "49          cora  GraphSAGE-MAS    20        104   132   0.000093   \n",
      "50          cora  GraphSAGE-TAS    20         99   124   0.000078   \n",
      "51       cornell            GAT    20          3    15   0.010514   \n",
      "52       cornell        GAT-MAS    20          4    22   0.012299   \n",
      "53       cornell        GAT-TAS    20          4    17   0.013140   \n",
      "54       cornell            GCN    20          8    32   0.009611   \n",
      "55       cornell        GCN-MAS    20          7    34   0.011918   \n",
      "56       cornell        GCN-TAS    20          7    34   0.012152   \n",
      "57       cornell      GraphSAGE    20         21    39   0.002134   \n",
      "58       cornell  GraphSAGE-MAS    20         24    36   0.002704   \n",
      "59       cornell  GraphSAGE-TAS    20         23    63   0.001609   \n",
      "60         cycle            GAT    20         11   129   0.001565   \n",
      "61         cycle        GAT-MAS    20         11   104   0.001566   \n",
      "62         cycle        GAT-TAS    20         10   116   0.001564   \n",
      "63         cycle            GCN    20         20   649   0.001528   \n",
      "64         cycle        GCN-MAS    20         30   466   0.001551   \n",
      "65         cycle        GCN-TAS    20         26   107   0.001563   \n",
      "66         cycle      GraphSAGE    20          5   115   0.001578   \n",
      "67         cycle  GraphSAGE-MAS    20          5   104   0.001577   \n",
      "68         cycle  GraphSAGE-TAS    20          5   115   0.001575   \n",
      "69          grid            GAT    20         10   196   0.001103   \n",
      "70          grid        GAT-MAS    20          7    71   0.001102   \n",
      "71          grid        GAT-TAS    20          7    74   0.001102   \n",
      "72          grid            GCN    20          8   710   0.001080   \n",
      "73          grid        GCN-MAS    20          9    88   0.001102   \n",
      "74          grid        GCN-TAS    20          8   103   0.001102   \n",
      "75          grid      GraphSAGE    20          9   111   0.001110   \n",
      "76          grid  GraphSAGE-MAS    20          8   114   0.001111   \n",
      "77          grid  GraphSAGE-TAS    20          9   119   0.001109   \n",
      "78         photo            GAT    20         72   116   0.000030   \n",
      "79         photo        GAT-MAS    20         78   111   0.000045   \n",
      "80         photo        GAT-TAS    20         87   131   0.000039   \n",
      "81         photo            GCN    20        108   228   0.000039   \n",
      "82         photo        GCN-MAS    20        116   179   0.000059   \n",
      "83         photo        GCN-TAS    20        118   244   0.000052   \n",
      "84         photo      GraphSAGE    20         88   129   0.000010   \n",
      "85         photo  GraphSAGE-MAS    20         89   129   0.000014   \n",
      "86         photo  GraphSAGE-TAS    20         86   108   0.000013   \n",
      "87        pubmed            GAT    20        111   194   0.000031   \n",
      "88        pubmed        GAT-MAS    20        129   157   0.000040   \n",
      "89        pubmed        GAT-TAS    20        111   154   0.000037   \n",
      "90        pubmed            GCN    20        208   275   0.000029   \n",
      "91        pubmed        GCN-MAS    20        203   239   0.000039   \n",
      "92        pubmed        GCN-TAS    20        185   229   0.000036   \n",
      "93        pubmed      GraphSAGE    20        146   180   0.000023   \n",
      "94        pubmed  GraphSAGE-MAS    20        161   190   0.000024   \n",
      "95        pubmed  GraphSAGE-TAS    20        161   190   0.000023   \n",
      "96         shape            GAT    20         23   128   0.003677   \n",
      "97         shape        GAT-MAS    20         17   150   0.003670   \n",
      "98         shape        GAT-TAS    20         16   143   0.003678   \n",
      "99         shape            GCN    20         36  1006   0.001128   \n",
      "100        shape        GCN-MAS    20         41   937   0.002808   \n",
      "101        shape        GCN-TAS    20         38   893   0.002397   \n",
      "102        shape      GraphSAGE    20         10   110   0.003704   \n",
      "103        shape  GraphSAGE-MAS    20         10   121   0.003702   \n",
      "104        shape  GraphSAGE-TAS    20         10   173   0.003695   \n",
      "105     squirrel        GAT-MAS    20         23    63   0.000519   \n",
      "106     squirrel            GCN    20         57    72   0.000480   \n",
      "107     squirrel        GCN-MAS    20         67   293   0.000458   \n",
      "108     squirrel        GCN-TAS    20         85   228   0.000440   \n",
      "109     squirrel      GraphSAGE    20         42    47   0.000315   \n",
      "110     squirrel  GraphSAGE-MAS    20         41    46   0.000357   \n",
      "111     squirrel  GraphSAGE-TAS    20         41    46   0.000358   \n",
      "112        texas            GAT    20          6    18   0.010210   \n",
      "113        texas        GAT-MAS    20          5    20   0.010980   \n",
      "114        texas        GAT-TAS    20          6    18   0.010645   \n",
      "115        texas            GCN    20         10    31   0.008787   \n",
      "116        texas        GCN-MAS    20         13    35   0.010882   \n",
      "117        texas        GCN-TAS    20         15    31   0.009182   \n",
      "118        texas      GraphSAGE    20         24    50   0.000607   \n",
      "119        texas  GraphSAGE-MAS    20         32    62   0.000640   \n",
      "120        texas  GraphSAGE-TAS    20         26    81   0.000546   \n",
      "121         wiki            GCN    20        231   348   0.000076   \n",
      "122         wiki        GCN-MAS    20        231   393   0.000101   \n",
      "123         wiki        GCN-TAS    20        252   420   0.000091   \n",
      "124         wiki      GraphSAGE    20        157   180   0.000053   \n",
      "125         wiki  GraphSAGE-MAS    20        152   186   0.000058   \n",
      "126         wiki  GraphSAGE-TAS    20        152   187   0.000055   \n",
      "127    wisconsin            GAT    20          4    21   0.008134   \n",
      "128    wisconsin        GAT-MAS    20          5    25   0.007995   \n",
      "129    wisconsin        GAT-TAS    20          5    24   0.008624   \n",
      "130    wisconsin            GCN    20         18    40   0.006498   \n",
      "131    wisconsin        GCN-MAS    20         17    42   0.006534   \n",
      "132    wisconsin        GCN-TAS    20         15    35   0.007566   \n",
      "133    wisconsin      GraphSAGE    20         23    45   0.001222   \n",
      "134    wisconsin  GraphSAGE-MAS    20         28    45   0.000638   \n",
      "135    wisconsin  GraphSAGE-TAS    20         24    48   0.000949   \n",
      "\n",
      "                  train_accuracy           validation_loss  ...  \\\n",
      "              std           mean       std            mean  ...   \n",
      "0    3.839636e-06       0.374000  0.010952        0.000815  ...   \n",
      "1    3.113478e-06       0.311487  0.022323        0.000824  ...   \n",
      "2    2.532742e-06       0.324645  0.016689        0.000822  ...   \n",
      "3    5.101311e-06       0.429474  0.011059        0.000807  ...   \n",
      "4    2.056465e-06       0.371079  0.007248        0.000820  ...   \n",
      "5    3.517813e-06       0.377000  0.010221        0.000819  ...   \n",
      "6    3.778187e-06       0.618092  0.006192        0.000752  ...   \n",
      "7    3.809835e-06       0.593750  0.009234        0.000738  ...   \n",
      "8    4.398847e-06       0.594908  0.010595        0.000738  ...   \n",
      "9    6.230370e-05       0.680185  0.026744        0.002024  ...   \n",
      "10   6.147337e-05       0.637039  0.028722        0.002020  ...   \n",
      "11   6.139300e-05       0.653647  0.028662        0.002067  ...   \n",
      "12   6.114188e-05       0.707733  0.027809        0.002095  ...   \n",
      "13   4.446430e-05       0.698638  0.019946        0.001981  ...   \n",
      "14   6.933772e-05       0.714455  0.025751        0.002022  ...   \n",
      "15   3.032898e-05       0.956459  0.008836        0.001750  ...   \n",
      "16   2.863411e-05       0.933392  0.009121        0.001803  ...   \n",
      "17   2.299246e-05       0.927900  0.009254        0.001842  ...   \n",
      "18   1.756341e-05       0.862237  0.008058        0.000919  ...   \n",
      "19   1.635117e-05       0.798076  0.008372        0.001081  ...   \n",
      "20   2.452955e-05       0.830607  0.009827        0.001009  ...   \n",
      "21   9.598185e-06       0.882231  0.004929        0.000893  ...   \n",
      "22   1.257627e-05       0.822099  0.007248        0.001022  ...   \n",
      "23   1.317442e-05       0.856885  0.006438        0.000960  ...   \n",
      "24   1.683738e-05       0.910884  0.008997        0.000880  ...   \n",
      "25   2.624849e-05       0.891612  0.017786        0.000996  ...   \n",
      "26   2.073735e-05       0.907517  0.012628        0.000929  ...   \n",
      "27   7.713589e-05       0.728143  0.021686        0.002772  ...   \n",
      "28   1.173969e-04       0.595571  0.026766        0.003827  ...   \n",
      "29   1.035440e-04       0.643429  0.024597        0.003338  ...   \n",
      "30   5.795349e-05       0.729500  0.016565        0.003108  ...   \n",
      "31   5.532777e-05       0.620571  0.016759        0.003719  ...   \n",
      "32   7.434782e-05       0.606714  0.022811        0.003702  ...   \n",
      "33   1.738027e-04       0.883571  0.047990        0.003622  ...   \n",
      "34   1.086841e-04       0.704571  0.038625        0.003486  ...   \n",
      "35   1.545493e-04       0.662214  0.065824        0.003805  ...   \n",
      "36   2.928424e-06       0.924520  0.005664        0.000099  ...   \n",
      "37   2.396868e-06       0.896815  0.005630        0.000109  ...   \n",
      "38   2.265733e-06       0.903672  0.005081        0.000104  ...   \n",
      "39   4.881071e-06       0.956494  0.010920        0.000089  ...   \n",
      "40   3.459957e-06       0.948109  0.008073        0.000091  ...   \n",
      "41   3.894496e-06       0.950327  0.009559        0.000090  ...   \n",
      "42   2.589317e-05       0.941100  0.009659        0.000622  ...   \n",
      "43   3.398781e-05       0.880761  0.012909        0.000821  ...   \n",
      "44   2.402421e-05       0.918833  0.009777        0.000701  ...   \n",
      "45   1.164836e-05       0.955207  0.005202        0.000575  ...   \n",
      "46   1.764950e-05       0.907533  0.008299        0.000731  ...   \n",
      "47   1.222693e-05       0.932422  0.005414        0.000635  ...   \n",
      "48   1.970493e-05       0.985340  0.007544        0.000566  ...   \n",
      "49   2.406520e-05       0.979616  0.010837        0.000692  ...   \n",
      "50   2.114325e-05       0.983900  0.009803        0.000605  ...   \n",
      "51   2.142000e-03       0.662637  0.081777        0.031007  ...   \n",
      "52   2.412095e-03       0.577473  0.092525        0.030910  ...   \n",
      "53   2.138058e-03       0.537912  0.091973        0.031376  ...   \n",
      "54   2.411629e-03       0.720330  0.107343        0.030192  ...   \n",
      "55   1.727851e-03       0.596154  0.071739        0.030147  ...   \n",
      "56   2.170276e-03       0.573626  0.091010        0.030869  ...   \n",
      "57   1.263544e-03       0.966484  0.028405        0.022175  ...   \n",
      "58   1.338676e-03       0.962637  0.022379        0.025031  ...   \n",
      "59   1.251887e-03       0.984615  0.019000        0.022377  ...   \n",
      "60   1.275695e-05       0.581379  0.014325        0.003094  ...   \n",
      "61   1.356652e-05       0.581379  0.014325        0.003097  ...   \n",
      "62   1.304683e-05       0.581379  0.014325        0.003095  ...   \n",
      "63   1.703104e-04       0.595517  0.066958        0.003036  ...   \n",
      "64   1.502065e-05       0.581264  0.014506        0.003086  ...   \n",
      "65   1.064309e-05       0.581379  0.014325        0.003111  ...   \n",
      "66   1.477218e-05       0.567586  0.019102        0.003059  ...   \n",
      "67   1.729390e-05       0.570920  0.023304        0.003067  ...   \n",
      "68   1.673441e-05       0.571264  0.020364        0.003064  ...   \n",
      "69   7.796272e-06       0.590325  0.009532        0.002203  ...   \n",
      "70   7.562845e-06       0.590000  0.009232        0.002204  ...   \n",
      "71   6.908700e-06       0.590000  0.009232        0.002205  ...   \n",
      "72   8.961956e-05       0.602602  0.057164        0.002173  ...   \n",
      "73   4.609914e-06       0.590000  0.009232        0.002212  ...   \n",
      "74   4.833741e-06       0.590000  0.009232        0.002213  ...   \n",
      "75   1.084475e-05       0.586829  0.012726        0.002188  ...   \n",
      "76   8.898780e-06       0.579268  0.011239        0.002192  ...   \n",
      "77   1.219412e-05       0.580976  0.011426        0.002191  ...   \n",
      "78   5.867977e-06       0.966810  0.006699        0.000102  ...   \n",
      "79   4.687649e-06       0.947203  0.005879        0.000131  ...   \n",
      "80   4.338467e-06       0.954118  0.004825        0.000120  ...   \n",
      "81   2.988983e-06       0.955830  0.003689        0.000111  ...   \n",
      "82   2.296375e-06       0.928471  0.003497        0.000140  ...   \n",
      "83   2.137160e-06       0.938144  0.002554        0.000128  ...   \n",
      "84   3.695416e-06       0.992418  0.004217        0.000088  ...   \n",
      "85   3.490135e-06       0.988105  0.004404        0.000093  ...   \n",
      "86   2.466986e-06       0.988379  0.002612        0.000092  ...   \n",
      "87   1.980775e-06       0.886189  0.007171        0.000078  ...   \n",
      "88   9.454506e-07       0.848453  0.004633        0.000088  ...   \n",
      "89   1.075085e-06       0.859480  0.004171        0.000084  ...   \n",
      "90   8.128265e-07       0.897063  0.003591        0.000072  ...   \n",
      "91   5.085246e-07       0.850005  0.002445        0.000086  ...   \n",
      "92   5.518015e-07       0.862102  0.002733        0.000082  ...   \n",
      "93   9.267552e-07       0.917965  0.003540        0.000069  ...   \n",
      "94   8.166620e-07       0.914612  0.003554        0.000068  ...   \n",
      "95   9.231803e-07       0.917706  0.003571        0.000067  ...   \n",
      "96   6.348738e-05       0.431857  0.017374        0.007333  ...   \n",
      "97   5.047393e-05       0.431857  0.017374        0.007347  ...   \n",
      "98   5.237366e-05       0.431857  0.017374        0.007349  ...   \n",
      "99   5.943337e-04       0.888571  0.099972        0.002193  ...   \n",
      "100  1.910601e-04       0.568143  0.031927        0.005721  ...   \n",
      "101  5.404766e-04       0.601857  0.069284        0.004776  ...   \n",
      "102  6.057487e-05       0.431143  0.018020        0.007313  ...   \n",
      "103  4.410345e-05       0.429286  0.016449        0.007321  ...   \n",
      "104  5.380637e-05       0.430286  0.016200        0.007318  ...   \n",
      "105  3.118857e-05       0.413827  0.038805        0.001162  ...   \n",
      "106  1.367680e-05       0.504250  0.019420        0.001118  ...   \n",
      "107  3.875770e-05       0.518865  0.056392        0.001128  ...   \n",
      "108  2.370048e-05       0.551808  0.031765        0.001116  ...   \n",
      "109  1.157094e-05       0.769423  0.010046        0.001010  ...   \n",
      "110  1.396373e-05       0.718404  0.011719        0.001035  ...   \n",
      "111  1.407797e-05       0.721808  0.011459        0.001046  ...   \n",
      "112  2.370936e-03       0.671978  0.105480        0.026227  ...   \n",
      "113  1.788341e-03       0.623077  0.066328        0.026407  ...   \n",
      "114  1.504106e-03       0.640110  0.076374        0.025985  ...   \n",
      "115  1.819064e-03       0.760440  0.081660        0.027645  ...   \n",
      "116  1.053891e-03       0.615934  0.039778        0.027214  ...   \n",
      "117  1.104122e-03       0.708242  0.060660        0.026137  ...   \n",
      "118  7.405295e-04       0.992857  0.013934        0.013481  ...   \n",
      "119  3.452450e-04       0.994505  0.007563        0.017019  ...   \n",
      "120  7.060026e-04       0.996154  0.008931        0.015395  ...   \n",
      "121  3.808925e-06       0.864829  0.005950        0.000197  ...   \n",
      "122  2.752415e-06       0.811718  0.005324        0.000233  ...   \n",
      "123  3.253979e-06       0.832179  0.006467        0.000218  ...   \n",
      "124  2.783576e-06       0.899197  0.005814        0.000167  ...   \n",
      "125  3.542252e-06       0.889214  0.007686        0.000177  ...   \n",
      "126  3.200233e-06       0.896077  0.007328        0.000172  ...   \n",
      "127  1.620164e-03       0.613200  0.089246        0.020077  ...   \n",
      "128  1.644545e-03       0.605200  0.089283        0.020063  ...   \n",
      "129  1.493445e-03       0.573200  0.076789        0.019936  ...   \n",
      "130  1.122864e-03       0.724400  0.056953        0.020051  ...   \n",
      "131  1.275577e-03       0.710400  0.058073        0.019554  ...   \n",
      "132  1.050579e-03       0.643200  0.042838        0.019683  ...   \n",
      "133  6.060917e-04       0.970800  0.019122        0.011999  ...   \n",
      "134  3.674933e-04       0.989600  0.008647        0.011131  ...   \n",
      "135  6.869115e-04       0.975200  0.023632        0.011115  ...   \n",
      "\n",
      "    validation_accuracy           test_loss           test_accuracy            \\\n",
      "                   mean       std      mean       std          mean       std   \n",
      "0              0.287132  0.008266  0.000814  0.000004      0.288500  0.009540   \n",
      "1              0.268026  0.009999  0.000824  0.000003      0.270789  0.010662   \n",
      "2              0.269763  0.008630  0.000823  0.000003      0.274763  0.010534   \n",
      "3              0.300368  0.007351  0.000808  0.000004      0.295921  0.009130   \n",
      "4              0.280211  0.010690  0.000820  0.000004      0.282737  0.008763   \n",
      "5              0.279316  0.007769  0.000819  0.000003      0.283079  0.007237   \n",
      "6              0.345632  0.007351  0.000752  0.000006      0.345684  0.010341   \n",
      "7              0.353421  0.008272  0.000739  0.000007      0.352816  0.011951   \n",
      "8              0.352474  0.008223  0.000739  0.000006      0.352947  0.010790   \n",
      "9              0.576801  0.033572  0.002013  0.000100      0.586316  0.025712   \n",
      "10             0.553515  0.031770  0.002044  0.000090      0.551140  0.029380   \n",
      "11             0.554833  0.026440  0.002064  0.000078      0.559825  0.019634   \n",
      "12             0.563884  0.026194  0.002087  0.000088      0.572982  0.026730   \n",
      "13             0.593409  0.021960  0.001997  0.000084      0.591228  0.023736   \n",
      "14             0.599385  0.022826  0.002023  0.000092      0.599912  0.023131   \n",
      "15             0.639895  0.016574  0.001760  0.000053      0.643596  0.015950   \n",
      "16             0.601845  0.018890  0.001800  0.000063      0.608070  0.018262   \n",
      "17             0.595343  0.020879  0.001824  0.000060      0.599474  0.020891   \n",
      "18             0.751023  0.012475  0.000880  0.000042      0.757743  0.013696   \n",
      "19             0.692298  0.012634  0.001064  0.000047      0.696939  0.016518   \n",
      "20             0.721480  0.016019  0.000982  0.000036      0.721369  0.015329   \n",
      "21             0.755656  0.013617  0.000884  0.000043      0.756963  0.014148   \n",
      "22             0.705235  0.008277  0.001017  0.000044      0.708583  0.017496   \n",
      "23             0.731408  0.013988  0.000957  0.000039      0.732413  0.012823   \n",
      "24             0.756558  0.013361  0.000871  0.000042      0.758824  0.014374   \n",
      "25             0.717088  0.011874  0.000991  0.000044      0.723049  0.016387   \n",
      "26             0.742298  0.015263  0.000926  0.000041      0.740576  0.014599   \n",
      "27             0.588429  0.028564  0.002710  0.000159      0.589857  0.025680   \n",
      "28             0.497571  0.023693  0.003770  0.000211      0.497143  0.023304   \n",
      "29             0.522143  0.024188  0.003199  0.000136      0.526286  0.025227   \n",
      "30             0.563000  0.021926  0.003172  0.000137      0.556286  0.019202   \n",
      "31             0.497857  0.023704  0.003729  0.000163      0.503857  0.025408   \n",
      "32             0.474714  0.020546  0.003672  0.000133      0.476000  0.021748   \n",
      "33             0.519429  0.019325  0.003658  0.000153      0.520857  0.020584   \n",
      "34             0.525000  0.019017  0.003504  0.000121      0.519286  0.025384   \n",
      "35             0.440714  0.023722  0.003806  0.000100      0.446571  0.020813   \n",
      "36             0.903665  0.005053  0.000099  0.000007      0.902967  0.006632   \n",
      "37             0.883159  0.005682  0.000110  0.000006      0.882548  0.007435   \n",
      "38             0.889456  0.004988  0.000104  0.000007      0.889282  0.008347   \n",
      "39             0.904334  0.004356  0.000090  0.000006      0.903883  0.004998   \n",
      "40             0.901862  0.004360  0.000094  0.000007      0.898531  0.007564   \n",
      "41             0.903156  0.004216  0.000092  0.000005      0.901163  0.004477   \n",
      "42             0.865657  0.012520  0.000579  0.000039      0.873781  0.010205   \n",
      "43             0.815879  0.015766  0.000771  0.000037      0.825849  0.010051   \n",
      "44             0.843944  0.012951  0.000656  0.000037      0.853767  0.007486   \n",
      "45             0.874594  0.010618  0.000561  0.000029      0.879616  0.008349   \n",
      "46             0.828656  0.013212  0.000700  0.000034      0.835672  0.010476   \n",
      "47             0.856278  0.011982  0.000620  0.000035      0.862629  0.008863   \n",
      "48             0.875702  0.009516  0.000556  0.000035      0.880945  0.008868   \n",
      "49             0.839956  0.013506  0.000668  0.000040      0.847046  0.009920   \n",
      "50             0.861448  0.010593  0.000594  0.000037      0.865805  0.009975   \n",
      "51             0.453333  0.069679  0.031050  0.002866      0.441489  0.063970   \n",
      "52             0.436667  0.070374  0.032137  0.002744      0.417021  0.068476   \n",
      "53             0.395556  0.062688  0.032081  0.003142      0.424468  0.081232   \n",
      "54             0.455556  0.068208  0.029685  0.001915      0.451064  0.061974   \n",
      "55             0.445556  0.070078  0.029980  0.001494      0.442553  0.051473   \n",
      "56             0.427778  0.063215  0.030856  0.001667      0.412766  0.067424   \n",
      "57             0.647778  0.060440  0.022489  0.002369      0.644681  0.046870   \n",
      "58             0.573333  0.070125  0.023985  0.002710      0.596809  0.053682   \n",
      "59             0.617778  0.075135  0.022474  0.003097      0.636170  0.050680   \n",
      "60             0.591244  0.014733  0.003087  0.000048      0.592694  0.027261   \n",
      "61             0.591244  0.014733  0.003093  0.000050      0.592694  0.027261   \n",
      "62             0.591244  0.014733  0.003089  0.000048      0.592694  0.027261   \n",
      "63             0.606682  0.071333  0.003027  0.000324      0.607306  0.065871   \n",
      "64             0.591244  0.014733  0.003065  0.000052      0.592237  0.026916   \n",
      "65             0.591244  0.014733  0.003091  0.000045      0.592694  0.027261   \n",
      "66             0.598618  0.018366  0.003097  0.000041      0.592694  0.027261   \n",
      "67             0.599770  0.018510  0.003096  0.000041      0.592694  0.027261   \n",
      "68             0.601382  0.019807  0.003101  0.000038      0.592694  0.027261   \n",
      "69             0.579153  0.024136  0.002203  0.000021      0.581877  0.017620   \n",
      "70             0.577687  0.022648  0.002204  0.000020      0.581877  0.017620   \n",
      "71             0.577687  0.022648  0.002205  0.000025      0.581877  0.017620   \n",
      "72             0.589251  0.056209  0.002165  0.000146      0.593366  0.054460   \n",
      "73             0.577687  0.022648  0.002202  0.000018      0.581877  0.017620   \n",
      "74             0.577687  0.022648  0.002202  0.000017      0.581877  0.017620   \n",
      "75             0.595114  0.022070  0.002204  0.000023      0.581877  0.017620   \n",
      "76             0.584365  0.019034  0.002203  0.000021      0.581877  0.017620   \n",
      "77             0.588111  0.020856  0.002203  0.000023      0.581877  0.017620   \n",
      "78             0.944456  0.006443  0.000102  0.000010      0.944851  0.005204   \n",
      "79             0.925654  0.007695  0.000135  0.000013      0.925248  0.007093   \n",
      "80             0.932505  0.005790  0.000122  0.000010      0.933194  0.007465   \n",
      "81             0.942312  0.006471  0.000117  0.000012      0.938996  0.007412   \n",
      "82             0.919142  0.008195  0.000142  0.000014      0.917459  0.010932   \n",
      "83             0.925758  0.006582  0.000130  0.000013      0.924438  0.008325   \n",
      "84             0.953347  0.005675  0.000091  0.000010      0.953136  0.005956   \n",
      "85             0.949215  0.006281  0.000092  0.000008      0.951490  0.005619   \n",
      "86             0.950863  0.005964  0.000093  0.000007      0.951150  0.004473   \n",
      "87             0.859373  0.004235  0.000072  0.000002      0.868783  0.004548   \n",
      "88             0.833962  0.004393  0.000086  0.000002      0.835507  0.005182   \n",
      "89             0.842422  0.003863  0.000081  0.000002      0.845193  0.004144   \n",
      "90             0.870542  0.004205  0.000071  0.000002      0.871562  0.003505   \n",
      "91             0.837766  0.003615  0.000085  0.000002      0.837759  0.004204   \n",
      "92             0.846693  0.005388  0.000081  0.000002      0.846937  0.003823   \n",
      "93             0.872479  0.003955  0.000068  0.000002      0.873256  0.003386   \n",
      "94             0.872469  0.004763  0.000068  0.000002      0.874016  0.003628   \n",
      "95             0.875593  0.004889  0.000067  0.000002      0.875690  0.003586   \n",
      "96             0.419429  0.026114  0.007369  0.000187      0.431143  0.029749   \n",
      "97             0.419429  0.026114  0.007363  0.000182      0.431143  0.029749   \n",
      "98             0.419429  0.026114  0.007371  0.000197      0.431143  0.029749   \n",
      "99             0.895143  0.125937  0.002370  0.001276      0.894571  0.118660   \n",
      "100            0.542857  0.049191  0.005692  0.000448      0.546857  0.044730   \n",
      "101            0.586000  0.085251  0.004852  0.001161      0.589143  0.079307   \n",
      "102            0.423714  0.027012  0.007393  0.000209      0.431143  0.029749   \n",
      "103            0.420000  0.027902  0.007385  0.000200      0.431143  0.029749   \n",
      "104            0.420286  0.028268  0.007380  0.000193      0.431143  0.029749   \n",
      "105            0.345885  0.030124  0.001174  0.000014      0.342352  0.032012   \n",
      "106            0.393615  0.017980  0.001123  0.000017      0.391045  0.014258   \n",
      "107            0.415308  0.036695  0.001144  0.000021      0.404919  0.034156   \n",
      "108            0.433000  0.023031  0.001136  0.000024      0.423251  0.018289   \n",
      "109            0.451615  0.013104  0.001008  0.000015      0.454112  0.011946   \n",
      "110            0.421462  0.013307  0.001033  0.000014      0.428978  0.009944   \n",
      "111            0.414500  0.014407  0.001045  0.000013      0.419216  0.010128   \n",
      "112            0.563333  0.071474  0.027435  0.004646      0.567021  0.064489   \n",
      "113            0.543333  0.061801  0.026384  0.002763      0.564894  0.060367   \n",
      "114            0.560000  0.053760  0.025868  0.003055      0.570213  0.053737   \n",
      "115            0.534444  0.058340  0.027367  0.002715      0.545745  0.071163   \n",
      "116            0.544444  0.068208  0.026162  0.002723      0.569149  0.082512   \n",
      "117            0.564444  0.061347  0.025565  0.002591      0.570213  0.060416   \n",
      "118            0.786667  0.065049  0.014235  0.004009      0.797872  0.061935   \n",
      "119            0.707778  0.056896  0.016811  0.003833      0.728723  0.074308   \n",
      "120            0.738889  0.060698  0.017377  0.005175      0.725532  0.065087   \n",
      "121            0.836154  0.007323  0.000198  0.000010      0.838876  0.007266   \n",
      "122            0.795470  0.009388  0.000234  0.000009      0.797215  0.009480   \n",
      "123            0.813744  0.008588  0.000217  0.000008      0.813397  0.007437   \n",
      "124            0.844103  0.007157  0.000165  0.000007      0.845711  0.007840   \n",
      "125            0.835419  0.006392  0.000175  0.000006      0.837064  0.006975   \n",
      "126            0.838308  0.007224  0.000171  0.000007      0.840499  0.007651   \n",
      "127            0.511290  0.069836  0.020714  0.001967      0.494531  0.055365   \n",
      "128            0.509677  0.072585  0.020700  0.001844      0.485156  0.050050   \n",
      "129            0.520161  0.076886  0.020622  0.001766      0.520312  0.042140   \n",
      "130            0.525000  0.069121  0.020562  0.001929      0.514062  0.048066   \n",
      "131            0.536290  0.054602  0.019214  0.001411      0.544531  0.057191   \n",
      "132            0.515323  0.058148  0.019975  0.001624      0.510938  0.040269   \n",
      "133            0.745968  0.057533  0.012183  0.001604      0.728906  0.046261   \n",
      "134            0.769355  0.062160  0.011198  0.001997      0.753906  0.049638   \n",
      "135            0.766935  0.075011  0.011837  0.001535      0.753125  0.043194   \n",
      "\n",
      "    training_runtime             total_runtime              \n",
      "                mean         std          mean         std  \n",
      "0           3.847020    0.707551      5.375707    0.764066  \n",
      "1           7.861172    2.985837     16.713725   12.917703  \n",
      "2           6.264781    2.327723     11.766787    2.761105  \n",
      "3           1.221547    0.089219      2.280879    0.129560  \n",
      "4           3.801526    2.298535      9.325710    2.730935  \n",
      "5           4.510583    7.305115     10.263451    7.508621  \n",
      "6           2.709603    1.473316      4.008834    1.649379  \n",
      "7           2.070527    0.758135      8.527134    1.105103  \n",
      "8           1.810783    0.454594      7.319949    0.842012  \n",
      "9           4.854377    0.617442      7.580739    0.668836  \n",
      "10          4.775568    0.449750      6.847189    0.474365  \n",
      "11          6.063409    1.524249      8.413365    1.696296  \n",
      "12          3.221453    2.220789      4.979969    2.337531  \n",
      "13          2.445234    0.864498      4.922654    0.927193  \n",
      "14          7.255613   10.197998      9.670784   10.015368  \n",
      "15          3.991584    7.922995      5.932504    7.863767  \n",
      "16          2.375148    1.006227      4.805587    1.079656  \n",
      "17          3.037005    4.657036      5.821968    4.924718  \n",
      "18         11.569640    0.804152     12.164402    0.886413  \n",
      "19          9.904667    1.198903     11.579375    1.239046  \n",
      "20          9.121410    1.438413     10.735305    1.588121  \n",
      "21          8.394066    1.249588      8.779009    1.278281  \n",
      "22          4.359344    1.467987      5.936334    1.480838  \n",
      "23          8.413234   10.465346     10.019503   10.375528  \n",
      "24          6.856557   10.883646      7.204585   10.921569  \n",
      "25          4.829382    1.549552      6.539301    1.587708  \n",
      "26          6.020870    7.337202      7.620960    7.413332  \n",
      "27          5.909436    2.896478      6.126320    2.921548  \n",
      "28          2.232758    1.012495      4.590672    8.930053  \n",
      "29          8.318454   14.421147      8.620020   14.409544  \n",
      "30          3.442015    1.686003      3.621020    1.696198  \n",
      "31          2.439834    1.067344      2.791240    1.078928  \n",
      "32         16.283737   21.999717     16.578431   21.972900  \n",
      "33          5.022316    1.807916      5.232608    1.796040  \n",
      "34          2.715233    1.925741      3.103378    1.921861  \n",
      "35         10.270060   19.224744     10.595963   19.227131  \n",
      "36         16.732649    3.553478     27.969338    3.312323  \n",
      "37          9.915987    2.819805     55.579086    8.298395  \n",
      "38         10.157955    2.951273     44.698626    5.699298  \n",
      "39          6.340597    2.589807     18.247323    7.883933  \n",
      "40          7.771956    3.222497     45.386889   17.193155  \n",
      "41          7.796526    2.516595     41.516582    4.077772  \n",
      "42          8.668059    2.968939      9.069888    2.970438  \n",
      "43          7.193553    2.075176      8.308861    2.073189  \n",
      "44          7.089954    4.145757      8.087920    4.127376  \n",
      "45          5.977429    2.366465      6.407101    2.405415  \n",
      "46          4.828228    8.342563      5.799101    8.303244  \n",
      "47         10.856774   17.432386     11.776220   17.398778  \n",
      "48          5.090550    1.908388      5.452700    1.969173  \n",
      "49          7.938712   16.715432      8.876203   16.725442  \n",
      "50          8.400301   12.697082      9.316819   12.674213  \n",
      "51          1.439063    1.191027      1.586367    1.230355  \n",
      "52          0.795949    0.795359      0.919110    0.838225  \n",
      "53          2.357565    6.984060      2.500861    6.979057  \n",
      "54          4.668524   13.608172      4.735727   13.604763  \n",
      "55          0.615330    0.415191      0.693296    0.418911  \n",
      "56          0.344249    0.120469      3.271121   12.753164  \n",
      "57          1.136376    0.543570      1.229227    0.547281  \n",
      "58          0.907387    0.506789      0.995255    0.550225  \n",
      "59          3.460833   10.617965      3.549168   10.617931  \n",
      "60          2.411454    2.518754      2.502156    2.561416  \n",
      "61          1.106156    1.267322      1.237573    1.311650  \n",
      "62          5.487900   14.590606      5.615800   14.596638  \n",
      "63          8.772891   20.136303      8.827331   20.131269  \n",
      "64          0.873470    1.169862      1.000645    1.176754  \n",
      "65          7.062369   15.035785      7.199680   15.037337  \n",
      "66          1.586592    1.495079      1.662793    1.533832  \n",
      "67          0.608730    0.422179      0.735907    0.453449  \n",
      "68          5.917637   14.790914      6.042857   14.777591  \n",
      "69          2.310982    2.452788      2.429029    2.476071  \n",
      "70          1.492876    1.532463      1.722548    1.528171  \n",
      "71          8.444258   17.274444      8.635772   17.280973  \n",
      "72          8.678659   20.266788      8.757432   20.273450  \n",
      "73          0.905849    0.688390      1.107968    0.721053  \n",
      "74          5.561905   15.839161      5.768167   15.829881  \n",
      "75          2.555238    1.895690      2.674197    1.927959  \n",
      "76          0.853253    0.425892      1.073637    0.466142  \n",
      "77          5.449667   15.270250      5.645458   15.248750  \n",
      "78         13.117397    1.660499     19.516875    1.784433  \n",
      "79         14.942521    1.018412     26.218074    2.060027  \n",
      "80         16.606501    1.036497     29.423515    2.969270  \n",
      "81         10.364268    4.403238     16.868399    5.248272  \n",
      "82          7.544536    2.691092     21.603073   11.282074  \n",
      "83          4.665858    1.810312     15.813893    2.196688  \n",
      "84          6.588265    2.443330     11.604688    2.444044  \n",
      "85          7.854514   10.993795     25.225601   27.539503  \n",
      "86          5.976130    5.824605     17.985031    6.634310  \n",
      "87         25.818484    8.109763     28.662144    8.181001  \n",
      "88         17.753246    2.247508     45.325773    3.489020  \n",
      "89         15.627066    1.713899     46.902329    8.228727  \n",
      "90         19.276262   28.839330     21.822332   28.765793  \n",
      "91          7.936918    2.447516     38.821690    9.743014  \n",
      "92          7.467137    1.652646     36.664285    6.739496  \n",
      "93          9.684165    2.873438     12.363377    2.891844  \n",
      "94          7.207840    2.273010     40.606942    8.088020  \n",
      "95          6.328619    1.457973     37.916257    7.533070  \n",
      "96          2.263090    2.094406      2.372700    2.116528  \n",
      "97          1.927186    1.430541      2.073028    1.450888  \n",
      "98          4.721594   11.922778      4.863734   11.907988  \n",
      "99         61.687027   23.703159     61.762237   23.680356  \n",
      "100         4.631844    4.663629      4.774168    4.667901  \n",
      "101        36.557631   28.893399     36.680900   28.908435  \n",
      "102         1.257598    0.889398      1.359362    0.906332  \n",
      "103         1.243434    1.319703      1.402811    1.327991  \n",
      "104         5.873786   14.798278      5.999632   14.790744  \n",
      "105        86.650326  338.245521     95.878244  338.181933  \n",
      "106         4.098880    2.313708     13.995114    2.829052  \n",
      "107         5.506972    2.181945     16.411236    6.721786  \n",
      "108         4.549867    1.211495     13.949275    1.159935  \n",
      "109         5.389757    3.375847     14.075187    3.754386  \n",
      "110         4.764686    5.574167     17.454889    8.693890  \n",
      "111         4.061371    4.549515     13.695752    4.938839  \n",
      "112         0.678073    0.232509      0.800029    0.242381  \n",
      "113         0.908035    0.637060      1.067787    0.652455  \n",
      "114         1.074159    1.736175      1.184961    1.741059  \n",
      "115         0.394579    0.117406      0.480526    0.137622  \n",
      "116         0.564383    0.244246      0.642367    0.274748  \n",
      "117         4.244648   11.718958      4.315959   11.714877  \n",
      "118         2.451406    1.278664      2.565252    1.293579  \n",
      "119         1.854298    0.811506      1.947870    0.836545  \n",
      "120         3.826965   10.159110      3.904601   10.161044  \n",
      "121        18.809511   14.818644     28.563912   14.611316  \n",
      "122        11.262038    2.256806     40.419620    8.897609  \n",
      "123        16.507136    5.641780     47.796531    9.589761  \n",
      "124         6.253996    2.862941     15.212757    3.569312  \n",
      "125         7.622452    2.636512     42.122615   13.470742  \n",
      "126         5.875554    1.883248     35.245046    8.265397  \n",
      "127         1.816086    0.947590      2.002149    0.986048  \n",
      "128         3.117524    7.495854      3.270556    7.499832  \n",
      "129         2.582216    6.559369      2.731897    6.563509  \n",
      "130         0.496211    0.301889      0.579127    0.321326  \n",
      "131         3.040606    7.496791      3.139183    7.499693  \n",
      "132         2.854540   10.459564      2.940820   10.456604  \n",
      "133         1.411177    0.903733      1.519104    0.901052  \n",
      "134         0.907128    0.318519      1.022262    0.333238  \n",
      "135         3.719091   11.748368      3.818592   11.744554  \n",
      "\n",
      "[136 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"results\"\n",
    "exp = 1\n",
    "\n",
    "datasets = ['actor','chameleon','citeseer','community','computer','cora','cornell','cycle','grid','photo','pubmed','shape','squirrel','texas','wiki','wisconsin']\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_gcn.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gcn_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gcn_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_sage.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_sage.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphSAGE\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_sage_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_sage_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphSAGE-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_sage_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_sage_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphSAGE-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        \n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results1_exp'+str(exp)+'.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset_name   method trial best_epoch      train_loss            \\\n",
      "                          count        min  max       mean       std   \n",
      "0          actor   CR-MAS    20          6   14   0.000748  0.000058   \n",
      "1          actor   CR-TAS    20         11   15   0.000698  0.000019   \n",
      "2          actor      NAG    20          4    9   0.000783  0.000020   \n",
      "3          actor  NAG-MAS    20          6    9   0.000729  0.000027   \n",
      "4          actor  NAG-TAS    20          6    9   0.000732  0.000027   \n",
      "5          actor      VCR    20          7   14   0.000714  0.000034   \n",
      "6          actor  VCR-MAS    20         10   19   0.000692  0.000029   \n",
      "7          actor  VCR-TAS    20          9   18   0.000672  0.000032   \n",
      "8      chameleon   CR-MAS    20         13   19   0.000838  0.000107   \n",
      "9      chameleon   CR-TAS    20         15   19   0.000846  0.000081   \n",
      "10     chameleon      NAG    20          8   12   0.000960  0.000080   \n",
      "11     chameleon  NAG-MAS    20         13   15   0.000702  0.000056   \n",
      "12     chameleon  NAG-TAS    20         13   15   0.000681  0.000054   \n",
      "13     chameleon      VCR    20          9   11   0.000990  0.000052   \n",
      "14     chameleon  VCR-MAS    20         12   17   0.000691  0.000067   \n",
      "15     chameleon  VCR-TAS    20         12   16   0.000677  0.000060   \n",
      "16      citeseer   CR-MAS    20          3    8   0.001041  0.000007   \n",
      "17      citeseer   CR-TAS    20          5    9   0.001034  0.000009   \n",
      "18      citeseer      NAG    20         14   16   0.000335  0.000025   \n",
      "19      citeseer  NAG-MAS    20         13   14   0.000385  0.000025   \n",
      "20      citeseer  NAG-TAS    20         13   15   0.000350  0.000029   \n",
      "21      citeseer      VCR    20         15   19   0.000240  0.000022   \n",
      "22      citeseer  VCR-MAS    20         11   14   0.000515  0.000023   \n",
      "23      citeseer  VCR-TAS    20         12   16   0.000463  0.000033   \n",
      "24     community   CR-MAS    20         24   43   0.001375  0.000138   \n",
      "25     community   CR-TAS    20         43  117   0.000565  0.000186   \n",
      "26     community      NAG    20         19   30   0.001356  0.000092   \n",
      "27     community  NAG-MAS    20         19   24   0.001570  0.000046   \n",
      "28     community  NAG-TAS    20         21   30   0.001764  0.000120   \n",
      "29     community      VCR    20         21   39   0.001527  0.000214   \n",
      "30     community  VCR-MAS    20         21   33   0.001309  0.000114   \n",
      "31     community  VCR-TAS    20         22   33   0.001427  0.000166   \n",
      "32      computer   CR-MAS    20         15   27   0.000139  0.000021   \n",
      "33      computer   CR-TAS    20         15   33   0.000150  0.000029   \n",
      "34      computer      NAG    20         15   49   0.000143  0.000019   \n",
      "35      computer  NAG-MAS    20         16   38   0.000143  0.000017   \n",
      "36      computer  NAG-TAS    20         14   75   0.000140  0.000020   \n",
      "37      computer      VCR    20         13   31   0.000128  0.000022   \n",
      "38      computer  VCR-MAS    20         13   24   0.000140  0.000030   \n",
      "39      computer  VCR-TAS    20         12   24   0.000145  0.000027   \n",
      "40          cora   CR-MAS    20          4   18   0.001334  0.000032   \n",
      "41          cora   CR-TAS    20          5   12   0.001339  0.000009   \n",
      "42          cora      NAG    20         18   20   0.000187  0.000024   \n",
      "43          cora  NAG-MAS    20         16   18   0.000211  0.000029   \n",
      "44          cora  NAG-TAS    20         16   19   0.000177  0.000032   \n",
      "45          cora      VCR    20         16   20   0.000205  0.000024   \n",
      "46          cora  VCR-MAS    20         15   19   0.000314  0.000034   \n",
      "47          cora  VCR-TAS    20         16   18   0.000291  0.000027   \n",
      "48       cornell   CR-MAS    20         12   18   0.007996  0.001270   \n",
      "49       cornell   CR-TAS    20         12   16   0.008230  0.001566   \n",
      "50       cornell      NAG    20         11   17   0.005969  0.002065   \n",
      "51       cornell  NAG-MAS    20         11   17   0.006508  0.002143   \n",
      "52       cornell  NAG-TAS    20          5   15   0.009367  0.002066   \n",
      "53       cornell      VCR    20         11   18   0.006686  0.001724   \n",
      "54       cornell  VCR-MAS    20         10   20   0.005944  0.002572   \n",
      "55       cornell  VCR-TAS    20         10   22   0.006912  0.002429   \n",
      "56         cycle   CR-MAS    20          2   59   0.001525  0.000019   \n",
      "57         cycle   CR-TAS    20         10   77   0.001498  0.000029   \n",
      "58         cycle      NAG    20         11  109   0.000302  0.000165   \n",
      "59         cycle  NAG-MAS    20          5   53   0.001529  0.000014   \n",
      "60         cycle  NAG-TAS    20         12  161   0.001521  0.000032   \n",
      "61         cycle      VCR    20         13   80   0.001471  0.000113   \n",
      "62         cycle  VCR-MAS    20         18   72   0.001561  0.000056   \n",
      "63         cycle  VCR-TAS    20          2  102   0.001562  0.000012   \n",
      "64          grid   CR-MAS    20         18   97   0.001086  0.000019   \n",
      "65          grid   CR-TAS    20         22   76   0.001083  0.000012   \n",
      "66          grid      NAG    20         28   58   0.000873  0.000087   \n",
      "67          grid  NAG-MAS    20          1  138   0.001102  0.000010   \n",
      "68          grid  NAG-TAS    20          1  120   0.001118  0.000058   \n",
      "69          grid      VCR    20          1  101   0.001083  0.000054   \n",
      "70          grid  VCR-MAS    20         21   77   0.001106  0.000058   \n",
      "71          grid  VCR-TAS    20         23   62   0.001092  0.000009   \n",
      "72         photo   CR-MAS    20         15   30   0.000079  0.000033   \n",
      "73         photo   CR-TAS    20         17   44   0.000066  0.000025   \n",
      "74         photo      NAG    20         15   38   0.000078  0.000023   \n",
      "75         photo  NAG-MAS    20         14   24   0.000085  0.000013   \n",
      "76         photo  NAG-TAS    20         14   27   0.000093  0.000033   \n",
      "77         photo      VCR    20         14   49   0.000075  0.000033   \n",
      "78         photo  VCR-MAS    20         15   30   0.000085  0.000026   \n",
      "79         photo  VCR-TAS    20         15   43   0.000089  0.000037   \n",
      "80        pubmed   CR-MAS    20         14   46   0.000138  0.000013   \n",
      "81        pubmed   CR-TAS    20         16   47   0.000125  0.000009   \n",
      "82        pubmed      NAG    20          6   10   0.000145  0.000013   \n",
      "83        pubmed  NAG-MAS    20          5   11   0.000133  0.000014   \n",
      "84        pubmed  NAG-TAS    20          5   10   0.000132  0.000016   \n",
      "85        pubmed      VCR    20         17   76   0.000126  0.000013   \n",
      "86        pubmed  VCR-MAS    20         17  178   0.000130  0.000014   \n",
      "87        pubmed  VCR-TAS    20         19  120   0.000131  0.000015   \n",
      "88         shape   CR-MAS    20         15   69   0.002893  0.000213   \n",
      "89         shape   CR-TAS    20         23   69   0.001804  0.000724   \n",
      "90         shape      NAG    20         19   87   0.002448  0.000180   \n",
      "91         shape  NAG-MAS    20         23   72   0.003277  0.000145   \n",
      "92         shape  NAG-TAS    20         14   36   0.003262  0.000148   \n",
      "93         shape      VCR    20         15  152   0.003127  0.000333   \n",
      "94         shape  VCR-MAS    20          4  165   0.003674  0.000055   \n",
      "95         shape  VCR-TAS    20         14   69   0.003520  0.000188   \n",
      "96      squirrel   CR-MAS    20          6   11   0.001029  0.000063   \n",
      "97      squirrel   CR-TAS    20          7   12   0.001047  0.000040   \n",
      "98      squirrel      NAG    20          4    6   0.001107  0.000034   \n",
      "99      squirrel  NAG-MAS    20          5    9   0.000981  0.000072   \n",
      "100     squirrel  NAG-TAS    20          5    9   0.000984  0.000069   \n",
      "101     squirrel      VCR    20          4   54   0.001034  0.000127   \n",
      "102     squirrel  VCR-MAS    20          5   13   0.000871  0.000129   \n",
      "103     squirrel  VCR-TAS    20          5   21   0.000872  0.000156   \n",
      "104        texas   CR-MAS    20         12   22   0.006081  0.002522   \n",
      "105        texas   CR-TAS    20         11   23   0.005812  0.002680   \n",
      "106        texas      NAG    20          7   16   0.006988  0.002402   \n",
      "107        texas  NAG-MAS    20         12   17   0.006363  0.001456   \n",
      "108        texas  NAG-TAS    20         11   21   0.007806  0.002270   \n",
      "109        texas      VCR    20         11   21   0.006587  0.002320   \n",
      "110        texas  VCR-MAS    20         10   22   0.006650  0.002602   \n",
      "111        texas  VCR-TAS    20         10   21   0.006479  0.003060   \n",
      "112         wiki   CR-MAS    20         18   68   0.000226  0.000030   \n",
      "113         wiki   CR-TAS    20         17   59   0.000243  0.000022   \n",
      "114         wiki      NAG    20         16   65   0.000225  0.000026   \n",
      "115         wiki  NAG-MAS    20         15   66   0.000245  0.000022   \n",
      "116         wiki  NAG-TAS    20         13   25   0.000233  0.000027   \n",
      "117         wiki      VCR    20         17   26   0.000223  0.000026   \n",
      "118         wiki  VCR-MAS    20         18   29   0.000232  0.000020   \n",
      "119         wiki  VCR-TAS    20         17   31   0.000226  0.000024   \n",
      "120    wisconsin   CR-MAS    20         14   29   0.003735  0.001361   \n",
      "121    wisconsin   CR-TAS    20         14   25   0.003501  0.001150   \n",
      "122    wisconsin      NAG    20          9   20   0.003841  0.002032   \n",
      "123    wisconsin  NAG-MAS    20         12   19   0.004159  0.001181   \n",
      "124    wisconsin  NAG-TAS    20         10   16   0.005633  0.001072   \n",
      "125    wisconsin      VCR    20         13   28   0.002928  0.001548   \n",
      "126    wisconsin  VCR-MAS    20         13   23   0.002886  0.001443   \n",
      "127    wisconsin  VCR-TAS    20         11   24   0.003245  0.001751   \n",
      "\n",
      "    train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "              mean       std            mean  ...                mean   \n",
      "0         0.387908  0.077148        0.000811  ...            0.304816   \n",
      "1         0.440605  0.019130        0.000765  ...            0.350105   \n",
      "2         0.351013  0.023813        0.000806  ...            0.300605   \n",
      "3         0.412342  0.030554        0.000779  ...            0.337026   \n",
      "4         0.408632  0.031383        0.000780  ...            0.334895   \n",
      "5         0.418724  0.037086        0.000782  ...            0.331263   \n",
      "6         0.444618  0.032892        0.000792  ...            0.317342   \n",
      "7         0.467171  0.032286        0.000798  ...            0.323237   \n",
      "8         0.632293  0.055941        0.002022  ...            0.547188   \n",
      "9         0.635062  0.055974        0.002112  ...            0.503691   \n",
      "10        0.644640  0.042848        0.002378  ...            0.428383   \n",
      "11        0.753998  0.021085        0.001880  ...            0.595431   \n",
      "12        0.760369  0.024553        0.001865  ...            0.589895   \n",
      "13        0.589192  0.036807        0.002314  ...            0.437786   \n",
      "14        0.728032  0.020074        0.001890  ...            0.601757   \n",
      "15        0.738708  0.019431        0.001863  ...            0.609490   \n",
      "16        0.238695  0.011506        0.002104  ...            0.211793   \n",
      "17        0.254209  0.015251        0.002099  ...            0.221600   \n",
      "18        0.839357  0.011341        0.000986  ...            0.740614   \n",
      "19        0.818671  0.012350        0.001107  ...            0.699819   \n",
      "20        0.840469  0.013916        0.001035  ...            0.724970   \n",
      "21        0.895640  0.008127        0.000693  ...            0.834537   \n",
      "22        0.730968  0.011463        0.001257  ...            0.656980   \n",
      "23        0.758719  0.012232        0.001171  ...            0.679422   \n",
      "24        0.592214  0.046034        0.003055  ...            0.545429   \n",
      "25        0.849786  0.063780        0.001586  ...            0.804857   \n",
      "26        0.586571  0.019688        0.003072  ...            0.520000   \n",
      "27        0.567429  0.014432        0.003633  ...            0.502571   \n",
      "28        0.458929  0.035964        0.003697  ...            0.426571   \n",
      "29        0.547071  0.076232        0.003590  ...            0.464714   \n",
      "30        0.624214  0.030079        0.003070  ...            0.561714   \n",
      "31        0.579357  0.043036        0.003265  ...            0.498571   \n",
      "32        0.924440  0.013224        0.000205  ...            0.893615   \n",
      "33        0.915532  0.016044        0.000209  ...            0.888104   \n",
      "34        0.916150  0.011453        0.000210  ...            0.885704   \n",
      "35        0.917714  0.010185        0.000220  ...            0.885239   \n",
      "36        0.919772  0.011018        0.000211  ...            0.889427   \n",
      "37        0.930032  0.012449        0.000204  ...            0.895099   \n",
      "38        0.926222  0.015731        0.000215  ...            0.894648   \n",
      "39        0.922978  0.014504        0.000206  ...            0.897106   \n",
      "40        0.304468  0.016959        0.002686  ...            0.302733   \n",
      "41        0.300111  0.006987        0.002692  ...            0.304948   \n",
      "42        0.939771  0.007632        0.000658  ...            0.866322   \n",
      "43        0.943796  0.009155        0.000820  ...            0.828139   \n",
      "44        0.957681  0.007813        0.000730  ...            0.852511   \n",
      "45        0.934158  0.005822        0.000652  ...            0.872304   \n",
      "46        0.887666  0.009524        0.000935  ...            0.803693   \n",
      "47        0.903250  0.008882        0.000849  ...            0.827696   \n",
      "48        0.816484  0.065751        0.026017  ...            0.536667   \n",
      "49        0.819231  0.076257        0.026535  ...            0.550000   \n",
      "50        0.880769  0.069343        0.024126  ...            0.618889   \n",
      "51        0.860989  0.070973        0.024318  ...            0.597778   \n",
      "52        0.756044  0.110674        0.027852  ...            0.464444   \n",
      "53        0.850549  0.056754        0.024988  ...            0.590000   \n",
      "54        0.887912  0.075430        0.023304  ...            0.616667   \n",
      "55        0.854396  0.060702        0.024768  ...            0.575556   \n",
      "56        0.582529  0.014316        0.003024  ...            0.588479   \n",
      "57        0.601379  0.025830        0.002916  ...            0.623502   \n",
      "58        0.956437  0.028746        0.000413  ...            0.970968   \n",
      "59        0.576897  0.021571        0.003025  ...            0.589862   \n",
      "60        0.596092  0.025239        0.002997  ...            0.608525   \n",
      "61        0.592184  0.071750        0.002773  ...            0.633410   \n",
      "62        0.581609  0.014347        0.003077  ...            0.596544   \n",
      "63        0.581379  0.014325        0.003113  ...            0.591475   \n",
      "64        0.607805  0.015770        0.002165  ...            0.609446   \n",
      "65        0.613821  0.022047        0.002164  ...            0.611889   \n",
      "66        0.743415  0.044507        0.001592  ...            0.791857   \n",
      "67        0.583659  0.033158        0.002208  ...            0.579316   \n",
      "68        0.568780  0.053169        0.002211  ...            0.576873   \n",
      "69        0.588537  0.054942        0.002143  ...            0.593648   \n",
      "70        0.580976  0.044211        0.002188  ...            0.591531   \n",
      "71        0.591626  0.010096        0.002187  ...            0.594300   \n",
      "72        0.956340  0.018557        0.000125  ...            0.937422   \n",
      "73        0.964510  0.014370        0.000117  ...            0.940167   \n",
      "74        0.956105  0.014860        0.000115  ...            0.942155   \n",
      "75        0.951922  0.008175        0.000126  ...            0.936559   \n",
      "76        0.947582  0.020743        0.000124  ...            0.939383   \n",
      "77        0.960510  0.017603        0.000116  ...            0.942390   \n",
      "78        0.952431  0.013953        0.000136  ...            0.932453   \n",
      "79        0.951582  0.020558        0.000129  ...            0.935696   \n",
      "80        0.899995  0.010170        0.000208  ...            0.873027   \n",
      "81        0.911082  0.006705        0.000211  ...            0.875188   \n",
      "82        0.894035  0.009625        0.000203  ...            0.876780   \n",
      "83        0.903779  0.010111        0.000201  ...            0.882065   \n",
      "84        0.904326  0.011220        0.000199  ...            0.880868   \n",
      "85        0.910590  0.011855        0.000203  ...            0.880067   \n",
      "86        0.907963  0.011457        0.000217  ...            0.871536   \n",
      "87        0.905366  0.013846        0.000212  ...            0.873869   \n",
      "88        0.520000  0.055387        0.005521  ...            0.544857   \n",
      "89        0.731571  0.141033        0.002525  ...            0.852000   \n",
      "90        0.590571  0.031750        0.004608  ...            0.604000   \n",
      "91        0.440286  0.036729        0.006247  ...            0.457429   \n",
      "92        0.458714  0.028109        0.006241  ...            0.489429   \n",
      "93        0.461714  0.059199        0.006058  ...            0.492571   \n",
      "94        0.432143  0.016963        0.007358  ...            0.419429   \n",
      "95        0.459857  0.053761        0.006810  ...            0.479143   \n",
      "96        0.433846  0.049633        0.001078  ...            0.396154   \n",
      "97        0.425654  0.034031        0.001109  ...            0.367462   \n",
      "98        0.422288  0.027702        0.001170  ...            0.325077   \n",
      "99        0.510577  0.034376        0.001101  ...            0.394346   \n",
      "100       0.505019  0.033301        0.001095  ...            0.402577   \n",
      "101       0.460673  0.072543        0.001185  ...            0.321500   \n",
      "102       0.565404  0.073714        0.001085  ...            0.434115   \n",
      "103       0.564808  0.077183        0.001082  ...            0.437808   \n",
      "104       0.833516  0.131544        0.022095  ...            0.627778   \n",
      "105       0.845604  0.135269        0.021379  ...            0.661111   \n",
      "106       0.808791  0.095494        0.023165  ...            0.610000   \n",
      "107       0.854945  0.059510        0.022016  ...            0.652222   \n",
      "108       0.803297  0.072971        0.022935  ...            0.615556   \n",
      "109       0.821429  0.103999        0.021452  ...            0.653333   \n",
      "110       0.815385  0.104653        0.022077  ...            0.633333   \n",
      "111       0.835714  0.113782        0.021213  ...            0.640000   \n",
      "112       0.856017  0.019331        0.000401  ...            0.818530   \n",
      "113       0.844402  0.014103        0.000392  ...            0.817761   \n",
      "114       0.856846  0.016549        0.000388  ...            0.822017   \n",
      "115       0.844538  0.014845        0.000409  ...            0.812838   \n",
      "116       0.850812  0.016607        0.000406  ...            0.813829   \n",
      "117       0.859496  0.015979        0.000376  ...            0.829060   \n",
      "118       0.854667  0.012441        0.000393  ...            0.823111   \n",
      "119       0.860077  0.016034        0.000381  ...            0.830239   \n",
      "120       0.890400  0.062298        0.014284  ...            0.686290   \n",
      "121       0.915200  0.041723        0.013596  ...            0.711290   \n",
      "122       0.872400  0.083481        0.014614  ...            0.676613   \n",
      "123       0.857600  0.052466        0.014079  ...            0.691935   \n",
      "124       0.784400  0.052265        0.016327  ...            0.603226   \n",
      "125       0.919200  0.065349        0.013653  ...            0.717742   \n",
      "126       0.915600  0.059271        0.012752  ...            0.741935   \n",
      "127       0.905200  0.075417        0.013952  ...            0.700000   \n",
      "\n",
      "              test_loss           test_accuracy           training_runtime  \\\n",
      "          std      mean       std          mean       std             mean   \n",
      "0    0.025724  0.000815  0.000012      0.303474  0.023365         7.160420   \n",
      "1    0.011058  0.000765  0.000012      0.346368  0.012077         7.527679   \n",
      "2    0.016890  0.000808  0.000007      0.305789  0.010428         4.197395   \n",
      "3    0.011952  0.000784  0.000007      0.330816  0.014090         4.530157   \n",
      "4    0.012911  0.000785  0.000006      0.328763  0.011358         4.428556   \n",
      "5    0.012047  0.000782  0.000011      0.328211  0.014180        16.397911   \n",
      "6    0.011527  0.000795  0.000015      0.315974  0.017295        15.683308   \n",
      "7    0.020364  0.000801  0.000015      0.324289  0.016971        18.288967   \n",
      "8    0.027097  0.002037  0.000057      0.548070  0.018924         2.934980   \n",
      "9    0.027597  0.002104  0.000063      0.504211  0.023018         2.903012   \n",
      "10   0.022426  0.002382  0.000044      0.424825  0.015445         1.889791   \n",
      "11   0.021940  0.001894  0.000060      0.595614  0.012747         1.887861   \n",
      "12   0.021990  0.001863  0.000062      0.592807  0.011870         1.780084   \n",
      "13   0.023818  0.002316  0.000047      0.432982  0.019291         3.959963   \n",
      "14   0.023992  0.001899  0.000087      0.600877  0.024840        11.107954   \n",
      "15   0.016224  0.001868  0.000085      0.605877  0.026675        10.530043   \n",
      "16   0.011248  0.002100  0.000013      0.204922  0.013705         3.122696   \n",
      "17   0.018180  0.002096  0.000010      0.212245  0.014046         3.175237   \n",
      "18   0.012569  0.000974  0.000050      0.746519  0.016740         2.615990   \n",
      "19   0.013266  0.001093  0.000048      0.708163  0.016625         2.734265   \n",
      "20   0.013938  0.001032  0.000046      0.726651  0.015931         2.723583   \n",
      "21   0.011156  0.001120  0.000065      0.719328  0.014514        16.026371   \n",
      "22   0.013494  0.001315  0.000057      0.634454  0.017714         9.320234   \n",
      "23   0.017203  0.001241  0.000050      0.660324  0.017184         9.954667   \n",
      "24   0.030827  0.003125  0.000145      0.540429  0.021725         2.252673   \n",
      "25   0.039209  0.001716  0.000217      0.786000  0.034979         2.909061   \n",
      "26   0.031230  0.003143  0.000137      0.505143  0.026522         1.759419   \n",
      "27   0.027230  0.003676  0.000126      0.496571  0.021473         1.805771   \n",
      "28   0.022461  0.003706  0.000110      0.429000  0.015155         1.832940   \n",
      "29   0.052177  0.003888  0.000347      0.434571  0.025721         4.627220   \n",
      "30   0.026405  0.003138  0.000135      0.541571  0.023895         5.000310   \n",
      "31   0.023751  0.003272  0.000104      0.493714  0.018437         4.900271   \n",
      "32   0.005983  0.000208  0.000018      0.894430  0.006867        23.545416   \n",
      "33   0.006733  0.000211  0.000014      0.887464  0.006062        24.395814   \n",
      "34   0.005165  0.000212  0.000019      0.884933  0.009291        10.544384   \n",
      "35   0.005848  0.000220  0.000015      0.884599  0.007819        11.896199   \n",
      "36   0.005001  0.000213  0.000015      0.888714  0.007432        11.850828   \n",
      "37   0.004279  0.000214  0.000017      0.892001  0.009495        26.731699   \n",
      "38   0.006119  0.000218  0.000015      0.893194  0.006854        33.015045   \n",
      "39   0.006157  0.000211  0.000018      0.895637  0.007145        21.666034   \n",
      "40   0.016493  0.002697  0.000025      0.296455  0.017293         5.234176   \n",
      "41   0.014236  0.002698  0.000022      0.302659  0.013930         4.459103   \n",
      "42   0.011822  0.000633  0.000030      0.869055  0.007551         2.995740   \n",
      "43   0.012545  0.000793  0.000037      0.836854  0.008659         2.348227   \n",
      "44   0.012230  0.000705  0.000031      0.860487  0.011305         2.399478   \n",
      "45   0.011802  0.000720  0.000051      0.859380  0.012299         5.145702   \n",
      "46   0.012283  0.000929  0.000038      0.807607  0.009154        10.370268   \n",
      "47   0.012444  0.000864  0.000051      0.825628  0.009626         7.773416   \n",
      "48   0.063379  0.025484  0.002417      0.540426  0.073833         1.335549   \n",
      "49   0.078939  0.025342  0.002181      0.557447  0.068545         1.397598   \n",
      "50   0.087199  0.024479  0.003919      0.585106  0.081532         2.900716   \n",
      "51   0.098038  0.024360  0.002737      0.564894  0.072556         1.053103   \n",
      "52   0.074544  0.026786  0.002100      0.448936  0.063605         0.984576   \n",
      "53   0.084535  0.025112  0.003733      0.552128  0.066022         1.026567   \n",
      "54   0.082165  0.027373  0.003592      0.510638  0.063267         2.216898   \n",
      "55   0.064446  0.028073  0.004932      0.488298  0.054124         1.476200   \n",
      "56   0.020506  0.003025  0.000065      0.591781  0.025548         1.416878   \n",
      "57   0.041840  0.002920  0.000061      0.613242  0.036683         2.098073   \n",
      "58   0.026329  0.000514  0.000147      0.963699  0.020976         8.015294   \n",
      "59   0.019779  0.003011  0.000047      0.579909  0.025272         1.831502   \n",
      "60   0.034951  0.002990  0.000071      0.598174  0.023424         1.932662   \n",
      "61   0.056667  0.002733  0.000234      0.642694  0.069248         2.891599   \n",
      "62   0.017013  0.003062  0.000051      0.592466  0.029364         1.786565   \n",
      "63   0.014284  0.003090  0.000049      0.592009  0.027288         2.417277   \n",
      "64   0.022316  0.002153  0.000030      0.617638  0.026568         2.054018   \n",
      "65   0.040024  0.002155  0.000030      0.607443  0.034555         4.031793   \n",
      "66   0.016093  0.001631  0.000106      0.785437  0.027483         2.263225   \n",
      "67   0.024059  0.002208  0.000026      0.582201  0.017186         1.530053   \n",
      "68   0.023723  0.002206  0.000022      0.579126  0.019935         1.484899   \n",
      "69   0.047508  0.002133  0.000109      0.601942  0.050421         4.290192   \n",
      "70   0.022279  0.002187  0.000030      0.585761  0.016232         2.430393   \n",
      "71   0.026473  0.002180  0.000026      0.592395  0.030075         3.058061   \n",
      "72   0.007509  0.000127  0.000014      0.937324  0.008852        12.960172   \n",
      "73   0.007036  0.000120  0.000015      0.939545  0.005173        11.703919   \n",
      "74   0.007048  0.000118  0.000014      0.940800  0.007013         5.811666   \n",
      "75   0.008529  0.000128  0.000015      0.934475  0.006867         6.030486   \n",
      "76   0.007263  0.000126  0.000013      0.936775  0.004840         5.861803   \n",
      "77   0.009285  0.000130  0.000039      0.935938  0.017240        15.244364   \n",
      "78   0.009361  0.000139  0.000016      0.929927  0.007995        17.857751   \n",
      "79   0.007869  0.000134  0.000016      0.933900  0.007114        16.899526   \n",
      "80   0.006215  0.000210  0.000008      0.873022  0.005428        27.583517   \n",
      "81   0.004724  0.000212  0.000011      0.875527  0.005344        23.546097   \n",
      "82   0.005071  0.000203  0.000008      0.876998  0.005687        11.911847   \n",
      "83   0.005730  0.000202  0.000007      0.880751  0.004132        12.119788   \n",
      "84   0.005226  0.000199  0.000008      0.881542  0.004012        12.265467   \n",
      "85   0.005445  0.000223  0.000011      0.867069  0.005529       250.992208   \n",
      "86   0.006396  0.000220  0.000011      0.871805  0.006297        75.378081   \n",
      "87   0.005575  0.000214  0.000007      0.873529  0.004200        57.152503   \n",
      "88   0.044506  0.005487  0.000398      0.543714  0.051086         1.429773   \n",
      "89   0.093085  0.002477  0.000676      0.859429  0.077853         1.670845   \n",
      "90   0.068924  0.004643  0.000281      0.608000  0.056611         1.504423   \n",
      "91   0.037470  0.006208  0.000288      0.457714  0.045333         1.796999   \n",
      "92   0.047567  0.006216  0.000382      0.485429  0.046441         1.561250   \n",
      "93   0.090514  0.006046  0.000853      0.486286  0.092045         2.676335   \n",
      "94   0.026114  0.007354  0.000201      0.431143  0.029749       208.538802   \n",
      "95   0.063097  0.006955  0.000302      0.472857  0.054868         1.444702   \n",
      "96   0.018872  0.001079  0.000021      0.389547  0.020048         6.123990   \n",
      "97   0.015115  0.001110  0.000020      0.360607  0.015889         5.464407   \n",
      "98   0.014626  0.001172  0.000011      0.319716  0.015293         3.120075   \n",
      "99   0.020872  0.001109  0.000020      0.391122  0.019786         4.034206   \n",
      "100  0.018904  0.001103  0.000017      0.397233  0.016215         4.010564   \n",
      "101  0.033353  0.001191  0.000017      0.315411  0.025516         8.323882   \n",
      "102  0.029214  0.001099  0.000026      0.427594  0.025766         9.697573   \n",
      "103  0.032603  0.001092  0.000024      0.431668  0.033047         9.260785   \n",
      "104  0.070963  0.021847  0.004201      0.636170  0.075272         1.044394   \n",
      "105  0.050404  0.020534  0.002732      0.654255  0.067943         1.055697   \n",
      "106  0.054659  0.023652  0.002719      0.590426  0.068293         0.945032   \n",
      "107  0.075712  0.021681  0.002480      0.621277  0.070600         1.391358   \n",
      "108  0.059059  0.022542  0.003939      0.615957  0.066022         1.328623   \n",
      "109  0.047497  0.021356  0.003342      0.654255  0.071697         6.293413   \n",
      "110  0.065882  0.023105  0.003598      0.624468  0.083202         1.339244   \n",
      "111  0.063102  0.022866  0.003892      0.617021  0.077793         1.000769   \n",
      "112  0.009644  0.000406  0.000019      0.814525  0.009461        15.055365   \n",
      "113  0.007419  0.000395  0.000023      0.817515  0.008447        14.363941   \n",
      "114  0.009180  0.000392  0.000019      0.824316  0.006743         8.814850   \n",
      "115  0.009066  0.000415  0.000018      0.813944  0.009208         9.184662   \n",
      "116  0.010241  0.000411  0.000019      0.812867  0.006689         9.233483   \n",
      "117  0.007330  0.000386  0.000018      0.827820  0.007942        18.035999   \n",
      "118  0.008008  0.000401  0.000021      0.819429  0.007621        24.238279   \n",
      "119  0.007766  0.000385  0.000016      0.828554  0.006962        23.326983   \n",
      "120  0.054502  0.014661  0.001677      0.657813  0.057778         1.104717   \n",
      "121  0.050165  0.014053  0.001852      0.703906  0.053283         1.071287   \n",
      "122  0.062462  0.016048  0.002000      0.627344  0.046813         1.148784   \n",
      "123  0.049892  0.014486  0.001221      0.677344  0.038029         1.150365   \n",
      "124  0.051909  0.016285  0.001741      0.582812  0.055324         1.101160   \n",
      "125  0.056239  0.013859  0.001974      0.707812  0.059141         1.271280   \n",
      "126  0.064728  0.015149  0.002017      0.671094  0.059655         1.748522   \n",
      "127  0.085090  0.015791  0.002855      0.658594  0.058304         1.154485   \n",
      "\n",
      "                total_runtime               \n",
      "            std          mean          std  \n",
      "0      0.441870     87.542709    62.972185  \n",
      "1      0.599664     97.099459    63.907045  \n",
      "2      0.226933      8.700799     0.525271  \n",
      "3      0.385651     13.892233     0.881823  \n",
      "4      0.451491     13.696755     0.747175  \n",
      "5      6.053409     74.537717    91.542256  \n",
      "6      3.685682    268.642147    34.607069  \n",
      "7      7.288104    276.635680    60.645119  \n",
      "8      0.432289     45.807589    10.337611  \n",
      "9      0.335114     46.355566     8.356324  \n",
      "10     0.362951      4.582189     0.447576  \n",
      "11     0.123507      6.003783     0.211938  \n",
      "12     0.121907      6.159890     0.204581  \n",
      "13     1.211518     65.695227    60.909203  \n",
      "14     3.546188     50.362048    32.818423  \n",
      "15     2.644493     59.358051    35.354594  \n",
      "16     0.243185    139.592910    61.291493  \n",
      "17     0.204770    133.289937    60.536424  \n",
      "18     0.118083      4.927008     0.234163  \n",
      "19     0.315686      5.771216     0.332250  \n",
      "20     0.316669      5.833860     0.378186  \n",
      "21     5.998230    185.317830   135.472712  \n",
      "22     4.330524    355.936081  1023.025458  \n",
      "23     5.641670    149.802319   143.213940  \n",
      "24     0.210564      3.108199     0.234967  \n",
      "25     0.627856      3.460634     0.619836  \n",
      "26     0.168545      2.520631     0.213088  \n",
      "27     0.172230      2.848766     0.244860  \n",
      "28     0.187475      2.808997     0.229504  \n",
      "29     2.472472      5.987481     2.911715  \n",
      "30     1.896324      7.248002     1.972249  \n",
      "31     1.682499      6.616097     1.746244  \n",
      "32     9.465782    223.546976   114.780065  \n",
      "33     7.510195    232.730867    85.270408  \n",
      "34     1.652094     23.888097     2.065854  \n",
      "35     1.191322     59.521506     2.693340  \n",
      "36     2.051539     59.662565     2.726205  \n",
      "37    10.560569    378.437820   663.519624  \n",
      "38    10.448748    431.104086   236.777809  \n",
      "39     4.076481    234.872505   247.013528  \n",
      "40     0.902236     47.688574    20.171720  \n",
      "41     1.028306     50.634851    18.630001  \n",
      "42     2.338994      4.305884     2.316568  \n",
      "43     0.210394      4.586132     0.353461  \n",
      "44     0.181062      4.449141     0.341903  \n",
      "45     0.861219     79.110614    52.806712  \n",
      "46     2.245187     80.129061    31.657555  \n",
      "47     2.347686     68.027120    50.046896  \n",
      "48     0.192041      5.885256     0.583692  \n",
      "49     0.292247      5.940403     1.040448  \n",
      "50     8.793594      3.476223     8.771191  \n",
      "51     0.176042      1.572395     0.214390  \n",
      "52     0.151098      1.565491     0.170320  \n",
      "53     0.437166      4.025782     3.098065  \n",
      "54     0.245904     15.459091    28.151426  \n",
      "55     0.146028      8.360906     1.101203  \n",
      "56     0.406274      1.869176     0.410619  \n",
      "57     0.417435      2.481826     0.437541  \n",
      "58    14.911440      8.556958    14.914957  \n",
      "59     0.575688      2.579820     0.486443  \n",
      "60     1.152449      2.556396     1.143792  \n",
      "61     1.063654      3.950201     1.257129  \n",
      "62     0.275063      2.500652     0.345959  \n",
      "63     0.914413      3.461051     0.930669  \n",
      "64     0.492884      2.715905     0.486546  \n",
      "65     0.812368      4.596449     0.820704  \n",
      "66     2.865983      2.889336     2.863122  \n",
      "67     0.720205      2.356894     0.735515  \n",
      "68     0.622797      2.314351     0.638628  \n",
      "69     1.883355      5.937459     3.516801  \n",
      "70     0.414374      3.674207     0.456257  \n",
      "71     0.432416      4.406038     0.463836  \n",
      "72     3.047053    125.686080    77.687616  \n",
      "73     2.378221    122.129416    75.546117  \n",
      "74     0.763989     11.509341     0.770681  \n",
      "75     0.484233     23.430980     1.266054  \n",
      "76     0.521814     23.156025     1.232635  \n",
      "77     6.600933    331.090349   893.852359  \n",
      "78     6.791812    119.643672   112.537099  \n",
      "79     7.555326    124.382539   114.964008  \n",
      "80    12.530874    616.612433  1257.758026  \n",
      "81     3.571591    316.111967   123.921907  \n",
      "82     1.792218     25.313507     2.154308  \n",
      "83     1.439090     58.948156     3.312083  \n",
      "84     1.271963     58.843292     3.121369  \n",
      "85   949.846823    440.556667   942.255041  \n",
      "86    32.449952    129.135906    33.065611  \n",
      "87    24.825530    723.566124   859.910909  \n",
      "88     0.246962      1.906202     0.301809  \n",
      "89     0.269448      2.129907     0.307513  \n",
      "90     0.308878      2.140024     0.315127  \n",
      "91     0.369586      2.599582     0.406113  \n",
      "92     0.235205      2.361083     0.269856  \n",
      "93     1.254547      3.303809     1.279152  \n",
      "94   913.209721    209.236868   913.172914  \n",
      "95     0.280398      1.935257     0.351354  \n",
      "96     1.210552     75.332398    34.847536  \n",
      "97     0.315640    118.897407    25.498634  \n",
      "98     0.467642     10.072440     0.552867  \n",
      "99     0.602945     18.534433     0.636036  \n",
      "100    0.624349     18.538950     0.620923  \n",
      "101    3.855850    145.000275   122.699453  \n",
      "102    3.157274    129.673484    64.640993  \n",
      "103    3.088022    226.247559    55.575569  \n",
      "104    0.122833      4.689652     0.405957  \n",
      "105    0.116694      5.473827     0.690819  \n",
      "106    0.123671      1.568362     0.158357  \n",
      "107    0.245578      1.975573     0.328552  \n",
      "108    0.206652      1.866037     0.263726  \n",
      "109   23.322195     11.153755    23.576345  \n",
      "110    0.574453      5.472199     1.442488  \n",
      "111    0.165284      9.017997     1.010458  \n",
      "112    2.386130     54.829836     2.637620  \n",
      "113    1.671970     52.969875     2.119350  \n",
      "114    1.433459     19.178412     2.458555  \n",
      "115    1.968834     44.677345     1.894321  \n",
      "116    0.816134     46.272921     1.234232  \n",
      "117    1.275132     82.665698   129.352777  \n",
      "118    3.811445     91.183563     9.766218  \n",
      "119    3.617078     94.938768     8.993650  \n",
      "120    0.116673      6.003601     0.435931  \n",
      "121    0.086941      6.377443     0.762432  \n",
      "122    0.198460      1.749691     0.236935  \n",
      "123    0.218880      1.785233     0.289840  \n",
      "124    0.249697      1.680980     0.268661  \n",
      "125    0.321194      5.139303     5.249160  \n",
      "126    0.562991      2.612963     1.262564  \n",
      "127    0.183991     12.916001     1.364824  \n",
      "\n",
      "[128 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"results_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = ['actor','chameleon','citeseer','community','computer','cora','cornell','cycle','grid','photo','pubmed','shape','squirrel','texas','wiki','wisconsin']\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_nag.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_vcr.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_vcr.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"VCR\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_vcr_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_vcr_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"VCR-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_vcr_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_vcr_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"VCR-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_cr_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_cr_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"CR-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_cr_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_cr_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"CR-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results2_exp'+str(exp)+'.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 378\u001b[0m\n\u001b[1;32m    376\u001b[0m cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m    377\u001b[0m split_text \u001b[38;5;241m=\u001b[39m cwd\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 378\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults3_exp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(exp)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    380\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_rows\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:2252\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2241\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2242\u001b[0m     df,\n\u001b[1;32m   2243\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2250\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[1;32m   2251\u001b[0m )\n\u001b[0;32m-> 2252\u001b[0m formatter\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m   2253\u001b[0m     excel_writer,\n\u001b[1;32m   2254\u001b[0m     sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[1;32m   2255\u001b[0m     startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[1;32m   2256\u001b[0m     startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[1;32m   2257\u001b[0m     freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[1;32m   2258\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m   2259\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   2260\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/excel.py:940\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[1;32m    937\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 940\u001b[0m     writer\u001b[38;5;241m.\u001b[39m_write_cells(\n\u001b[1;32m    941\u001b[0m         formatted_cells,\n\u001b[1;32m    942\u001b[0m         sheet_name,\n\u001b[1;32m    943\u001b[0m         startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[1;32m    944\u001b[0m         startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[1;32m    945\u001b[0m         freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_save:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:485\u001b[0m, in \u001b[0;36mOpenpyxlWriter._write_cells\u001b[0;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[1;32m    480\u001b[0m     freeze_panes \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m], freeze_panes)\n\u001b[1;32m    481\u001b[0m     wks\u001b[38;5;241m.\u001b[39mfreeze_panes \u001b[38;5;241m=\u001b[39m wks\u001b[38;5;241m.\u001b[39mcell(\n\u001b[1;32m    482\u001b[0m         row\u001b[38;5;241m=\u001b[39mfreeze_panes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, column\u001b[38;5;241m=\u001b[39mfreeze_panes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m cells:\n\u001b[1;32m    486\u001b[0m     xcell \u001b[38;5;241m=\u001b[39m wks\u001b[38;5;241m.\u001b[39mcell(\n\u001b[1;32m    487\u001b[0m         row\u001b[38;5;241m=\u001b[39mstartrow \u001b[38;5;241m+\u001b[39m cell\u001b[38;5;241m.\u001b[39mrow \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, column\u001b[38;5;241m=\u001b[39mstartcol \u001b[38;5;241m+\u001b[39m cell\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    488\u001b[0m     )\n\u001b[1;32m    489\u001b[0m     xcell\u001b[38;5;241m.\u001b[39mvalue, fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_with_fmt(cell\u001b[38;5;241m.\u001b[39mval)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/excel.py:883\u001b[0m, in \u001b[0;36mExcelFormatter.get_formatted_cells\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_formatted_cells\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[ExcelCell]:\n\u001b[0;32m--> 883\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_header(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_body()):\n\u001b[1;32m    884\u001b[0m         cell\u001b[38;5;241m.\u001b[39mval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_value(cell\u001b[38;5;241m.\u001b[39mval)\n\u001b[1;32m    885\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cell\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/excel.py:780\u001b[0m, in \u001b[0;36mExcelFormatter._format_regular_rows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     coloffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 780\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_body(coloffset)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/excel.py:871\u001b[0m, in \u001b[0;36mExcelFormatter._generate_body\u001b[0;34m(self, coloffset)\u001b[0m\n\u001b[1;32m    869\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[:, colidx]\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series):\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m CssExcelCell(\n\u001b[1;32m    872\u001b[0m         row\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcounter \u001b[38;5;241m+\u001b[39m i,\n\u001b[1;32m    873\u001b[0m         col\u001b[38;5;241m=\u001b[39mcolidx \u001b[38;5;241m+\u001b[39m coloffset,\n\u001b[1;32m    874\u001b[0m         val\u001b[38;5;241m=\u001b[39mval,\n\u001b[1;32m    875\u001b[0m         style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    876\u001b[0m         css_styles\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mctx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    877\u001b[0m         css_row\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    878\u001b[0m         css_col\u001b[38;5;241m=\u001b[39mcolidx,\n\u001b[1;32m    879\u001b[0m         css_converter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle_converter,\n\u001b[1;32m    880\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/excel.py:100\u001b[0m, in \u001b[0;36mCssExcelCell.__init__\u001b[0;34m(self, row, col, val, style, css_styles, css_row, css_col, css_converter, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     unique_declarations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(declaration_dict\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m     98\u001b[0m     style \u001b[38;5;241m=\u001b[39m css_converter(unique_declarations)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(row\u001b[38;5;241m=\u001b[39mrow, col\u001b[38;5;241m=\u001b[39mcol, val\u001b[38;5;241m=\u001b[39mval, style\u001b[38;5;241m=\u001b[39mstyle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder = \"results_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = ['actor','chameleon','citeseer','community','computer','cora','cornell','cycle','grid','photo','pubmed','shape','squirrel','texas','wiki','wisconsin']\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_san.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_san.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAN\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_san_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_san_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAN-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_san_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_san_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAN-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gt.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gt.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GT\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gt_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gt_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GT-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gt_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gt_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GT-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_graphormer.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_graphormer.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Graphormer\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_graphormer_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_graphormer_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Graphormer-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_graphormer_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_graphormer_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Graphormer-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gophormer.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gophormer.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Gophormer\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gophormer_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gophormer_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Gophormer-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gophormer_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gophormer_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Gophormer-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_exphormer.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_exphormer.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Exphormer\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_exphormer_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_exphormer_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Exphormer-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_exphormer_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_exphormer_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"Exphormer-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results3_exp'+str(exp)+'.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name   method trial best_epoch      train_loss                \\\n",
      "                         count        min  max       mean           std   \n",
      "0         actor  GAT-MAS    20         25   37   0.000406  3.113484e-06   \n",
      "1         actor  GAT-TAS    20         25   36   0.000404  2.532746e-06   \n",
      "2         actor  GCN-MAS    20         62   73   0.000391  2.248805e-06   \n",
      "3         actor  GCN-TAS    20         62   71   0.000380  3.951728e-06   \n",
      "4     chameleon  GAT-MAS    20         37   58   0.000789  6.148690e-05   \n",
      "5     chameleon  GAT-TAS    20         38   62   0.000775  6.139690e-05   \n",
      "6     chameleon  GCN-MAS    20         76  120   0.000797  4.695664e-05   \n",
      "7     chameleon  GCN-TAS    20         76  111   0.000722  7.555457e-05   \n",
      "8      citeseer  GAT-MAS    20         67   73   0.000371  1.635116e-05   \n",
      "9      citeseer  GAT-TAS    20         62   72   0.000317  2.452956e-05   \n",
      "10     citeseer  GCN-MAS    20        111  122   0.000275  1.506244e-05   \n",
      "11     citeseer  GCN-TAS    20        109  123   0.000208  1.462579e-05   \n",
      "12    community  GAT-MAS    20         63  158   0.001523  1.170527e-04   \n",
      "13    community  GAT-TAS    20         74  193   0.001234  1.040628e-04   \n",
      "14    community  GCN-MAS    20        167  203   0.001282  4.405045e-05   \n",
      "15    community  GCN-TAS    20        161  204   0.001253  6.091363e-05   \n",
      "16     computer  GCN-MAS    20        126  272   0.000048  2.841373e-06   \n",
      "17     computer  GCN-TAS    20        142  268   0.000041  1.847574e-06   \n",
      "18         cora  GAT-MAS    20         78  102   0.000266  3.399100e-05   \n",
      "19         cora  GAT-TAS    20         78  102   0.000190  2.402756e-05   \n",
      "20         cora  GCN-MAS    20        141  166   0.000202  1.713808e-05   \n",
      "21         cora  GCN-TAS    20        138  156   0.000151  1.335776e-05   \n",
      "22      cornell  GAT-MAS    20          4   22   0.012299  2.412095e-03   \n",
      "23      cornell  GAT-TAS    20          4   17   0.013140  2.138058e-03   \n",
      "24      cornell  GCN-MAS    20          6   39   0.012738  1.760820e-03   \n",
      "25      cornell  GCN-TAS    20          9   39   0.008646  1.845012e-03   \n",
      "26        cycle  GAT-MAS    20         11  104   0.001566  1.356653e-05   \n",
      "27        cycle  GAT-TAS    20         10  116   0.001564  1.304682e-05   \n",
      "28        cycle  GCN-MAS    20         30  494   0.001550  1.654323e-05   \n",
      "29        cycle  GCN-TAS    20         26  683   0.001543  6.779306e-05   \n",
      "30         grid  GAT-MAS    20          7   71   0.001102  7.562841e-06   \n",
      "31         grid  GAT-TAS    20          7   74   0.001102  6.908691e-06   \n",
      "32         grid  GCN-MAS    20          9  326   0.001099  5.290925e-06   \n",
      "33         grid  GCN-TAS    20          7   69   0.001102  5.509693e-06   \n",
      "34        photo  GAT-MAS    20         82  104   0.000045  3.448727e-06   \n",
      "35        photo  GAT-TAS    20         87  131   0.000040  4.556071e-06   \n",
      "36        photo  GCN-MAS    20        130  254   0.000058  3.325227e-06   \n",
      "37        photo  GCN-TAS    20        115  237   0.000046  3.831093e-06   \n",
      "38       pubmed  GAT-MAS    20        129  157   0.000040  9.447578e-07   \n",
      "39       pubmed  GAT-TAS    20        111  154   0.000037  1.074954e-06   \n",
      "40       pubmed  GCN-MAS    20        204  263   0.000040  4.137136e-07   \n",
      "41       pubmed  GCN-TAS    20        181  241   0.000036  6.984932e-07   \n",
      "42        shape  GAT-MAS    20         17  150   0.003670  5.047389e-05   \n",
      "43        shape  GAT-TAS    20         16  143   0.003678  5.237370e-05   \n",
      "44        shape  GCN-MAS    20         46  709   0.002569  2.394773e-04   \n",
      "45        shape  GCN-TAS    20         39  958   0.000966  6.257229e-04   \n",
      "46     squirrel  GAT-MAS    20         23   63   0.000519  3.118651e-05   \n",
      "47     squirrel  GCN-MAS    20         67  173   0.000476  2.726430e-05   \n",
      "48     squirrel  GCN-TAS    20         66  105   0.000472  2.185054e-05   \n",
      "49        texas  GAT-MAS    20          5   20   0.010980  1.788342e-03   \n",
      "50        texas  GAT-TAS    20          6   18   0.010645  1.504106e-03   \n",
      "51        texas  GCN-MAS    20         23   46   0.010208  1.334518e-03   \n",
      "52        texas  GCN-TAS    20         27   43   0.006228  1.222050e-03   \n",
      "53         wiki  GCN-MAS    20        210  362   0.000104  4.567773e-06   \n",
      "54         wiki  GCN-TAS    20        234  363   0.000087  3.977591e-06   \n",
      "55    wisconsin  GAT-MAS    20          5   25   0.007995  1.644545e-03   \n",
      "56    wisconsin  GAT-TAS    20          5   24   0.008624  1.493444e-03   \n",
      "57    wisconsin  GCN-MAS    20         25   43   0.006508  9.318931e-04   \n",
      "58    wisconsin  GCN-TAS    20         22   40   0.005393  8.226306e-04   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.311487  0.022323        0.000824  ...            0.268026   \n",
      "1        0.324645  0.016689        0.000822  ...            0.269763   \n",
      "2        0.379763  0.006116        0.000822  ...            0.280447   \n",
      "3        0.405763  0.010504        0.000814  ...            0.287632   \n",
      "4        0.637127  0.028844        0.002020  ...            0.553691   \n",
      "5        0.653647  0.028662        0.002067  ...            0.554833   \n",
      "6        0.659622  0.019314        0.002097  ...            0.575220   \n",
      "7        0.708216  0.031980        0.002120  ...            0.583919   \n",
      "8        0.798076  0.008372        0.001081  ...            0.692298   \n",
      "9        0.830607  0.009827        0.001009  ...            0.721480   \n",
      "10       0.850932  0.009342        0.000963  ...            0.731408   \n",
      "11       0.899068  0.009019        0.000912  ...            0.750481   \n",
      "12       0.595357  0.026689        0.003827  ...            0.497286   \n",
      "13       0.643071  0.023973        0.003337  ...            0.522714   \n",
      "14       0.661857  0.014211        0.003434  ...            0.509000   \n",
      "15       0.663286  0.016525        0.003396  ...            0.503143   \n",
      "16       0.905148  0.004477        0.000118  ...            0.888380   \n",
      "17       0.920332  0.003876        0.000104  ...            0.902298   \n",
      "18       0.880724  0.012825        0.000821  ...            0.815953   \n",
      "19       0.918833  0.009798        0.000701  ...            0.843944   \n",
      "20       0.915583  0.007709        0.000716  ...            0.834490   \n",
      "21       0.946307  0.005310        0.000633  ...            0.860709   \n",
      "22       0.577473  0.092525        0.030910  ...            0.436667   \n",
      "23       0.537912  0.091973        0.031376  ...            0.395556   \n",
      "24       0.563736  0.071759        0.031281  ...            0.424444   \n",
      "25       0.754396  0.071509        0.028332  ...            0.501111   \n",
      "26       0.581379  0.014325        0.003097  ...            0.591244   \n",
      "27       0.581379  0.014325        0.003095  ...            0.591244   \n",
      "28       0.581609  0.014558        0.003087  ...            0.591244   \n",
      "29       0.592069  0.039828        0.003080  ...            0.599770   \n",
      "30       0.590000  0.009232        0.002204  ...            0.577687   \n",
      "31       0.590000  0.009232        0.002205  ...            0.577687   \n",
      "32       0.590732  0.009001        0.002206  ...            0.578013   \n",
      "33       0.590000  0.009232        0.002212  ...            0.577687   \n",
      "34       0.947765  0.004840        0.000131  ...            0.926621   \n",
      "35       0.953948  0.005139        0.000120  ...            0.932505   \n",
      "36       0.931869  0.003574        0.000141  ...            0.925994   \n",
      "37       0.948797  0.004508        0.000119  ...            0.938860   \n",
      "38       0.848468  0.004648        0.000088  ...            0.833932   \n",
      "39       0.859475  0.004169        0.000084  ...            0.842422   \n",
      "40       0.852308  0.002044        0.000089  ...            0.837807   \n",
      "41       0.865120  0.003106        0.000082  ...            0.848174   \n",
      "42       0.431857  0.017374        0.007347  ...            0.419429   \n",
      "43       0.431857  0.017374        0.007349  ...            0.419429   \n",
      "44       0.591000  0.037186        0.005201  ...            0.570286   \n",
      "45       0.905429  0.103680        0.001894  ...            0.908571   \n",
      "46       0.413788  0.038768        0.001162  ...            0.345846   \n",
      "47       0.479365  0.035635        0.001123  ...            0.405769   \n",
      "48       0.507308  0.023653        0.001117  ...            0.410846   \n",
      "49       0.623077  0.066328        0.026407  ...            0.543333   \n",
      "50       0.640110  0.076374        0.025985  ...            0.560000   \n",
      "51       0.676374  0.055518        0.027852  ...            0.540000   \n",
      "52       0.846154  0.040807        0.023231  ...            0.622222   \n",
      "53       0.821368  0.006152        0.000249  ...            0.809590   \n",
      "54       0.845607  0.006325        0.000214  ...            0.826479   \n",
      "55       0.605200  0.089283        0.020063  ...            0.509677   \n",
      "56       0.573200  0.076789        0.019936  ...            0.520161   \n",
      "57       0.714400  0.061592        0.019971  ...            0.537903   \n",
      "58       0.774400  0.033901        0.017673  ...            0.612097   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.009999  0.000824  0.000003      0.270789  0.010662         3.890716   \n",
      "1   0.008630  0.000823  0.000003      0.274763  0.010534         3.816634   \n",
      "2   0.009010  0.000822  0.000003      0.283053  0.008462         2.263166   \n",
      "3   0.007516  0.000813  0.000003      0.291763  0.008682         1.364917   \n",
      "4   0.031984  0.002044  0.000090      0.551228  0.029547         4.662905   \n",
      "5   0.026440  0.002064  0.000078      0.559825  0.019634         4.868731   \n",
      "6   0.026739  0.002099  0.000077      0.574211  0.026393         1.743535   \n",
      "7   0.027980  0.002114  0.000096      0.587544  0.025397         1.271881   \n",
      "8   0.012634  0.001064  0.000047      0.696939  0.016518         7.211964   \n",
      "9   0.016019  0.000982  0.000036      0.721369  0.015329         7.593142   \n",
      "10  0.010495  0.000960  0.000048      0.731273  0.014771         2.507622   \n",
      "11  0.011072  0.000912  0.000041      0.751200  0.017348         1.917844   \n",
      "12  0.023877  0.003770  0.000211      0.497143  0.023063         1.394393   \n",
      "13  0.024778  0.003199  0.000135      0.525857  0.024726         1.711293   \n",
      "14  0.025977  0.003413  0.000147      0.517571  0.020630         1.153833   \n",
      "15  0.022968  0.003415  0.000115      0.500857  0.026788         0.897476   \n",
      "16  0.004438  0.000116  0.000007      0.888176  0.007910         7.821692   \n",
      "17  0.003428  0.000103  0.000009      0.900524  0.008120         6.514783   \n",
      "18  0.015818  0.000771  0.000037      0.825849  0.010051         3.768498   \n",
      "19  0.012880  0.000656  0.000037      0.853767  0.007486         7.676185   \n",
      "20  0.013976  0.000692  0.000034      0.842171  0.012691         1.475715   \n",
      "21  0.013915  0.000628  0.000036      0.862925  0.010997         1.471540   \n",
      "22  0.070374  0.032137  0.002744      0.417021  0.068476         0.552776   \n",
      "23  0.062688  0.032081  0.003142      0.424468  0.081232         0.605858   \n",
      "24  0.060279  0.030939  0.001503      0.434043  0.044416         0.252432   \n",
      "25  0.075437  0.027885  0.002454      0.497872  0.050444         0.288667   \n",
      "26  0.014733  0.003093  0.000050      0.592694  0.027261         0.383074   \n",
      "27  0.014733  0.003089  0.000048      0.592694  0.027261         0.445346   \n",
      "28  0.014733  0.003067  0.000052      0.592694  0.027261         0.457312   \n",
      "29  0.029233  0.003065  0.000089      0.603881  0.037621         0.463158   \n",
      "30  0.022648  0.002204  0.000020      0.581877  0.017620         0.450431   \n",
      "31  0.022648  0.002205  0.000025      0.581877  0.017620         0.522906   \n",
      "32  0.022923  0.002198  0.000021      0.583010  0.018375         0.382326   \n",
      "33  0.022648  0.002203  0.000016      0.581877  0.017620         0.258407   \n",
      "34  0.007957  0.000135  0.000015      0.925693  0.007218        14.403574   \n",
      "35  0.005986  0.000123  0.000010      0.932593  0.007507        21.523496   \n",
      "36  0.007531  0.000149  0.000021      0.921066  0.016866         3.284605   \n",
      "37  0.005676  0.000128  0.000016      0.932619  0.011997         3.459985   \n",
      "38  0.004381  0.000086  0.000002      0.835517  0.005193        16.654182   \n",
      "39  0.003859  0.000081  0.000002      0.845193  0.004158        14.596954   \n",
      "40  0.004029  0.000088  0.000002      0.837546  0.004516         7.768586   \n",
      "41  0.005352  0.000081  0.000002      0.847819  0.004203         8.414752   \n",
      "42  0.026114  0.007363  0.000182      0.431143  0.029749         0.549503   \n",
      "43  0.026114  0.007371  0.000197      0.431143  0.029749        20.697472   \n",
      "44  0.053303  0.005180  0.000600      0.576857  0.054950         1.426701   \n",
      "45  0.127668  0.002101  0.001308      0.895714  0.117881         3.926231   \n",
      "46  0.030009  0.001174  0.000014      0.342352  0.032011        14.896062   \n",
      "47  0.029758  0.001133  0.000020      0.395926  0.025600         2.951371   \n",
      "48  0.019632  0.001126  0.000021      0.408570  0.019073         3.767296   \n",
      "49  0.061801  0.026384  0.002763      0.564894  0.060367         0.561196   \n",
      "50  0.053760  0.025868  0.003055      0.570213  0.053737         0.634780   \n",
      "51  0.063307  0.027699  0.002964      0.562766  0.076395         0.491753   \n",
      "52  0.082520  0.023379  0.003825      0.646809  0.059141         0.471381   \n",
      "53  0.009045  0.000251  0.000012      0.809142  0.008555         7.543077   \n",
      "54  0.007733  0.000214  0.000010      0.827324  0.007998        15.346176   \n",
      "55  0.072585  0.020700  0.001844      0.485156  0.050050         0.954202   \n",
      "56  0.076886  0.020622  0.001766      0.520312  0.042140         0.595454   \n",
      "57  0.050539  0.019650  0.001504      0.550781  0.060807         0.331305   \n",
      "58  0.062681  0.018056  0.002139      0.586719  0.046593         0.965205   \n",
      "\n",
      "              total_runtime             \n",
      "          std          mean        std  \n",
      "0    0.312905      9.256007   0.309728  \n",
      "1    0.867084     10.952061   8.498502  \n",
      "2    0.816655      7.597402   0.835388  \n",
      "3    0.193656      6.440500   0.255613  \n",
      "4    0.406902      7.033037   0.418515  \n",
      "5    0.332424      7.292099   0.393309  \n",
      "6    0.458718      4.010334   0.451454  \n",
      "7    0.117919      3.566880   0.166103  \n",
      "8    0.633932      8.756284   0.703508  \n",
      "9    0.610540      9.152979   0.649805  \n",
      "10   0.479475      3.970515   0.529296  \n",
      "11   0.081231      3.284657   0.160159  \n",
      "12   0.365977      1.731529   0.385436  \n",
      "13   0.918091      2.036321   0.913339  \n",
      "14   0.241383      1.496917   0.245907  \n",
      "15   0.071720      1.207490   0.115668  \n",
      "16   2.795177     41.820913   6.962626  \n",
      "17   1.162957     37.917484   1.873287  \n",
      "18   0.311306      4.726195   0.346534  \n",
      "19  14.715810      8.626665  14.711469  \n",
      "20   0.098859      2.373655   0.193358  \n",
      "21   0.139373      2.321042   0.195677  \n",
      "22   0.136306      0.666400   0.149358  \n",
      "23   0.183521      0.722146   0.189169  \n",
      "24   0.068799      0.346366   0.093272  \n",
      "25   0.063488      0.354503   0.088520  \n",
      "26   0.152068      0.497594   0.177505  \n",
      "27   0.118293      0.563633   0.126051  \n",
      "28   0.327023      0.573458   0.329860  \n",
      "29   0.578263      0.573370   0.597668  \n",
      "30   0.090022      0.637322   0.124028  \n",
      "31   0.164360      0.714230   0.193725  \n",
      "32   0.312045      0.580634   0.312882  \n",
      "33   0.064363      0.440285   0.104924  \n",
      "34   0.569729     25.241859   0.667934  \n",
      "35  23.224157     36.225454  25.821606  \n",
      "36   0.384106     13.779973   0.450686  \n",
      "37   0.545584     13.941196   0.570609  \n",
      "38   1.468258     45.526588   5.927409  \n",
      "39   1.200620     41.567778   2.426324  \n",
      "40   5.140457     38.278194  10.958789  \n",
      "41   8.673947     36.494994   8.896097  \n",
      "42   0.166319      0.699384   0.182920  \n",
      "43  89.135502     20.832953  89.128349  \n",
      "44   0.454635      1.574541   0.453430  \n",
      "45   1.239278      4.053769   1.230984  \n",
      "46  15.674124     30.585485  26.969107  \n",
      "47   1.155627     12.460648   1.242862  \n",
      "48   0.930683     14.509158   1.215848  \n",
      "49   0.120248      0.670177   0.147516  \n",
      "50   0.141501      0.747476   0.166256  \n",
      "51   0.378034      0.561944   0.403987  \n",
      "52   0.314441      0.539889   0.323557  \n",
      "53   2.064829     31.424738   2.110787  \n",
      "54  26.002745     55.949716  43.322952  \n",
      "55   0.446126      1.122982   0.455719  \n",
      "56   0.135892      0.731421   0.152205  \n",
      "57   0.048402      0.422638   0.081250  \n",
      "58   0.674014      1.065165   0.691095  \n",
      "\n",
      "[59 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"results_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = ['actor','chameleon','citeseer','community','computer','cora','cornell','cycle','grid','photo','pubmed','shape','squirrel','texas','wiki','wisconsin']\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_gcn_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gcn_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        \n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results4_exp'+str(exp)+'.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name        method trial best_epoch      train_loss            \\\n",
      "                              count        min  max       mean       std   \n",
      "0         actor  GraphGPS-MAS    20         17   21   0.000319  0.000010   \n",
      "1         actor  GraphGPS-TAS    20         18   21   0.000307  0.000007   \n",
      "2         actor       NAG-MAS    20          6   10   0.000733  0.000026   \n",
      "3         actor       NAG-TAS    20          6   10   0.000725  0.000027   \n",
      "4     chameleon  GraphGPS-MAS    20         15   20   0.000274  0.000056   \n",
      "5     chameleon  GraphGPS-TAS    20         18   20   0.000241  0.000029   \n",
      "6     chameleon       NAG-MAS    20         14   17   0.000646  0.000055   \n",
      "7     chameleon       NAG-TAS    20         15   18   0.000616  0.000058   \n",
      "8      citeseer  GraphGPS-MAS    20         21   26   0.000176  0.000034   \n",
      "9      citeseer  GraphGPS-TAS    20         21   26   0.000157  0.000035   \n",
      "10     citeseer       NAG-MAS    20         13   14   0.000349  0.000012   \n",
      "11     citeseer       NAG-TAS    20         13   15   0.000330  0.000022   \n",
      "12    community  GraphGPS-MAS    20         18   42   0.001508  0.000165   \n",
      "13    community  GraphGPS-TAS    20         16  166   0.001634  0.000252   \n",
      "14    community       NAG-MAS    20         22   29   0.001444  0.000041   \n",
      "15    community       NAG-TAS    20         37   47   0.001279  0.000117   \n",
      "16     computer       NAG-MAS    20         14   74   0.000138  0.000021   \n",
      "17     computer       NAG-TAS    20         17   60   0.000127  0.000015   \n",
      "18         cora  GraphGPS-MAS    20         28   37   0.000076  0.000026   \n",
      "19         cora  GraphGPS-TAS    20         28   35   0.000063  0.000020   \n",
      "20         cora       NAG-MAS    20         17   19   0.000187  0.000019   \n",
      "21         cora       NAG-TAS    20         17   21   0.000160  0.000031   \n",
      "22      cornell  GraphGPS-MAS    20         12   30   0.000950  0.001375   \n",
      "23      cornell  GraphGPS-TAS    20         12   34   0.000654  0.000831   \n",
      "24      cornell       NAG-MAS    20         11   17   0.006384  0.002222   \n",
      "25      cornell       NAG-TAS    20          7   17   0.007715  0.002497   \n",
      "26        cycle  GraphGPS-MAS    20          7  150   0.001555  0.000014   \n",
      "27        cycle  GraphGPS-TAS    20          5  207   0.001557  0.000034   \n",
      "28        cycle       NAG-MAS    20          6  106   0.001538  0.000020   \n",
      "29        cycle       NAG-TAS    20         31   78   0.001514  0.000027   \n",
      "30         grid  GraphGPS-MAS    20          2  155   0.001103  0.000013   \n",
      "31         grid  GraphGPS-TAS    20          2   93   0.001105  0.000011   \n",
      "32         grid       NAG-MAS    20          4   91   0.001079  0.000011   \n",
      "33         grid       NAG-TAS    20         41  106   0.001078  0.000010   \n",
      "34        photo  GraphGPS-MAS    20         37   52   0.000027  0.000005   \n",
      "35        photo  GraphGPS-TAS    20         39   67   0.000025  0.000005   \n",
      "36        photo       NAG-MAS    20         16   62   0.000079  0.000021   \n",
      "37        photo       NAG-TAS    20         15   64   0.000061  0.000018   \n",
      "38       pubmed       NAG-MAS    20          6   36   0.000129  0.000015   \n",
      "39       pubmed       NAG-TAS    20          6   11   0.000133  0.000015   \n",
      "40        shape  GraphGPS-MAS    20         52  133   0.002688  0.000201   \n",
      "41        shape  GraphGPS-TAS    20         52   92   0.002010  0.000348   \n",
      "42        shape       NAG-MAS    20         25   61   0.002937  0.000115   \n",
      "43        shape       NAG-TAS    20         43  106   0.001216  0.000162   \n",
      "44     squirrel  GraphGPS-MAS    20         17   19   0.000339  0.000011   \n",
      "45     squirrel  GraphGPS-TAS    20         17   19   0.000337  0.000011   \n",
      "46     squirrel       NAG-MAS    20          6    9   0.000966  0.000075   \n",
      "47     squirrel       NAG-TAS    20          6    9   0.000959  0.000069   \n",
      "48        texas  GraphGPS-MAS    20         16   33   0.000570  0.000482   \n",
      "49        texas  GraphGPS-TAS    20         13   47   0.000864  0.000940   \n",
      "50        texas       NAG-MAS    20         12   19   0.005823  0.001582   \n",
      "51        texas       NAG-TAS    20         12   22   0.005923  0.002238   \n",
      "52         wiki       NAG-MAS    20         15   62   0.000225  0.000030   \n",
      "53         wiki       NAG-TAS    20         15   57   0.000218  0.000022   \n",
      "54    wisconsin  GraphGPS-MAS    20         13   93   0.000392  0.000491   \n",
      "55    wisconsin  GraphGPS-TAS    20         14   22   0.000580  0.000371   \n",
      "56    wisconsin       NAG-MAS    20         13   20   0.003549  0.001038   \n",
      "57    wisconsin       NAG-TAS    20         12   28   0.003752  0.001715   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.509776  0.015995        0.000760  ...            0.348368   \n",
      "1        0.528776  0.012614        0.000761  ...            0.354263   \n",
      "2        0.408526  0.027019        0.000779  ...            0.332579   \n",
      "3        0.422697  0.027127        0.000775  ...            0.337763   \n",
      "4        0.913401  0.021676        0.001879  ...            0.577944   \n",
      "5        0.932557  0.010160        0.001874  ...            0.583919   \n",
      "6        0.778647  0.026443        0.001863  ...            0.594200   \n",
      "7        0.802241  0.028822        0.001882  ...            0.590422   \n",
      "8        0.904029  0.019360        0.000963  ...            0.743803   \n",
      "9        0.914492  0.019335        0.000940  ...            0.752587   \n",
      "10       0.833764  0.006419        0.001065  ...            0.717810   \n",
      "11       0.846993  0.010118        0.001007  ...            0.738568   \n",
      "12       0.573214  0.048180        0.003580  ...            0.486429   \n",
      "13       0.511000  0.080998        0.003643  ...            0.447857   \n",
      "14       0.573000  0.011807        0.003294  ...            0.517857   \n",
      "15       0.610929  0.034975        0.002772  ...            0.586000   \n",
      "16       0.922695  0.011914        0.000209  ...            0.890416   \n",
      "17       0.927349  0.008200        0.000205  ...            0.893106   \n",
      "18       0.970126  0.012037        0.000674  ...            0.849261   \n",
      "19       0.976292  0.008738        0.000627  ...            0.866248   \n",
      "20       0.948818  0.005620        0.000769  ...            0.841507   \n",
      "21       0.956019  0.008257        0.000700  ...            0.861965   \n",
      "22       0.989560  0.020318        0.022730  ...            0.630000   \n",
      "23       0.992308  0.013854        0.021333  ...            0.658889   \n",
      "24       0.876374  0.080110        0.024658  ...            0.576667   \n",
      "25       0.819780  0.104944        0.026382  ...            0.518889   \n",
      "26       0.577126  0.013414        0.003056  ...            0.599539   \n",
      "27       0.573103  0.017604        0.003053  ...            0.600461   \n",
      "28       0.579195  0.021571        0.003046  ...            0.588940   \n",
      "29       0.594368  0.015546        0.002987  ...            0.606682   \n",
      "30       0.580732  0.021772        0.002189  ...            0.585342   \n",
      "31       0.579919  0.019811        0.002194  ...            0.580782   \n",
      "32       0.616098  0.016889        0.002154  ...            0.615147   \n",
      "33       0.604959  0.034228        0.002152  ...            0.605863   \n",
      "34       0.970601  0.006842        0.000099  ...            0.946679   \n",
      "35       0.972562  0.006374        0.000095  ...            0.948509   \n",
      "36       0.957072  0.012359        0.000115  ...            0.943541   \n",
      "37       0.966013  0.012293        0.000110  ...            0.946940   \n",
      "38       0.907065  0.011170        0.000201  ...            0.881710   \n",
      "39       0.905087  0.011604        0.000199  ...            0.881852   \n",
      "40       0.569286  0.035816        0.005389  ...            0.566857   \n",
      "41       0.707571  0.086648        0.004107  ...            0.700857   \n",
      "42       0.508143  0.032738        0.005909  ...            0.500000   \n",
      "43       0.802714  0.046474        0.002117  ...            0.858857   \n",
      "44       0.712212  0.013777        0.001104  ...            0.385462   \n",
      "45       0.717173  0.015726        0.001100  ...            0.385731   \n",
      "46       0.529135  0.039609        0.001086  ...            0.407423   \n",
      "47       0.543442  0.035739        0.001070  ...            0.416385   \n",
      "48       0.992857  0.011428        0.016047  ...            0.732222   \n",
      "49       0.991209  0.013148        0.015452  ...            0.726667   \n",
      "50       0.881319  0.070553        0.021943  ...            0.643333   \n",
      "51       0.873077  0.076673        0.021567  ...            0.655556   \n",
      "52       0.858205  0.017563        0.000388  ...            0.823949   \n",
      "53       0.860803  0.013160        0.000380  ...            0.823932   \n",
      "54       0.990000  0.013947        0.009945  ...            0.789516   \n",
      "55       0.987600  0.012028        0.011096  ...            0.766935   \n",
      "56       0.892400  0.049958        0.013642  ...            0.706452   \n",
      "57       0.888800  0.062719        0.014787  ...            0.667742   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.011619  0.000761  0.000007      0.351789  0.011016         8.259935   \n",
      "1   0.011204  0.000762  0.000009      0.350816  0.011917         8.510328   \n",
      "2   0.013377  0.000783  0.000006      0.329342  0.010841         3.019385   \n",
      "3   0.010645  0.000778  0.000011      0.336474  0.012605         3.188565   \n",
      "4   0.018159  0.001854  0.000071      0.592018  0.019264         1.958197   \n",
      "5   0.020102  0.001843  0.000068      0.596579  0.016599         1.668496   \n",
      "6   0.020207  0.001879  0.000066      0.591491  0.017912         1.393290   \n",
      "7   0.017281  0.001899  0.000066      0.584123  0.022578         1.489792   \n",
      "8   0.014408  0.001001  0.000062      0.738776  0.014476         2.839036   \n",
      "9   0.014379  0.000973  0.000050      0.748079  0.012742         2.342932   \n",
      "10  0.012188  0.001053  0.000048      0.721729  0.016095         1.789209   \n",
      "11  0.012535  0.000992  0.000047      0.741477  0.016313         1.865795   \n",
      "12  0.029062  0.003710  0.000201      0.474286  0.030365         0.898494   \n",
      "13  0.054051  0.003703  0.000184      0.452571  0.029466         0.912662   \n",
      "14  0.024681  0.003327  0.000149      0.512571  0.018961       580.784742   \n",
      "15  0.023522  0.002776  0.000150      0.582143  0.028615         1.882280   \n",
      "16  0.005627  0.000208  0.000014      0.890954  0.005934         8.265077   \n",
      "17  0.004725  0.000208  0.000012      0.891870  0.006855         8.530525   \n",
      "18  0.012128  0.000664  0.000051      0.854948  0.014564         1.981737   \n",
      "19  0.010785  0.000638  0.000052      0.864549  0.009319         2.535188   \n",
      "20  0.014919  0.000743  0.000034      0.848449  0.007446         1.724822   \n",
      "21  0.011704  0.000672  0.000033      0.868168  0.010028         1.666000   \n",
      "22  0.062968  0.023426  0.002942      0.611702  0.065077         2.792442   \n",
      "23  0.067355  0.022787  0.004478      0.656383  0.057039         0.758881   \n",
      "24  0.097659  0.024230  0.002908      0.576596  0.070701         0.879313   \n",
      "25  0.098666  0.026041  0.002142      0.490426  0.057538         0.783125   \n",
      "26  0.021506  0.003106  0.000055      0.557763  0.027005         5.741802   \n",
      "27  0.019153  0.003146  0.000098      0.568265  0.046625         0.769174   \n",
      "28  0.017474  0.003038  0.000047      0.581279  0.028230         1.213996   \n",
      "29  0.032561  0.002997  0.000062      0.592009  0.021938         1.350746   \n",
      "30  0.021506  0.002252  0.000063      0.539320  0.072184         8.372584   \n",
      "31  0.024719  0.002247  0.000058      0.547087  0.066675         0.706025   \n",
      "32  0.025259  0.002152  0.000030      0.618447  0.019808         1.287500   \n",
      "33  0.027538  0.002144  0.000029      0.605987  0.024442         1.543075   \n",
      "34  0.005793  0.000106  0.000011      0.944276  0.006734        11.700680   \n",
      "35  0.005267  0.000101  0.000010      0.946759  0.007574        11.843223   \n",
      "36  0.007162  0.000119  0.000012      0.942656  0.006941         4.602924   \n",
      "37  0.008253  0.000114  0.000011      0.946053  0.005056         4.324360   \n",
      "38  0.005628  0.000201  0.000008      0.881937  0.004550         8.435607   \n",
      "39  0.003809  0.000198  0.000006      0.882647  0.003692         8.055920   \n",
      "40  0.032410  0.005669  0.000761      0.548857  0.064129        41.710621   \n",
      "41  0.080498  0.006165  0.002146      0.562571  0.134108         1.619406   \n",
      "42  0.036495  0.005902  0.000283      0.502571  0.033447         1.254851   \n",
      "43  0.034936  0.002176  0.000313      0.844286  0.040528         1.640492   \n",
      "44  0.012466  0.001103  0.000018      0.392045  0.011693         4.960592   \n",
      "45  0.012594  0.001100  0.000017      0.391814  0.013441         6.367284   \n",
      "46  0.016215  0.001088  0.000023      0.408878  0.016010         2.612590   \n",
      "47  0.017019  0.001069  0.000018      0.421291  0.014065         2.437143   \n",
      "48  0.065872  0.017647  0.004894      0.741489  0.058279         0.639905   \n",
      "49  0.055427  0.016759  0.003791      0.729787  0.065887         0.669976   \n",
      "50  0.067046  0.022416  0.003035      0.625532  0.058737         0.849450   \n",
      "51  0.061812  0.021166  0.002074      0.652128  0.042707         0.858628   \n",
      "52  0.008462  0.000395  0.000022      0.823787  0.011919         6.320338   \n",
      "53  0.007896  0.000382  0.000022      0.825889  0.011970         6.361178   \n",
      "54  0.056476  0.011348  0.003107      0.783594  0.044274         0.722027   \n",
      "55  0.055744  0.011325  0.001843      0.750000  0.050440         0.848247   \n",
      "56  0.054282  0.014088  0.001719      0.685937  0.051174         0.855473   \n",
      "57  0.059757  0.016158  0.002861      0.633594  0.054476         0.826396   \n",
      "\n",
      "                total_runtime               \n",
      "            std          mean          std  \n",
      "0      0.587950     14.417486     0.607863  \n",
      "1      0.880300     14.495768     0.863941  \n",
      "2      0.119048      9.376991     0.252115  \n",
      "3      0.280885      9.713323     0.404887  \n",
      "4      0.489492      4.370758     0.489122  \n",
      "5      0.126356      4.197006     0.238680  \n",
      "6      0.095968      4.067066     0.105206  \n",
      "7      0.119422      4.410104     0.236213  \n",
      "8      0.407485      4.470575     0.421534  \n",
      "9      0.144928      3.944021     0.227549  \n",
      "10     0.058556      3.713934     0.089928  \n",
      "11     0.254883      3.776685     0.295781  \n",
      "12     0.099904      1.336993     0.144043  \n",
      "13     0.331287      1.327686     0.364090  \n",
      "14  2591.200696    581.281188  2591.234221  \n",
      "15     0.139886      2.315993     0.160661  \n",
      "16     1.332966     46.436639     1.561418  \n",
      "17     1.140884     46.204487     1.428156  \n",
      "18     0.124453      3.061130     0.186568  \n",
      "19     0.504106      3.582571     0.574283  \n",
      "20     0.117336      3.024037     0.180473  \n",
      "21     0.082239      2.831142     0.164729  \n",
      "22     9.887237      2.898698     9.885526  \n",
      "23     0.151909      0.870813     0.171521  \n",
      "24     0.138211      1.061134     0.159898  \n",
      "25     0.111348      0.961942     0.148537  \n",
      "26    15.809610      5.929322    15.819182  \n",
      "27     0.492823      0.946771     0.527150  \n",
      "28     0.350222      1.469389     0.361497  \n",
      "29     0.242964      1.580723     0.262357  \n",
      "30    18.234655      8.649382    18.239018  \n",
      "31     0.236981      0.965414     0.267686  \n",
      "32     0.374704      1.648080     0.367037  \n",
      "33     0.289228      1.857459     0.295024  \n",
      "34     0.418699     22.848766     0.485875  \n",
      "35     0.723937     23.114629     0.833966  \n",
      "36     0.821165     18.552218     0.823485  \n",
      "37     0.638540     17.449568     0.641427  \n",
      "38     0.804545     41.591123     2.306643  \n",
      "39     0.239271     40.509709     1.911828  \n",
      "40   181.449024     41.949289   181.443079  \n",
      "41     1.267440      1.831318     1.302728  \n",
      "42     0.240819      1.539590     0.249220  \n",
      "43     0.260225      1.889142     0.274669  \n",
      "44     0.198147     15.369003     0.399516  \n",
      "45     2.403446     16.883383     2.584854  \n",
      "46     0.309277     14.593321     0.610624  \n",
      "47     0.086879     14.273361     0.334312  \n",
      "48     0.070701      0.749322     0.095879  \n",
      "49     0.096939      0.772161     0.116252  \n",
      "50     0.065331      1.008876     0.084135  \n",
      "51     0.128610      1.033422     0.141657  \n",
      "52     0.916271     35.735504     1.473205  \n",
      "53     0.870923     37.346823     1.213582  \n",
      "54     0.168136      0.885800     0.178308  \n",
      "55     0.539854      1.028703     0.557549  \n",
      "56     0.071888      1.065803     0.092284  \n",
      "57     0.071761      1.033015     0.091877  \n",
      "\n",
      "[58 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"results_new_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = ['actor','chameleon','citeseer','community','computer','cora','cornell','cycle','grid','photo','pubmed','shape','squirrel','texas','wiki','wisconsin']\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_gps_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results5_exp'+str(exp)+'.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
