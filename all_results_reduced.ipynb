{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name   method trial best_epoch      train_loss            \\\n",
      "                         count        min  max       mean       std   \n",
      "0         actor  NAG-MAS    20          7   10   0.000714  0.000038   \n",
      "1         actor  NAG-TAS    20          7   10   0.000713  0.000037   \n",
      "2     chameleon  NAG-MAS    20         12   15   0.000707  0.000067   \n",
      "3     chameleon  NAG-TAS    20         13   15   0.000673  0.000046   \n",
      "4      citeseer  NAG-MAS    20         12   13   0.000407  0.000025   \n",
      "5      citeseer  NAG-TAS    20         12   14   0.000358  0.000020   \n",
      "6     community  NAG-MAS    20         13   29   0.001551  0.000148   \n",
      "7     community  NAG-TAS    20         13   29   0.001719  0.000076   \n",
      "8      computer  NAG-MAS    20         11   24   0.000151  0.000026   \n",
      "9      computer  NAG-TAS    20         12   38   0.000145  0.000026   \n",
      "10         cora  NAG-MAS    20         15   19   0.000202  0.000040   \n",
      "11         cora  NAG-TAS    20         16   19   0.000169  0.000025   \n",
      "12      cornell  NAG-MAS    20         10   17   0.004377  0.001829   \n",
      "13      cornell  NAG-TAS    20          9   16   0.008241  0.002122   \n",
      "14        cycle  NAG-MAS    20          5   76   0.001536  0.000022   \n",
      "15        cycle  NAG-TAS    20         14  148   0.001497  0.000039   \n",
      "16         grid  NAG-MAS    20          1  162   0.001109  0.000027   \n",
      "17         grid  NAG-TAS    20          1  174   0.001107  0.000021   \n",
      "18        photo  NAG-MAS    20         14   21   0.000082  0.000017   \n",
      "19        photo  NAG-TAS    20         14   22   0.000079  0.000017   \n",
      "20       pubmed  NAG-MAS    20          6   37   0.000134  0.000009   \n",
      "21       pubmed  NAG-TAS    20          5   45   0.000133  0.000018   \n",
      "22        shape  NAG-MAS    20         34   89   0.003138  0.000095   \n",
      "23        shape  NAG-TAS    20         20   63   0.003149  0.000164   \n",
      "24     squirrel  NAG-MAS    20          6    8   0.000961  0.000037   \n",
      "25     squirrel  NAG-TAS    20          6    8   0.000959  0.000039   \n",
      "26        texas  NAG-MAS    20         12   17   0.004322  0.001194   \n",
      "27        texas  NAG-TAS    20          7   16   0.007218  0.002206   \n",
      "28         wiki  NAG-MAS    20         13   21   0.000239  0.000025   \n",
      "29         wiki  NAG-TAS    20         15   24   0.000221  0.000025   \n",
      "30    wisconsin  NAG-MAS    20         14   21   0.003075  0.001061   \n",
      "31    wisconsin  NAG-TAS    20         11   19   0.004192  0.001173   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.426145  0.039073        0.000782  ...            0.335684   \n",
      "1        0.424487  0.034301        0.000780  ...            0.336684   \n",
      "2        0.727285  0.027094        0.001890  ...            0.581459   \n",
      "3        0.741696  0.021244        0.001900  ...            0.580668   \n",
      "4        0.781600  0.011781        0.001051  ...            0.709146   \n",
      "5        0.812087  0.010232        0.000980  ...            0.730746   \n",
      "6        0.581214  0.041707        0.003825  ...            0.479143   \n",
      "7        0.483143  0.027653        0.003789  ...            0.423286   \n",
      "8        0.912565  0.016342        0.000215  ...            0.886867   \n",
      "9        0.915256  0.015276        0.000212  ...            0.888220   \n",
      "10       0.921529  0.013292        0.000799  ...            0.828360   \n",
      "11       0.939180  0.009213        0.000694  ...            0.855096   \n",
      "12       0.936813  0.068290        0.023493  ...            0.605556   \n",
      "13       0.800549  0.117994        0.027517  ...            0.456667   \n",
      "14       0.576782  0.022137        0.003041  ...            0.588940   \n",
      "15       0.605977  0.026173        0.002985  ...            0.612442   \n",
      "16       0.557967  0.062021        0.002206  ...            0.580293   \n",
      "17       0.557886  0.063488        0.002208  ...            0.580619   \n",
      "18       0.955033  0.009983        0.000120  ...            0.939304   \n",
      "19       0.956562  0.011043        0.000118  ...            0.939592   \n",
      "20       0.901730  0.007590        0.000201  ...            0.878748   \n",
      "21       0.900624  0.014358        0.000198  ...            0.879763   \n",
      "22       0.466143  0.027952        0.006187  ...            0.458857   \n",
      "23       0.479000  0.030552        0.005934  ...            0.492857   \n",
      "24       0.531750  0.022255        0.001091  ...            0.397154   \n",
      "25       0.531788  0.018674        0.001090  ...            0.396577   \n",
      "26       0.905495  0.045853        0.020671  ...            0.663333   \n",
      "27       0.799451  0.087395        0.022553  ...            0.610000   \n",
      "28       0.846923  0.015054        0.000395  ...            0.815915   \n",
      "29       0.857085  0.017551        0.000395  ...            0.818735   \n",
      "30       0.907600  0.039744        0.012926  ...            0.722581   \n",
      "31       0.844000  0.058874        0.015431  ...            0.614516   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.013834  0.000786  0.000011      0.328605  0.010124         4.543842   \n",
      "1   0.010660  0.000783  0.000008      0.333211  0.011080         4.395340   \n",
      "2   0.025894  0.001887  0.000081      0.583070  0.021647         2.331776   \n",
      "3   0.025240  0.001890  0.000081      0.582807  0.024287         2.254997   \n",
      "4   0.015715  0.001050  0.000043      0.713745  0.011458         1.469156   \n",
      "5   0.015621  0.000972  0.000044      0.730912  0.014894         1.371288   \n",
      "6   0.019840  0.003902  0.000137      0.474286  0.026415         1.900407   \n",
      "7   0.019318  0.003757  0.000072      0.426429  0.023023         1.913887   \n",
      "8   0.007140  0.000216  0.000017      0.885209  0.010310         9.842119   \n",
      "9   0.006543  0.000214  0.000016      0.887944  0.008605         9.000255   \n",
      "10  0.015812  0.000769  0.000051      0.835598  0.008993         1.199485   \n",
      "11  0.012075  0.000680  0.000044      0.861004  0.010221         1.300319   \n",
      "12  0.086781  0.023569  0.003160      0.604255  0.063041         1.541735   \n",
      "13  0.076803  0.027091  0.002466      0.461702  0.054398         0.942112   \n",
      "14  0.025922  0.003019  0.000055      0.583562  0.025898         1.986624   \n",
      "15  0.028560  0.002992  0.000069      0.608904  0.026801         1.767589   \n",
      "16  0.021717  0.002202  0.000030      0.581068  0.021064         2.258598   \n",
      "17  0.020706  0.002201  0.000021      0.580906  0.017927         1.571832   \n",
      "18  0.007360  0.000120  0.000012      0.938996  0.006310         5.695540   \n",
      "19  0.007933  0.000120  0.000011      0.939415  0.006231         5.358608   \n",
      "20  0.005000  0.000200  0.000008      0.878895  0.004384         9.692642   \n",
      "21  0.006043  0.000196  0.000008      0.880152  0.006610        12.098655   \n",
      "22  0.031249  0.006166  0.000289      0.466571  0.032233         2.448301   \n",
      "23  0.048483  0.005903  0.000392      0.503143  0.046992         2.169301   \n",
      "24  0.012032  0.001096  0.000010      0.389739  0.011738         3.582736   \n",
      "25  0.007666  0.001096  0.000014      0.392275  0.012992         3.586001   \n",
      "26  0.056437  0.019986  0.002995      0.632979  0.068293         1.615869   \n",
      "27  0.045869  0.021573  0.002171      0.624468  0.063746         1.440124   \n",
      "28  0.008997  0.000397  0.000016      0.818045  0.010353         7.701366   \n",
      "29  0.006881  0.000396  0.000023      0.818592  0.012956         7.969159   \n",
      "30  0.046394  0.013426  0.001286      0.692187  0.037630         1.606497   \n",
      "31  0.061895  0.015625  0.002093      0.617188  0.039431         1.507565   \n",
      "\n",
      "             total_runtime            \n",
      "         std          mean       std  \n",
      "0   0.257380     10.503095  0.346328  \n",
      "1   0.376290     10.364625  0.505684  \n",
      "2   0.101230      4.709708  0.116560  \n",
      "3   0.265234      4.748285  0.453217  \n",
      "4   0.140906      3.410413  0.356618  \n",
      "5   0.055343      3.116285  0.120789  \n",
      "6   0.156558      2.459715  0.178042  \n",
      "7   0.150902      2.430847  0.170893  \n",
      "8   1.044351     45.278719  1.980168  \n",
      "9   1.161238     47.022013  3.399526  \n",
      "10  0.069022      2.307467  0.157587  \n",
      "11  0.079859      2.384063  0.100098  \n",
      "12  0.096733      1.818991  0.121642  \n",
      "13  0.133429      1.141169  0.164544  \n",
      "14  0.372310      2.331444  0.382052  \n",
      "15  0.814691      2.037199  0.835171  \n",
      "16  1.136219      2.681825  1.130414  \n",
      "17  0.678997      1.912692  0.701257  \n",
      "18  1.851370     17.210154  1.806329  \n",
      "19  0.602155     16.927118  0.620226  \n",
      "20  2.090861     44.659522  4.703978  \n",
      "21  1.916568     49.239586  2.406028  \n",
      "22  0.285820      2.819330  0.311228  \n",
      "23  0.288314      2.512688  0.321441  \n",
      "24  0.340464     13.816966  0.341170  \n",
      "25  0.241811     14.099923  0.555604  \n",
      "26  0.093744      1.895099  0.136538  \n",
      "27  0.161004      1.683725  0.212722  \n",
      "28  0.688863     35.232228  2.160653  \n",
      "29  1.316039     37.122143  2.132189  \n",
      "30  0.113295      1.918391  0.149228  \n",
      "31  0.145075      1.834082  0.187665  \n",
      "\n",
      "[32 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"p1_30supernodes_unmerged\"\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        # if dataset+\"_san_mas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_san_mas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag5 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"SAN-MAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_san_tas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_san_tas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag5 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"SAN-TAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_exphormer_mas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_exphormer_mas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"Exphormer-MAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_exphormer_tas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_exphormer_tas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"Exphormer-TAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results_exp'+str(exp)+'_unweighted3.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name   method trial best_epoch      train_loss            \\\n",
      "                         count        min  max       mean       std   \n",
      "0         actor      SAN    20         14   17   0.000320  0.000005   \n",
      "1         actor  SAN-MAS    20         14   17   0.000321  0.000007   \n",
      "2         actor  SAN-TAS    20         14   18   0.000320  0.000007   \n",
      "3     chameleon      SAN    20         14   18   0.000331  0.000063   \n",
      "4     chameleon  SAN-MAS    20         13   18   0.000344  0.000064   \n",
      "5     chameleon  SAN-TAS    20         13   18   0.000357  0.000071   \n",
      "6      citeseer      SAN    20         20   23   0.000174  0.000036   \n",
      "7      citeseer  SAN-MAS    20         20   23   0.000174  0.000038   \n",
      "8      citeseer  SAN-TAS    20         20   23   0.000171  0.000038   \n",
      "9     community      SAN    20         14   32   0.001546  0.000180   \n",
      "10    community  SAN-MAS    20         14   29   0.001478  0.000113   \n",
      "11    community  SAN-TAS    20         14   30   0.001698  0.000108   \n",
      "12     computer      SAN    20         63   94   0.000018  0.000003   \n",
      "13     computer  SAN-MAS    20         47   95   0.000022  0.000004   \n",
      "14     computer  SAN-TAS    20         65  105   0.000019  0.000003   \n",
      "15         cora      SAN    20         28   36   0.000074  0.000049   \n",
      "16         cora  SAN-MAS    20         28   37   0.000081  0.000049   \n",
      "17         cora  SAN-TAS    20         28   38   0.000059  0.000050   \n",
      "18      cornell      SAN    20         10   22   0.000801  0.001009   \n",
      "19      cornell  SAN-MAS    20         11   29   0.000763  0.000757   \n",
      "20      cornell  SAN-TAS    20         11   20   0.000696  0.000694   \n",
      "21        cycle      SAN    20          2  124   0.001577  0.000015   \n",
      "22        cycle  SAN-MAS    20          2  124   0.001579  0.000017   \n",
      "23        cycle  SAN-TAS    20          2  111   0.001575  0.000018   \n",
      "24         grid      SAN    20          6  165   0.001119  0.000015   \n",
      "25         grid  SAN-MAS    20          1  138   0.001118  0.000016   \n",
      "26         grid  SAN-TAS    20          6   95   0.001118  0.000015   \n",
      "27        photo      SAN    20         35   65   0.000019  0.000007   \n",
      "28        photo  SAN-MAS    20         37   79   0.000020  0.000008   \n",
      "29        photo  SAN-TAS    20         39   90   0.000018  0.000005   \n",
      "30        shape      SAN    20          3  103   0.003714  0.000063   \n",
      "31        shape  SAN-MAS    20          3   85   0.003698  0.000056   \n",
      "32        shape  SAN-TAS    20          3   89   0.003705  0.000049   \n",
      "33     squirrel      SAN    20         13   14   0.000384  0.000013   \n",
      "34     squirrel  SAN-MAS    20         11   14   0.000397  0.000018   \n",
      "35     squirrel  SAN-TAS    20         11   14   0.000400  0.000019   \n",
      "36        texas      SAN    20         15   96   0.000390  0.000383   \n",
      "37        texas  SAN-MAS    20         15   35   0.000677  0.000580   \n",
      "38        texas  SAN-TAS    20         15  165   0.000620  0.000457   \n",
      "39         wiki      SAN    20         51   81   0.000057  0.000008   \n",
      "40         wiki  SAN-MAS    20         57   81   0.000055  0.000006   \n",
      "41         wiki  SAN-TAS    20         55   84   0.000054  0.000009   \n",
      "42    wisconsin      SAN    20         15   27   0.000222  0.000161   \n",
      "43    wisconsin  SAN-MAS    20         14   75   0.000169  0.000201   \n",
      "44    wisconsin  SAN-TAS    20         15   27   0.000238  0.000178   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.499145  0.011503        0.000751  ...            0.358737   \n",
      "1        0.492934  0.013981        0.000750  ...            0.358289   \n",
      "2        0.496211  0.014120        0.000749  ...            0.362237   \n",
      "3        0.908963  0.018679        0.001974  ...            0.552636   \n",
      "4        0.897671  0.021542        0.002010  ...            0.528822   \n",
      "5        0.893278  0.025429        0.002041  ...            0.522759   \n",
      "6        0.914071  0.010643        0.000971  ...            0.736282   \n",
      "7        0.912267  0.014594        0.000993  ...            0.727076   \n",
      "8        0.915033  0.014303        0.000980  ...            0.733875   \n",
      "9        0.556786  0.072405        0.003855  ...            0.416429   \n",
      "10       0.594214  0.033205        0.003646  ...            0.497429   \n",
      "11       0.496000  0.041836        0.003893  ...            0.393429   \n",
      "12       0.960544  0.007740        0.000092  ...            0.903519   \n",
      "13       0.953629  0.009746        0.000094  ...            0.901018   \n",
      "14       0.960755  0.008072        0.000092  ...            0.902661   \n",
      "15       0.974298  0.020106        0.000845  ...            0.822600   \n",
      "16       0.970864  0.021419        0.000875  ...            0.815140   \n",
      "17       0.981093  0.020814        0.000845  ...            0.826514   \n",
      "18       0.991209  0.018388        0.019222  ...            0.695556   \n",
      "19       0.995604  0.014872        0.020365  ...            0.703333   \n",
      "20       0.996703  0.008052        0.019530  ...            0.686667   \n",
      "21       0.574138  0.018222        0.003074  ...            0.594470   \n",
      "22       0.573563  0.019570        0.003075  ...            0.595622   \n",
      "23       0.574253  0.018655        0.003073  ...            0.593779   \n",
      "24       0.564228  0.027219        0.002194  ...            0.584528   \n",
      "25       0.564959  0.030768        0.002194  ...            0.585668   \n",
      "26       0.568862  0.028056        0.002196  ...            0.583062   \n",
      "27       0.981072  0.008318        0.000105  ...            0.949765   \n",
      "28       0.979373  0.009326        0.000105  ...            0.947725   \n",
      "29       0.981516  0.006397        0.000104  ...            0.949111   \n",
      "30       0.422286  0.023933        0.007301  ...            0.418286   \n",
      "31       0.427714  0.021100        0.007308  ...            0.417714   \n",
      "32       0.425571  0.020758        0.007304  ...            0.418571   \n",
      "33       0.649000  0.021891        0.001139  ...            0.361423   \n",
      "34       0.628327  0.029759        0.001147  ...            0.354577   \n",
      "35       0.624231  0.028588        0.001152  ...            0.351231   \n",
      "36       0.996154  0.006452        0.010631  ...            0.833333   \n",
      "37       0.995055  0.006646        0.012894  ...            0.793333   \n",
      "38       0.993956  0.005609        0.012289  ...            0.795556   \n",
      "39       0.890436  0.016021        0.000172  ...            0.840650   \n",
      "40       0.893479  0.013860        0.000180  ...            0.833658   \n",
      "41       0.896137  0.018066        0.000176  ...            0.835504   \n",
      "42       0.997600  0.003761        0.008896  ...            0.828226   \n",
      "43       0.996000  0.008000        0.008067  ...            0.846774   \n",
      "44       0.995200  0.007958        0.008553  ...            0.834677   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.008117  0.000749  0.000007      0.363737  0.009084         4.694854   \n",
      "1   0.011408  0.000748  0.000007      0.361842  0.010448         5.754293   \n",
      "2   0.010512  0.000748  0.000008      0.360526  0.009908         5.720444   \n",
      "3   0.018152  0.001961  0.000075      0.561316  0.023361         1.902260   \n",
      "4   0.019652  0.001986  0.000083      0.545175  0.020276         1.059350   \n",
      "5   0.021399  0.002010  0.000083      0.543421  0.020998         1.084677   \n",
      "6   0.011304  0.001001  0.000056      0.736495  0.014067         1.390913   \n",
      "7   0.014193  0.001032  0.000070      0.729712  0.015419         1.597845   \n",
      "8   0.012336  0.001017  0.000061      0.733253  0.016701         2.935291   \n",
      "9   0.037607  0.003903  0.000112      0.427286  0.027584         1.243847   \n",
      "10  0.027104  0.003725  0.000120      0.488857  0.025385         0.719930   \n",
      "11  0.027656  0.003930  0.000105      0.407571  0.025187         0.659128   \n",
      "12  0.005127  0.000096  0.000006      0.900102  0.007216        25.178082   \n",
      "13  0.005194  0.000098  0.000006      0.899287  0.007023        34.973001   \n",
      "14  0.005181  0.000095  0.000007      0.900596  0.006339        31.161435   \n",
      "15  0.018084  0.000883  0.000078      0.830650  0.018407         1.328695   \n",
      "16  0.017080  0.000924  0.000082      0.822821  0.011841         2.289886   \n",
      "17  0.016994  0.000902  0.000071      0.830724  0.017617         2.509690   \n",
      "18  0.062895  0.018665  0.003351      0.721277  0.048272         0.772908   \n",
      "19  0.052128  0.018895  0.003691      0.712766  0.053693         0.492628   \n",
      "20  0.063225  0.017976  0.003063      0.711702  0.060760         0.521661   \n",
      "21  0.022969  0.003120  0.000055      0.578767  0.057068         1.092523   \n",
      "22  0.023539  0.003126  0.000077      0.572146  0.065640         0.520253   \n",
      "23  0.020570  0.003120  0.000059      0.572146  0.065640         0.591032   \n",
      "24  0.024064  0.002216  0.000034      0.581877  0.017620         1.221912   \n",
      "25  0.023336  0.002219  0.000036      0.581877  0.017620         0.678752   \n",
      "26  0.022789  0.002216  0.000033      0.581877  0.017620         0.652276   \n",
      "27  0.007788  0.000108  0.000012      0.949268  0.004612         9.914427   \n",
      "28  0.006307  0.000152  0.000189      0.916048  0.129539         8.996534   \n",
      "29  0.005922  0.000109  0.000011      0.946341  0.007683         7.391606   \n",
      "30  0.027411  0.007414  0.000208      0.431143  0.029749         0.769867   \n",
      "31  0.024378  0.007420  0.000193      0.431143  0.029749         0.576338   \n",
      "32  0.024093  0.007409  0.000188      0.431143  0.029749         0.506153   \n",
      "33  0.012981  0.001133  0.000018      0.376018  0.008129         2.538087   \n",
      "34  0.015583  0.001141  0.000019      0.368178  0.008671         2.552895   \n",
      "35  0.013793  0.001147  0.000018      0.364335  0.007941         2.769433   \n",
      "36  0.056079  0.013491  0.004819      0.822340  0.073145         0.691064   \n",
      "37  0.054956  0.014156  0.003681      0.778723  0.061511         0.526500   \n",
      "38  0.047607  0.014292  0.004372      0.778723  0.065633         1.132021   \n",
      "39  0.008320  0.000174  0.000008      0.840926  0.006553        14.991046   \n",
      "40  0.006630  0.000184  0.000009      0.830537  0.010191        16.036581   \n",
      "41  0.007168  0.000178  0.000009      0.836227  0.008375        16.329451   \n",
      "42  0.052662  0.009476  0.002543      0.815625  0.041988         0.817049   \n",
      "43  0.054508  0.009257  0.003154      0.824219  0.039227         0.943952   \n",
      "44  0.058007  0.009363  0.002485      0.831250  0.041059         0.569658   \n",
      "\n",
      "             total_runtime            \n",
      "         std          mean       std  \n",
      "0   0.467259      5.762523  0.466370  \n",
      "1   1.017785     12.144439  0.992692  \n",
      "2   1.026803     11.933827  1.097245  \n",
      "3   1.147660      3.524610  1.153277  \n",
      "4   0.437176      4.181130  0.443308  \n",
      "5   0.439587      4.435830  0.434639  \n",
      "6   0.062475      1.667321  0.092580  \n",
      "7   0.568944      3.176212  0.569798  \n",
      "8   0.657153      4.490895  0.667898  \n",
      "9   0.929554      1.401990  0.953783  \n",
      "10  0.344647      1.200442  0.356982  \n",
      "11  0.292111      1.074841  0.292682  \n",
      "12  6.666126     34.465526  6.677627  \n",
      "13  6.424645     74.881367  6.502445  \n",
      "14  8.823695     71.554026  8.252343  \n",
      "15  0.077773      1.601305  0.096655  \n",
      "16  0.742953      3.404229  0.739357  \n",
      "17  0.627506      3.567548  0.623033  \n",
      "18  0.638529      0.849436  0.664547  \n",
      "19  0.233471      0.580198  0.243570  \n",
      "20  0.174352      0.604887  0.180995  \n",
      "21  0.870135      1.160867  0.902282  \n",
      "22  0.250520      0.683243  0.266843  \n",
      "23  0.346420      0.738998  0.371781  \n",
      "24  1.048683      1.321162  1.052144  \n",
      "25  0.518103      0.929296  0.508818  \n",
      "26  0.379899      0.885060  0.377392  \n",
      "27  1.512856     14.517559  1.628564  \n",
      "28  2.118871     24.296394  3.079019  \n",
      "29  2.328024     21.944210  2.527672  \n",
      "30  0.585408      0.847775  0.602128  \n",
      "31  0.594458      0.795192  0.624282  \n",
      "32  0.294627      0.685689  0.311057  \n",
      "33  0.338454     10.144574  0.351271  \n",
      "34  0.840339     17.105709  1.154753  \n",
      "35  1.234202     17.821949  1.405803  \n",
      "36  0.358470      0.761059  0.367940  \n",
      "37  0.221884      0.611221  0.226609  \n",
      "38  0.688332      1.230810  0.691337  \n",
      "39  1.209130     22.863843  1.277810  \n",
      "40  1.627836     47.867330  2.388973  \n",
      "41  3.627442     49.468155  3.828699  \n",
      "42  0.474047      0.904370  0.492096  \n",
      "43  0.732008      1.066629  0.769300  \n",
      "44  0.449727      0.679070  0.495018  \n",
      "\n",
      "[45 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"p1_30supernodes_unmerged_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_san.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_san.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAN\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_san_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_san_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAN-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_san_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_san_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAN-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_gps.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_gps_mas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps_mas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS-MAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_gps_tas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps_tas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS-TAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results_exp'+str(exp)+'_unweighted2.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name        method trial best_epoch      train_loss            \\\n",
      "                              count        min  max       mean       std   \n",
      "0         actor      GraphGPS    20         20   22   0.000309  0.000006   \n",
      "1         actor  GraphGPS-MAS    20         20   22   0.000312  0.000004   \n",
      "2         actor  GraphGPS-TAS    20         20   22   0.000313  0.000005   \n",
      "3     chameleon      GraphGPS    20         15   19   0.000318  0.000051   \n",
      "4     chameleon  GraphGPS-MAS    20         15   19   0.000312  0.000048   \n",
      "5     chameleon  GraphGPS-TAS    20         16   19   0.000331  0.000038   \n",
      "6      citeseer      GraphGPS    20         23   24   0.000180  0.000017   \n",
      "7      citeseer  GraphGPS-MAS    20         23   24   0.000199  0.000020   \n",
      "8      citeseer  GraphGPS-TAS    20         23   24   0.000190  0.000018   \n",
      "9     community      GraphGPS    20         17   28   0.001791  0.000039   \n",
      "10    community  GraphGPS-MAS    20         18   33   0.001770  0.000052   \n",
      "11    community  GraphGPS-TAS    20         18   27   0.001814  0.000033   \n",
      "12     computer      GraphGPS    20         57  108   0.000023  0.000003   \n",
      "13     computer  GraphGPS-TAS     2         56   60   0.000029  0.000003   \n",
      "14         cora      GraphGPS    20         29   37   0.000041  0.000017   \n",
      "15         cora  GraphGPS-MAS    20         29   37   0.000050  0.000020   \n",
      "16         cora  GraphGPS-TAS    20         29   37   0.000045  0.000019   \n",
      "17      cornell      GraphGPS    20         10   25   0.001096  0.000877   \n",
      "18      cornell  GraphGPS-MAS    20         13   42   0.000914  0.000716   \n",
      "19      cornell  GraphGPS-TAS    20         12   25   0.001130  0.000688   \n",
      "20        cycle      GraphGPS    20         17  134   0.001529  0.000061   \n",
      "21        cycle  GraphGPS-MAS    20         16  225   0.001544  0.000026   \n",
      "22        cycle  GraphGPS-TAS    20         17  111   0.001579  0.000017   \n",
      "23         grid      GraphGPS    20         13  160   0.001062  0.000045   \n",
      "24         grid  GraphGPS-MAS    20          5   65   0.001113  0.000012   \n",
      "25         grid  GraphGPS-TAS    20          5   67   0.001112  0.000012   \n",
      "26        photo      GraphGPS    20         39   45   0.000024  0.000003   \n",
      "27        photo  GraphGPS-MAS    20         40   72   0.000024  0.000003   \n",
      "28        photo  GraphGPS-TAS    20         39   91   0.000024  0.000005   \n",
      "29        shape      GraphGPS    20         63  111   0.002450  0.000287   \n",
      "30        shape  GraphGPS-MAS    20          5  127   0.003537  0.000182   \n",
      "31        shape  GraphGPS-TAS    20         18  170   0.003539  0.000194   \n",
      "32     squirrel      GraphGPS    20         12   17   0.000386  0.000039   \n",
      "33     squirrel  GraphGPS-MAS    20         12   17   0.000392  0.000037   \n",
      "34     squirrel  GraphGPS-TAS    20         12   17   0.000419  0.000036   \n",
      "35        texas      GraphGPS    20         14   63   0.000272  0.000345   \n",
      "36        texas  GraphGPS-MAS    20         13   33   0.000570  0.000621   \n",
      "37        texas  GraphGPS-TAS    20         13   47   0.000748  0.000620   \n",
      "38         wiki      GraphGPS    20         64  104   0.000063  0.000004   \n",
      "39         wiki  GraphGPS-MAS    20         54   99   0.000066  0.000005   \n",
      "40         wiki  GraphGPS-TAS    20         60  107   0.000064  0.000005   \n",
      "41    wisconsin      GraphGPS    20         16  114   0.000305  0.000307   \n",
      "42    wisconsin  GraphGPS-MAS    20         17   70   0.000276  0.000290   \n",
      "43    wisconsin  GraphGPS-TAS    20         13   65   0.000434  0.000629   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.528368  0.013031        0.000765  ...            0.343947   \n",
      "1        0.520763  0.010342        0.000764  ...            0.345579   \n",
      "2        0.520053  0.012136        0.000764  ...            0.344500   \n",
      "3        0.919640  0.015562        0.001982  ...            0.547364   \n",
      "4        0.912961  0.016798        0.001971  ...            0.543058   \n",
      "5        0.910413  0.013383        0.002018  ...            0.534974   \n",
      "6        0.915454  0.010539        0.000924  ...            0.747292   \n",
      "7        0.909140  0.009516        0.000960  ...            0.735740   \n",
      "8        0.914672  0.008575        0.000936  ...            0.742058   \n",
      "9        0.448071  0.020563        0.003824  ...            0.416714   \n",
      "10       0.479571  0.021296        0.003805  ...            0.429857   \n",
      "11       0.437429  0.017469        0.003845  ...            0.406857   \n",
      "12       0.949527  0.006796        0.000092  ...            0.900684   \n",
      "13       0.935428  0.003085        0.000090  ...            0.901687   \n",
      "14       0.988774  0.007960        0.000740  ...            0.842097   \n",
      "15       0.985561  0.009273        0.000757  ...            0.835081   \n",
      "16       0.987075  0.009307        0.000718  ...            0.843575   \n",
      "17       0.984615  0.018663        0.020012  ...            0.685556   \n",
      "18       0.991209  0.012143        0.020180  ...            0.665556   \n",
      "19       0.987363  0.012491        0.020697  ...            0.674444   \n",
      "20       0.559770  0.033259        0.002980  ...            0.586175   \n",
      "21       0.571494  0.012949        0.003025  ...            0.594009   \n",
      "22       0.571149  0.024832        0.003073  ...            0.600000   \n",
      "23       0.647967  0.057685        0.002114  ...            0.653909   \n",
      "24       0.574553  0.021333        0.002197  ...            0.582085   \n",
      "25       0.577398  0.020452        0.002197  ...            0.584853   \n",
      "26       0.975961  0.003234        0.000099  ...            0.947280   \n",
      "27       0.974797  0.003558        0.000098  ...            0.948117   \n",
      "28       0.974771  0.005514        0.000099  ...            0.947960   \n",
      "29       0.643857  0.083759        0.005027  ...            0.640857   \n",
      "30       0.417714  0.032253        0.007026  ...            0.418286   \n",
      "31       0.414429  0.037717        0.007099  ...            0.394857   \n",
      "32       0.645423  0.057314        0.001160  ...            0.343385   \n",
      "33       0.637096  0.052803        0.001158  ...            0.343269   \n",
      "34       0.600154  0.052478        0.001161  ...            0.336077   \n",
      "35       0.996703  0.005167        0.012903  ...            0.773333   \n",
      "36       0.992857  0.010858        0.015110  ...            0.748889   \n",
      "37       0.991758  0.007018        0.014887  ...            0.730000   \n",
      "38       0.876453  0.008654        0.000184  ...            0.826085   \n",
      "39       0.872325  0.008702        0.000186  ...            0.827521   \n",
      "40       0.874701  0.009466        0.000185  ...            0.828017   \n",
      "41       0.992000  0.010052        0.009579  ...            0.801613   \n",
      "42       0.990800  0.012250        0.008474  ...            0.832258   \n",
      "43       0.988400  0.018257        0.009477  ...            0.808871   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.008880  0.000766  0.000007      0.347263  0.008088         4.794476   \n",
      "1   0.008593  0.000764  0.000007      0.346026  0.009522         7.725994   \n",
      "2   0.009727  0.000765  0.000007      0.343947  0.007481         7.733786   \n",
      "3   0.016550  0.001954  0.000068      0.557632  0.023408         3.108937   \n",
      "4   0.020912  0.001940  0.000067      0.559912  0.019051         1.264891   \n",
      "5   0.018898  0.001973  0.000062      0.552807  0.017506         1.259990   \n",
      "6   0.013575  0.000955  0.000049      0.737155  0.019766         1.387820   \n",
      "7   0.013712  0.000993  0.000047      0.725330  0.014287         2.310963   \n",
      "8   0.013860  0.000972  0.000046      0.732113  0.017094         1.383503   \n",
      "9   0.018890  0.003831  0.000095      0.414429  0.019718         1.048081   \n",
      "10  0.017624  0.003853  0.000128      0.437429  0.020243         0.757401   \n",
      "11  0.019541  0.003843  0.000095      0.405857  0.024586         0.702020   \n",
      "12  0.004629  0.000098  0.000009      0.892234  0.011233        22.086822   \n",
      "13  0.003291  0.000102  0.000001      0.889761  0.008638        51.235978   \n",
      "14  0.012814  0.000741  0.000055      0.843575  0.011893         1.406583   \n",
      "15  0.014040  0.000755  0.000058      0.839069  0.014349         2.218862   \n",
      "16  0.010885  0.000725  0.000056      0.846455  0.011366         2.153744   \n",
      "17  0.092408  0.019354  0.002644      0.686170  0.048260         0.962354   \n",
      "18  0.071547  0.019748  0.003233      0.656383  0.062614         0.469945   \n",
      "19  0.082921  0.019403  0.001565      0.668085  0.043330         0.513385   \n",
      "20  0.037276  0.003135  0.000235      0.551370  0.075829         1.390783   \n",
      "21  0.017621  0.003059  0.000051      0.572831  0.036694         0.824993   \n",
      "22  0.019414  0.003093  0.000054      0.592694  0.027261         0.598135   \n",
      "23  0.049815  0.002207  0.000099      0.592395  0.073712         1.496963   \n",
      "24  0.025278  0.002222  0.000031      0.580583  0.017862         0.618990   \n",
      "25  0.022455  0.002216  0.000032      0.581877  0.017620         0.559317   \n",
      "26  0.007242  0.000102  0.000008      0.947073  0.004991         9.626851   \n",
      "27  0.006913  0.000101  0.000010      0.948275  0.006470         8.874264   \n",
      "28  0.005655  0.000102  0.000009      0.947622  0.005954         6.538626   \n",
      "29  0.079705  0.005793  0.001131      0.531714  0.109736         1.310749   \n",
      "30  0.036026  0.007237  0.000522      0.421143  0.046427         1.236724   \n",
      "31  0.039193  0.008228  0.002186      0.404000  0.056602         1.176299   \n",
      "32  0.016317  0.001158  0.000022      0.352921  0.014154         3.139328   \n",
      "33  0.017195  0.001155  0.000022      0.356879  0.015393         3.611739   \n",
      "34  0.015107  0.001157  0.000020      0.348847  0.017055         4.164265   \n",
      "35  0.067094  0.015129  0.003787      0.777660  0.055857         1.015619   \n",
      "36  0.070679  0.016121  0.003280      0.745745  0.051876         0.406876   \n",
      "37  0.075022  0.016933  0.003530      0.731915  0.064903         0.402081   \n",
      "38  0.006589  0.000187  0.000011      0.826179  0.010158        16.557678   \n",
      "39  0.007349  0.000189  0.000007      0.824761  0.007495        16.672542   \n",
      "40  0.007612  0.000187  0.000007      0.826384  0.007157        22.456491   \n",
      "41  0.048838  0.010891  0.002757      0.778906  0.038029         0.810181   \n",
      "42  0.046629  0.009234  0.002004      0.811719  0.028889         0.476371   \n",
      "43  0.056669  0.011085  0.002794      0.774219  0.052799         0.456393   \n",
      "\n",
      "              total_runtime             \n",
      "          std          mean        std  \n",
      "0    0.519261      5.917491   0.595191  \n",
      "1    5.370164     14.402790   5.340981  \n",
      "2    5.486383     14.250332   5.491999  \n",
      "3    5.688432      4.914865   5.706740  \n",
      "4    0.559711      4.515689   0.549959  \n",
      "5    0.523562      4.744101   0.555809  \n",
      "6    0.056105      1.673361   0.117404  \n",
      "7    0.561011      3.914391   0.583005  \n",
      "8    0.061162      2.963556   0.125422  \n",
      "9    1.005921      1.213379   1.050932  \n",
      "10   0.383189      1.247235   0.376040  \n",
      "11   0.333968      1.124208   0.356656  \n",
      "12   2.941198     31.932416   2.919923  \n",
      "13   0.735278     91.965204   1.920199  \n",
      "14   0.101359      1.674496   0.137164  \n",
      "15   0.695764      3.375991   0.711316  \n",
      "16   0.614528      3.187226   0.623207  \n",
      "17   0.812051      1.038334   0.844039  \n",
      "18   0.247213      0.559242   0.280294  \n",
      "19   0.271820      0.599342   0.291328  \n",
      "20   1.234441      1.454117   1.249697  \n",
      "21   0.616889      0.986730   0.621528  \n",
      "22   0.326418      0.750565   0.350557  \n",
      "23   1.263128      1.594216   1.274832  \n",
      "24   0.270799      0.874772   0.278067  \n",
      "25   0.270036      0.808712   0.292268  \n",
      "26   1.702372     14.159028   1.940449  \n",
      "27   1.908016     23.560982   1.979681  \n",
      "28   0.959449     21.118257   1.147694  \n",
      "29   0.832682      1.394346   0.852562  \n",
      "30   1.000438      1.472426   1.016118  \n",
      "31   1.329179      1.374704   1.326620  \n",
      "32   0.431552     10.905354   0.430276  \n",
      "33   1.516896     18.461261   1.483071  \n",
      "34   1.517345     19.050514   1.335102  \n",
      "35   0.918118      1.091139   0.938964  \n",
      "36   0.085925      0.491476   0.106206  \n",
      "37   0.078151      0.491805   0.135249  \n",
      "38   1.338182     24.557146   1.401833  \n",
      "39   1.249696     47.607354   1.500023  \n",
      "40  17.299876     55.879876  17.331935  \n",
      "41   0.794282      0.900094   0.836945  \n",
      "42   0.083865      0.582911   0.105484  \n",
      "43   0.094393      0.557253   0.124714  \n",
      "\n",
      "[44 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"p1_30supernodes_unmerged_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        # if dataset+\"_san.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_san.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag5 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"SAN\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_san_mas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_san_mas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag5 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"SAN-MAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_san_tas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_san_tas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag5 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"SAN-TAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results_exp'+str(exp)+'_gps_noconcat.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset_name         method trial best_epoch       train_loss  \\\n",
      "                                count        min   max       mean   \n",
      "0          actor            GAT    20         25    33   0.000390   \n",
      "1          actor        GAT-MAS    20         13    36   0.000406   \n",
      "2          actor        GAT-TAS    20         25    36   0.000403   \n",
      "3          actor            GCN    20         57    68   0.000372   \n",
      "4          actor        GCN-MAS    20         62    73   0.000390   \n",
      "5          actor        GCN-TAS    20         60    69   0.000391   \n",
      "6          actor      GraphSAGE    20         51    54   0.000294   \n",
      "7          actor  GraphSAGE-MAS    20         54    57   0.000294   \n",
      "8          actor  GraphSAGE-TAS    20         53    56   0.000294   \n",
      "9      chameleon            GAT    20         31    49   0.000733   \n",
      "10     chameleon        GAT-MAS    20         38    58   0.000781   \n",
      "11     chameleon        GAT-TAS    20         37    62   0.000779   \n",
      "12     chameleon            GCN    20         66    91   0.000723   \n",
      "13     chameleon        GCN-MAS    20         89   128   0.000696   \n",
      "14     chameleon        GCN-TAS    20         83   150   0.000697   \n",
      "15     chameleon      GraphSAGE    20         51    57   0.000255   \n",
      "16     chameleon  GraphSAGE-MAS    20         52    57   0.000308   \n",
      "17     chameleon  GraphSAGE-TAS    20         52    57   0.000314   \n",
      "18      citeseer            GAT    20         66    73   0.000270   \n",
      "19      citeseer        GAT-MAS    20         67    78   0.000366   \n",
      "20      citeseer        GAT-TAS    20         62    76   0.000322   \n",
      "21      citeseer            GCN    20        109   117   0.000229   \n",
      "22      citeseer        GCN-MAS    20        110   118   0.000318   \n",
      "23      citeseer        GCN-TAS    20        109   118   0.000273   \n",
      "24      citeseer      GraphSAGE    20         87    96   0.000188   \n",
      "25      citeseer  GraphSAGE-MAS    20         88    98   0.000223   \n",
      "26      citeseer  GraphSAGE-TAS    20         90   100   0.000200   \n",
      "27     community            GAT    20        102   182   0.000925   \n",
      "28     community        GAT-MAS    20         63   147   0.001515   \n",
      "29     community        GAT-TAS    20         74   173   0.001234   \n",
      "30     community            GCN    20        167   229   0.001046   \n",
      "31     community        GCN-MAS    20        153   204   0.001439   \n",
      "32     community        GCN-TAS    20        149   209   0.001435   \n",
      "33     community      GraphSAGE    20         99   144   0.000736   \n",
      "34     community  GraphSAGE-MAS    20         72   107   0.001209   \n",
      "35     community  GraphSAGE-TAS    20         59   108   0.001337   \n",
      "36      computer            GCN    20        118   243   0.000038   \n",
      "37      computer        GCN-MAS    20        124   250   0.000047   \n",
      "38      computer        GCN-TAS    20        139   258   0.000044   \n",
      "39      computer      GraphSAGE    20         88   155   0.000023   \n",
      "40      computer  GraphSAGE-MAS    20         94   154   0.000024   \n",
      "41      computer  GraphSAGE-TAS    20         90   156   0.000025   \n",
      "42          cora            GAT    20         78   100   0.000153   \n",
      "43          cora        GAT-MAS    20         78   102   0.000242   \n",
      "44          cora        GAT-TAS    20         78   102   0.000186   \n",
      "45          cora            GCN    20        136   157   0.000126   \n",
      "46          cora        GCN-MAS    20        133   165   0.000206   \n",
      "47          cora        GCN-TAS    20        137   150   0.000165   \n",
      "48          cora      GraphSAGE    20         99   127   0.000071   \n",
      "49          cora  GraphSAGE-MAS    20        104   132   0.000093   \n",
      "50          cora  GraphSAGE-TAS    20         99   124   0.000078   \n",
      "51       cornell            GAT    20          3    15   0.010514   \n",
      "52       cornell        GAT-MAS    20          4    22   0.012469   \n",
      "53       cornell        GAT-TAS    20          4    17   0.013410   \n",
      "54       cornell            GCN    20          8    32   0.009611   \n",
      "55       cornell        GCN-MAS    20          7    34   0.011918   \n",
      "56       cornell        GCN-TAS    20          7    34   0.012152   \n",
      "57       cornell      GraphSAGE    20         21    39   0.002134   \n",
      "58       cornell  GraphSAGE-MAS    20         24    36   0.002704   \n",
      "59       cornell  GraphSAGE-TAS    20         23    63   0.001609   \n",
      "60         cycle            GAT    20         11   129   0.001565   \n",
      "61         cycle        GAT-MAS    20         11   115   0.001565   \n",
      "62         cycle        GAT-TAS    20         10    69   0.001563   \n",
      "63         cycle            GCN    20         20   649   0.001528   \n",
      "64         cycle        GCN-MAS    20         30   466   0.001551   \n",
      "65         cycle        GCN-TAS    20         26   107   0.001563   \n",
      "66         cycle      GraphSAGE    20          5   115   0.001578   \n",
      "67         cycle  GraphSAGE-MAS    20          5   104   0.001577   \n",
      "68         cycle  GraphSAGE-TAS    20          5   115   0.001575   \n",
      "69          grid            GAT    20         10   196   0.001103   \n",
      "70          grid        GAT-MAS    20          7   137   0.001102   \n",
      "71          grid        GAT-TAS    20          7    74   0.001102   \n",
      "72          grid            GCN    20          8   895   0.001079   \n",
      "73          grid        GCN-MAS    20          9    88   0.001102   \n",
      "74          grid        GCN-TAS    20          8   103   0.001102   \n",
      "75          grid      GraphSAGE    20          9   111   0.001110   \n",
      "76          grid  GraphSAGE-MAS    20          8   114   0.001111   \n",
      "77          grid  GraphSAGE-TAS    20          9   119   0.001109   \n",
      "78         photo            GAT    20         74   116   0.000028   \n",
      "79         photo        GAT-MAS    20         82   119   0.000043   \n",
      "80         photo        GAT-TAS    20         79   137   0.000041   \n",
      "81         photo            GCN    20        128   241   0.000037   \n",
      "82         photo        GCN-MAS    20        111   211   0.000060   \n",
      "83         photo        GCN-TAS    20        118   211   0.000052   \n",
      "84         photo      GraphSAGE    20         89   131   0.000011   \n",
      "85         photo  GraphSAGE-MAS    20         89   129   0.000014   \n",
      "86         photo  GraphSAGE-TAS    20         86   114   0.000013   \n",
      "87        pubmed            GAT    20        111   194   0.000031   \n",
      "88        pubmed        GAT-MAS    20        118   161   0.000040   \n",
      "89        pubmed        GAT-TAS    20        112   161   0.000037   \n",
      "90        pubmed            GCN    20        208   275   0.000029   \n",
      "91        pubmed        GCN-MAS    20        203   239   0.000039   \n",
      "92        pubmed        GCN-TAS    20        185   229   0.000036   \n",
      "93        pubmed      GraphSAGE    20        146   180   0.000023   \n",
      "94        pubmed  GraphSAGE-MAS    20        161   190   0.000024   \n",
      "95        pubmed  GraphSAGE-TAS    20        161   190   0.000023   \n",
      "96         shape            GAT    20         23   128   0.003677   \n",
      "97         shape        GAT-MAS    20         14   150   0.003673   \n",
      "98         shape        GAT-TAS    20         15    99   0.003685   \n",
      "99         shape            GCN    20         36  1045   0.001134   \n",
      "100        shape        GCN-MAS    20         41   893   0.002808   \n",
      "101        shape        GCN-TAS    20         38   893   0.002390   \n",
      "102        shape      GraphSAGE    20         10   110   0.003704   \n",
      "103        shape  GraphSAGE-MAS    20         10   121   0.003702   \n",
      "104        shape  GraphSAGE-TAS    20         10   173   0.003695   \n",
      "105     squirrel        GAT-MAS    20         20    63   0.000520   \n",
      "106     squirrel            GCN    20         57    72   0.000480   \n",
      "107     squirrel        GCN-MAS    20         67   293   0.000460   \n",
      "108     squirrel        GCN-TAS    20         85   231   0.000441   \n",
      "109     squirrel      GraphSAGE    20         42    47   0.000315   \n",
      "110     squirrel  GraphSAGE-MAS    20         41    46   0.000357   \n",
      "111     squirrel  GraphSAGE-TAS    20         41    46   0.000358   \n",
      "112        texas            GAT    20          6    18   0.010210   \n",
      "113        texas        GAT-MAS    20          5    20   0.011460   \n",
      "114        texas        GAT-TAS    20          6    21   0.010331   \n",
      "115        texas            GCN    20         10    31   0.008787   \n",
      "116        texas        GCN-MAS    20         13    35   0.010882   \n",
      "117        texas        GCN-TAS    20         15    31   0.009182   \n",
      "118        texas      GraphSAGE    20         24    50   0.000607   \n",
      "119        texas  GraphSAGE-MAS    20         32    62   0.000640   \n",
      "120        texas  GraphSAGE-TAS    20         26    81   0.000546   \n",
      "121         wiki            GCN    20        231   344   0.000076   \n",
      "122         wiki        GCN-MAS    20        231   364   0.000101   \n",
      "123         wiki        GCN-TAS    20        252   405   0.000091   \n",
      "124         wiki      GraphSAGE    20        157   187   0.000053   \n",
      "125         wiki  GraphSAGE-MAS    20        152   199   0.000057   \n",
      "126         wiki  GraphSAGE-TAS    20        152   186   0.000055   \n",
      "127    wisconsin            GAT    20          4    21   0.008134   \n",
      "128    wisconsin        GAT-MAS    20          5    25   0.007800   \n",
      "129    wisconsin        GAT-TAS    20          5    22   0.008450   \n",
      "130    wisconsin            GCN    20         18    40   0.006498   \n",
      "131    wisconsin        GCN-MAS    20         17    42   0.006534   \n",
      "132    wisconsin        GCN-TAS    20         15    35   0.007566   \n",
      "133    wisconsin      GraphSAGE    20         23    45   0.001222   \n",
      "134    wisconsin  GraphSAGE-MAS    20         28    45   0.000638   \n",
      "135    wisconsin  GraphSAGE-TAS    20         24    48   0.000949   \n",
      "\n",
      "                  train_accuracy           validation_loss  ...  \\\n",
      "              std           mean       std            mean  ...   \n",
      "0    3.839636e-06       0.374000  0.010952        0.000815  ...   \n",
      "1    2.673905e-06       0.308500  0.020297        0.000824  ...   \n",
      "2    2.663233e-06       0.328053  0.016575        0.000823  ...   \n",
      "3    5.101309e-06       0.429474  0.011059        0.000807  ...   \n",
      "4    2.056467e-06       0.371092  0.007269        0.000820  ...   \n",
      "5    3.517813e-06       0.377000  0.010221        0.000819  ...   \n",
      "6    3.778197e-06       0.618092  0.006192        0.000752  ...   \n",
      "7    3.809833e-06       0.593750  0.009234        0.000738  ...   \n",
      "8    4.398872e-06       0.594908  0.010595        0.000738  ...   \n",
      "9    6.230383e-05       0.680185  0.026744        0.002024  ...   \n",
      "10   5.160091e-05       0.636511  0.026133        0.002024  ...   \n",
      "11   6.714324e-05       0.649077  0.033798        0.002070  ...   \n",
      "12   6.114215e-05       0.707733  0.027809        0.002095  ...   \n",
      "13   4.447308e-05       0.698638  0.019958        0.001981  ...   \n",
      "14   6.933741e-05       0.714455  0.025751        0.002022  ...   \n",
      "15   3.032894e-05       0.956459  0.008836        0.001750  ...   \n",
      "16   2.863413e-05       0.933392  0.009121        0.001803  ...   \n",
      "17   2.299246e-05       0.927900  0.009254        0.001842  ...   \n",
      "18   1.756342e-05       0.862237  0.008058        0.000919  ...   \n",
      "19   2.208335e-05       0.800481  0.009993        0.001082  ...   \n",
      "20   2.881136e-05       0.830367  0.012900        0.001010  ...   \n",
      "21   9.598179e-06       0.882231  0.004929        0.000893  ...   \n",
      "22   1.257626e-05       0.822099  0.007248        0.001022  ...   \n",
      "23   1.317444e-05       0.856885  0.006438        0.000960  ...   \n",
      "24   1.683739e-05       0.910884  0.008997        0.000880  ...   \n",
      "25   2.624847e-05       0.891612  0.017786        0.000996  ...   \n",
      "26   2.073735e-05       0.907517  0.012628        0.000929  ...   \n",
      "27   7.717937e-05       0.728500  0.021963        0.002773  ...   \n",
      "28   1.036118e-04       0.597786  0.024528        0.003825  ...   \n",
      "29   1.136862e-04       0.647571  0.025063        0.003336  ...   \n",
      "30   5.791721e-05       0.729429  0.016708        0.003108  ...   \n",
      "31   5.532625e-05       0.620643  0.016804        0.003719  ...   \n",
      "32   7.433959e-05       0.606857  0.022958        0.003702  ...   \n",
      "33   1.738038e-04       0.883571  0.047990        0.003622  ...   \n",
      "34   1.086841e-04       0.704571  0.038625        0.003486  ...   \n",
      "35   1.545492e-04       0.662214  0.065824        0.003805  ...   \n",
      "36   2.494432e-06       0.923437  0.005121        0.000100  ...   \n",
      "37   2.271253e-06       0.898320  0.004593        0.000109  ...   \n",
      "38   1.892236e-06       0.904268  0.004208        0.000104  ...   \n",
      "39   5.094202e-06       0.953461  0.011258        0.000089  ...   \n",
      "40   3.877778e-06       0.949985  0.009020        0.000091  ...   \n",
      "41   4.171540e-06       0.947579  0.010322        0.000090  ...   \n",
      "42   2.631756e-05       0.940436  0.009912        0.000622  ...   \n",
      "43   2.973572e-05       0.890916  0.014461        0.000821  ...   \n",
      "44   2.780908e-05       0.921123  0.009887        0.000701  ...   \n",
      "45   1.164836e-05       0.955207  0.005202        0.000575  ...   \n",
      "46   1.764949e-05       0.907533  0.008299        0.000731  ...   \n",
      "47   1.222693e-05       0.932422  0.005414        0.000635  ...   \n",
      "48   1.970493e-05       0.985340  0.007544        0.000566  ...   \n",
      "49   2.406521e-05       0.979616  0.010837        0.000692  ...   \n",
      "50   2.114324e-05       0.983900  0.009803        0.000605  ...   \n",
      "51   2.142001e-03       0.662637  0.081777        0.031007  ...   \n",
      "52   2.543565e-03       0.584615  0.107941        0.030940  ...   \n",
      "53   2.125006e-03       0.531319  0.091475        0.031351  ...   \n",
      "54   2.411629e-03       0.720330  0.107343        0.030192  ...   \n",
      "55   1.727851e-03       0.596154  0.071739        0.030147  ...   \n",
      "56   2.170276e-03       0.573626  0.091010        0.030869  ...   \n",
      "57   1.263544e-03       0.966484  0.028405        0.022175  ...   \n",
      "58   1.338676e-03       0.962637  0.022379        0.025031  ...   \n",
      "59   1.251887e-03       0.984615  0.019000        0.022377  ...   \n",
      "60   1.275695e-05       0.581379  0.014325        0.003094  ...   \n",
      "61   1.234140e-05       0.581379  0.014325        0.003096  ...   \n",
      "62   1.247550e-05       0.581379  0.014325        0.003096  ...   \n",
      "63   1.734667e-04       0.596092  0.069472        0.003035  ...   \n",
      "64   1.489983e-05       0.581149  0.014397        0.003086  ...   \n",
      "65   1.064309e-05       0.581379  0.014325        0.003111  ...   \n",
      "66   1.477217e-05       0.567586  0.019102        0.003059  ...   \n",
      "67   1.729390e-05       0.570920  0.023304        0.003067  ...   \n",
      "68   1.673441e-05       0.571264  0.020364        0.003064  ...   \n",
      "69   7.796274e-06       0.590325  0.009532        0.002203  ...   \n",
      "70   6.973012e-06       0.590000  0.009232        0.002205  ...   \n",
      "71   6.994947e-06       0.590000  0.009232        0.002205  ...   \n",
      "72   9.358989e-05       0.602358  0.056088        0.002169  ...   \n",
      "73   4.609914e-06       0.590000  0.009232        0.002212  ...   \n",
      "74   4.833729e-06       0.590000  0.009232        0.002213  ...   \n",
      "75   1.084476e-05       0.586829  0.012726        0.002188  ...   \n",
      "76   8.898786e-06       0.579268  0.011239        0.002192  ...   \n",
      "77   1.219412e-05       0.580976  0.011426        0.002191  ...   \n",
      "78   5.623931e-06       0.968314  0.006315        0.000102  ...   \n",
      "79   5.162166e-06       0.950536  0.006027        0.000131  ...   \n",
      "80   6.195039e-06       0.953425  0.007592        0.000121  ...   \n",
      "81   3.241884e-06       0.956562  0.003868        0.000110  ...   \n",
      "82   3.104496e-06       0.927817  0.004074        0.000141  ...   \n",
      "83   2.674165e-06       0.937203  0.003433        0.000128  ...   \n",
      "84   3.290350e-06       0.992052  0.003662        0.000088  ...   \n",
      "85   3.899090e-06       0.988222  0.004702        0.000093  ...   \n",
      "86   2.557674e-06       0.988654  0.002745        0.000092  ...   \n",
      "87   1.982421e-06       0.886209  0.007179        0.000078  ...   \n",
      "88   1.192614e-06       0.847920  0.004786        0.000089  ...   \n",
      "89   1.018828e-06       0.859297  0.004138        0.000084  ...   \n",
      "90   8.123527e-07       0.897058  0.003618        0.000072  ...   \n",
      "91   5.085475e-07       0.849990  0.002463        0.000086  ...   \n",
      "92   5.517885e-07       0.862112  0.002743        0.000082  ...   \n",
      "93   9.268030e-07       0.917955  0.003531        0.000069  ...   \n",
      "94   8.166662e-07       0.914597  0.003554        0.000068  ...   \n",
      "95   9.232355e-07       0.917701  0.003565        0.000067  ...   \n",
      "96   6.348731e-05       0.431857  0.017374        0.007333  ...   \n",
      "97   4.378031e-05       0.431857  0.017374        0.007348  ...   \n",
      "98   5.457678e-05       0.431857  0.017374        0.007353  ...   \n",
      "99   5.928385e-04       0.890143  0.100283        0.002200  ...   \n",
      "100  1.903829e-04       0.570000  0.031809        0.005724  ...   \n",
      "101  5.443306e-04       0.602429  0.069116        0.004768  ...   \n",
      "102  6.057488e-05       0.431143  0.018020        0.007313  ...   \n",
      "103  4.410342e-05       0.429286  0.016449        0.007321  ...   \n",
      "104  5.380636e-05       0.430286  0.016200        0.007318  ...   \n",
      "105  3.231537e-05       0.414538  0.041896        0.001162  ...   \n",
      "106  1.367681e-05       0.504250  0.019420        0.001118  ...   \n",
      "107  3.774354e-05       0.517250  0.055421        0.001128  ...   \n",
      "108  2.343842e-05       0.552692  0.031188        0.001117  ...   \n",
      "109  1.157094e-05       0.769423  0.010046        0.001010  ...   \n",
      "110  1.396375e-05       0.718385  0.011687        0.001035  ...   \n",
      "111  1.407798e-05       0.721808  0.011459        0.001046  ...   \n",
      "112  2.370936e-03       0.671978  0.105480        0.026227  ...   \n",
      "113  1.771284e-03       0.608791  0.067024        0.026419  ...   \n",
      "114  1.672418e-03       0.646703  0.072392        0.025793  ...   \n",
      "115  1.819064e-03       0.760440  0.081660        0.027645  ...   \n",
      "116  1.053891e-03       0.615934  0.039778        0.027214  ...   \n",
      "117  1.104122e-03       0.708242  0.060660        0.026137  ...   \n",
      "118  7.405295e-04       0.992857  0.013934        0.013481  ...   \n",
      "119  3.452452e-04       0.994505  0.007563        0.017019  ...   \n",
      "120  7.060026e-04       0.996154  0.008931        0.015395  ...   \n",
      "121  3.875422e-06       0.864222  0.005492        0.000197  ...   \n",
      "122  2.338483e-06       0.811128  0.005043        0.000233  ...   \n",
      "123  2.712804e-06       0.832547  0.005153        0.000218  ...   \n",
      "124  3.142143e-06       0.899872  0.006453        0.000167  ...   \n",
      "125  4.566879e-06       0.891607  0.009629        0.000177  ...   \n",
      "126  3.713690e-06       0.895641  0.007745        0.000172  ...   \n",
      "127  1.620164e-03       0.613200  0.089246        0.020077  ...   \n",
      "128  1.553380e-03       0.618800  0.083675        0.020048  ...   \n",
      "129  1.303838e-03       0.581600  0.069651        0.019811  ...   \n",
      "130  1.122864e-03       0.724400  0.056953        0.020051  ...   \n",
      "131  1.275577e-03       0.710400  0.058073        0.019554  ...   \n",
      "132  1.050579e-03       0.643200  0.042838        0.019683  ...   \n",
      "133  6.060917e-04       0.970800  0.019122        0.011999  ...   \n",
      "134  3.674933e-04       0.989600  0.008647        0.011131  ...   \n",
      "135  6.869115e-04       0.975200  0.023632        0.011115  ...   \n",
      "\n",
      "    validation_accuracy           test_loss           test_accuracy            \\\n",
      "                   mean       std      mean       std          mean       std   \n",
      "0              0.287132  0.008266  0.000814  0.000004      0.288500  0.009540   \n",
      "1              0.267474  0.011262  0.000824  0.000003      0.270368  0.010380   \n",
      "2              0.270842  0.008799  0.000823  0.000003      0.275105  0.010827   \n",
      "3              0.300368  0.007351  0.000808  0.000004      0.295921  0.009130   \n",
      "4              0.280211  0.010690  0.000820  0.000004      0.282711  0.008789   \n",
      "5              0.279316  0.007769  0.000819  0.000003      0.283079  0.007237   \n",
      "6              0.345632  0.007351  0.000752  0.000006      0.345684  0.010341   \n",
      "7              0.353421  0.008272  0.000739  0.000007      0.352816  0.011951   \n",
      "8              0.352474  0.008223  0.000739  0.000006      0.352947  0.010790   \n",
      "9              0.576801  0.033572  0.002013  0.000100      0.586316  0.025712   \n",
      "10             0.553603  0.027405  0.002041  0.000086      0.549298  0.029702   \n",
      "11             0.555185  0.024821  0.002062  0.000083      0.556053  0.019298   \n",
      "12             0.563972  0.026321  0.002087  0.000088      0.572982  0.026730   \n",
      "13             0.593409  0.021960  0.001997  0.000084      0.591316  0.023692   \n",
      "14             0.599385  0.022826  0.002028  0.000090      0.598509  0.024917   \n",
      "15             0.639895  0.016574  0.001760  0.000053      0.643596  0.015950   \n",
      "16             0.601845  0.018890  0.001800  0.000063      0.608070  0.018262   \n",
      "17             0.595343  0.020879  0.001824  0.000060      0.599474  0.020891   \n",
      "18             0.751023  0.012475  0.000880  0.000042      0.757743  0.013696   \n",
      "19             0.691998  0.011716  0.001066  0.000046      0.696819  0.016108   \n",
      "20             0.723406  0.015442  0.000983  0.000039      0.721489  0.016111   \n",
      "21             0.755656  0.013617  0.000884  0.000043      0.756963  0.014148   \n",
      "22             0.705235  0.008277  0.001017  0.000044      0.708583  0.017496   \n",
      "23             0.731408  0.013988  0.000957  0.000039      0.732413  0.012823   \n",
      "24             0.756558  0.013361  0.000871  0.000042      0.758824  0.014374   \n",
      "25             0.717028  0.011857  0.000991  0.000044      0.723049  0.016387   \n",
      "26             0.742298  0.015263  0.000926  0.000041      0.740576  0.014599   \n",
      "27             0.587714  0.028513  0.002706  0.000159      0.591571  0.026439   \n",
      "28             0.495429  0.029143  0.003787  0.000211      0.494857  0.027083   \n",
      "29             0.517857  0.023540  0.003210  0.000151      0.517286  0.030428   \n",
      "30             0.563000  0.021808  0.003172  0.000137      0.556143  0.018890   \n",
      "31             0.497857  0.023704  0.003729  0.000163      0.503857  0.025408   \n",
      "32             0.474714  0.020546  0.003672  0.000133      0.475857  0.021590   \n",
      "33             0.519571  0.019451  0.003658  0.000153      0.520857  0.020584   \n",
      "34             0.525000  0.019017  0.003504  0.000121      0.519286  0.025384   \n",
      "35             0.440714  0.023722  0.003806  0.000100      0.446571  0.020813   \n",
      "36             0.903650  0.005638  0.000099  0.000007      0.901876  0.006006   \n",
      "37             0.883086  0.004722  0.000109  0.000006      0.882635  0.006949   \n",
      "38             0.890489  0.004982  0.000104  0.000007      0.889194  0.007123   \n",
      "39             0.904203  0.005421  0.000092  0.000010      0.901062  0.011075   \n",
      "40             0.901702  0.003454  0.000094  0.000008      0.899360  0.007896   \n",
      "41             0.901963  0.005019  0.000092  0.000006      0.899898  0.007841   \n",
      "42             0.865731  0.012514  0.000579  0.000039      0.873634  0.010058   \n",
      "43             0.815731  0.014932  0.000767  0.000038      0.825775  0.010373   \n",
      "44             0.844756  0.012615  0.000659  0.000037      0.854210  0.008547   \n",
      "45             0.874594  0.010618  0.000633  0.000320      0.869276  0.046125   \n",
      "46             0.828656  0.013212  0.000700  0.000034      0.835672  0.010476   \n",
      "47             0.856278  0.011982  0.000748  0.000500      0.833973  0.126399   \n",
      "48             0.875702  0.009516  0.000556  0.000035      0.880945  0.008868   \n",
      "49             0.839956  0.013506  0.000668  0.000040      0.847046  0.009920   \n",
      "50             0.861448  0.010593  0.000594  0.000037      0.865805  0.009975   \n",
      "51             0.453333  0.069679  0.031050  0.002866      0.441489  0.063970   \n",
      "52             0.433333  0.069716  0.032418  0.002894      0.411702  0.075706   \n",
      "53             0.403333  0.060440  0.032099  0.003137      0.415957  0.090920   \n",
      "54             0.455556  0.068208  0.029685  0.001915      0.451064  0.061974   \n",
      "55             0.445556  0.070078  0.029980  0.001494      0.442553  0.051473   \n",
      "56             0.427778  0.063215  0.030856  0.001667      0.412766  0.067424   \n",
      "57             0.647778  0.060440  0.022489  0.002369      0.644681  0.046870   \n",
      "58             0.573333  0.070125  0.023985  0.002710      0.596809  0.053682   \n",
      "59             0.617778  0.075135  0.022474  0.003097      0.636170  0.050680   \n",
      "60             0.591244  0.014733  0.003087  0.000048      0.592694  0.027261   \n",
      "61             0.591244  0.014733  0.003091  0.000045      0.592694  0.027261   \n",
      "62             0.591244  0.014733  0.003093  0.000046      0.592694  0.027261   \n",
      "63             0.606912  0.072342  0.003026  0.000328      0.607763  0.067742   \n",
      "64             0.591244  0.014733  0.003065  0.000052      0.592237  0.026916   \n",
      "65             0.591244  0.014733  0.003091  0.000045      0.592694  0.027261   \n",
      "66             0.598618  0.018366  0.003097  0.000041      0.592694  0.027261   \n",
      "67             0.599770  0.018510  0.003096  0.000041      0.592694  0.027261   \n",
      "68             0.601382  0.019807  0.003101  0.000038      0.592694  0.027261   \n",
      "69             0.579153  0.024136  0.002203  0.000021      0.581877  0.017620   \n",
      "70             0.577687  0.022648  0.002205  0.000022      0.581877  0.017620   \n",
      "71             0.577687  0.022648  0.002205  0.000024      0.581877  0.017620   \n",
      "72             0.589739  0.058216  0.002164  0.000154      0.593042  0.053093   \n",
      "73             0.577687  0.022648  0.002202  0.000018      0.581877  0.017620   \n",
      "74             0.577687  0.022648  0.002202  0.000017      0.581877  0.017620   \n",
      "75             0.595114  0.022070  0.002204  0.000023      0.581877  0.017620   \n",
      "76             0.584365  0.019034  0.002203  0.000021      0.581877  0.017620   \n",
      "77             0.588111  0.020856  0.002203  0.000023      0.581877  0.017620   \n",
      "78             0.944691  0.006466  0.000102  0.000010      0.944929  0.005145   \n",
      "79             0.928347  0.007466  0.000136  0.000016      0.926372  0.007403   \n",
      "80             0.932270  0.006332  0.000123  0.000012      0.932593  0.006301   \n",
      "81             0.943305  0.005988  0.000122  0.000023      0.935677  0.015023   \n",
      "82             0.918776  0.007434  0.000146  0.000021      0.912859  0.018978   \n",
      "83             0.925968  0.006518  0.000131  0.000012      0.924124  0.008212   \n",
      "84             0.953373  0.005947  0.000090  0.000009      0.953241  0.006095   \n",
      "85             0.950026  0.006093  0.000093  0.000008      0.951359  0.005644   \n",
      "86             0.950915  0.006072  0.000092  0.000007      0.951307  0.004378   \n",
      "87             0.859485  0.004211  0.000072  0.000002      0.868783  0.004511   \n",
      "88             0.833323  0.004054  0.000087  0.000002      0.834615  0.004930   \n",
      "89             0.842950  0.005368  0.000082  0.000003      0.843306  0.005059   \n",
      "90             0.870521  0.004201  0.000071  0.000002      0.871562  0.003528   \n",
      "91             0.837756  0.003599  0.000085  0.000002      0.837789  0.004179   \n",
      "92             0.846693  0.005390  0.000081  0.000002      0.846917  0.003824   \n",
      "93             0.872479  0.003983  0.000068  0.000002      0.873215  0.003412   \n",
      "94             0.872479  0.004752  0.000068  0.000002      0.874016  0.003628   \n",
      "95             0.875604  0.004906  0.000067  0.000002      0.875680  0.003574   \n",
      "96             0.419429  0.026114  0.007369  0.000187      0.431143  0.029749   \n",
      "97             0.419429  0.026114  0.007368  0.000186      0.431143  0.029749   \n",
      "98             0.419429  0.026114  0.007373  0.000188      0.431143  0.029749   \n",
      "99             0.895429  0.125811  0.002377  0.001275      0.893429  0.118353   \n",
      "100            0.539143  0.048284  0.005698  0.000452      0.547429  0.044053   \n",
      "101            0.586571  0.086110  0.004842  0.001163      0.587714  0.079012   \n",
      "102            0.423714  0.027012  0.007393  0.000209      0.431143  0.029749   \n",
      "103            0.420000  0.027902  0.007385  0.000200      0.431143  0.029749   \n",
      "104            0.420286  0.028268  0.007380  0.000193      0.431143  0.029749   \n",
      "105            0.345885  0.030907  0.001172  0.000013      0.340661  0.029650   \n",
      "106            0.393615  0.017980  0.001123  0.000017      0.391045  0.014258   \n",
      "107            0.414846  0.036892  0.001147  0.000020      0.400692  0.030464   \n",
      "108            0.432846  0.021921  0.001131  0.000018      0.422982  0.019774   \n",
      "109            0.451615  0.013104  0.001008  0.000015      0.454112  0.011946   \n",
      "110            0.421462  0.013307  0.001033  0.000014      0.428978  0.009944   \n",
      "111            0.414500  0.014407  0.001045  0.000013      0.419254  0.010165   \n",
      "112            0.563333  0.071474  0.027435  0.004646      0.567021  0.064489   \n",
      "113            0.550000  0.059835  0.026583  0.002822      0.562766  0.058360   \n",
      "114            0.568889  0.049112  0.026434  0.003665      0.568085  0.062548   \n",
      "115            0.534444  0.058340  0.027367  0.002715      0.545745  0.071163   \n",
      "116            0.544444  0.068208  0.026162  0.002723      0.569149  0.082512   \n",
      "117            0.564444  0.061347  0.025565  0.002591      0.570213  0.060416   \n",
      "118            0.786667  0.065049  0.014235  0.004009      0.797872  0.061935   \n",
      "119            0.707778  0.056896  0.016811  0.003833      0.728723  0.074308   \n",
      "120            0.738889  0.060698  0.017377  0.005175      0.725532  0.065087   \n",
      "121            0.836308  0.007931  0.000198  0.000010      0.838243  0.007571   \n",
      "122            0.795385  0.009283  0.000253  0.000065      0.783886  0.041599   \n",
      "123            0.812855  0.008850  0.000248  0.000119      0.784655  0.109070   \n",
      "124            0.844769  0.006568  0.000165  0.000007      0.846326  0.007589   \n",
      "125            0.836103  0.006117  0.000175  0.000007      0.837406  0.007020   \n",
      "126            0.838376  0.007185  0.000171  0.000007      0.840123  0.007929   \n",
      "127            0.511290  0.069836  0.020714  0.001967      0.494531  0.055365   \n",
      "128            0.515323  0.053231  0.020667  0.001819      0.489063  0.052951   \n",
      "129            0.523387  0.063978  0.020685  0.001958      0.510156  0.049222   \n",
      "130            0.525000  0.069121  0.020562  0.001929      0.514062  0.048066   \n",
      "131            0.536290  0.054602  0.019214  0.001411      0.544531  0.057191   \n",
      "132            0.515323  0.058148  0.019975  0.001624      0.510938  0.040269   \n",
      "133            0.745968  0.057533  0.012183  0.001604      0.728906  0.046261   \n",
      "134            0.769355  0.062160  0.011198  0.001997      0.753906  0.049638   \n",
      "135            0.766935  0.075011  0.011837  0.001535      0.753125  0.043194   \n",
      "\n",
      "    training_runtime           total_runtime            \n",
      "                mean       std          mean       std  \n",
      "0           3.151822  0.240408      4.321206  0.251392  \n",
      "1           5.385641  0.890277     11.981719  0.848074  \n",
      "2           5.243362  1.007800     11.624444  1.029498  \n",
      "3           1.350616  0.143332      2.482460  0.137310  \n",
      "4           1.480324  0.256949      8.035434  0.324424  \n",
      "5           1.382699  0.208171      7.724278  0.219859  \n",
      "6           1.960333  0.747015      3.083571  0.746543  \n",
      "7           1.537748  0.332874      8.138431  0.346100  \n",
      "8           2.141525  0.888786      8.523535  0.839659  \n",
      "9           4.309899  0.377209      6.043407  0.386248  \n",
      "10          6.401862  1.277139      9.768516  1.284004  \n",
      "11          6.621779  1.202863     10.129988  1.208865  \n",
      "12          1.230153  0.213381      2.896440  0.196989  \n",
      "13          1.576656  0.209556      4.878498  0.210431  \n",
      "14          1.638543  0.221488      5.068327  0.217344  \n",
      "15          2.023497  0.982049      3.696476  0.998078  \n",
      "16          1.471516  0.264128      4.741702  0.267394  \n",
      "17          1.751354  0.683322      5.173689  0.671608  \n",
      "18          9.677806  0.673380     10.084446  0.692133  \n",
      "19         10.244775  1.083607     11.963057  1.127947  \n",
      "20         10.145054  0.717669     11.835648  0.760426  \n",
      "21          2.005745  0.100062      2.291522  0.124872  \n",
      "22          1.951307  0.094119      3.566491  0.148543  \n",
      "23          1.942619  0.082064      3.518285  0.127444  \n",
      "24          3.500894  0.999750      3.805199  1.012736  \n",
      "25          2.639231  0.246367      4.283849  0.283824  \n",
      "26          2.677304  0.183892      4.266167  0.212528  \n",
      "27          2.207455  1.229578      2.361657  1.246497  \n",
      "28          3.059753  0.983496      3.573149  1.011675  \n",
      "29          2.951278  0.864126      3.385674  0.884169  \n",
      "30          0.859410  0.068553      0.998115  0.092620  \n",
      "31          0.893146  0.069650      1.383674  0.116043  \n",
      "32          0.873010  0.095711      1.302283  0.150956  \n",
      "33          1.014938  0.888201      1.158828  0.911726  \n",
      "34          0.616799  0.287611      1.106114  0.304877  \n",
      "35          0.564202  0.214856      0.985965  0.256757  \n",
      "36          5.880964  1.337243     15.305738  1.336448  \n",
      "37          7.295299  1.927182     47.865632  2.105499  \n",
      "38          7.052139  1.527207     47.752905  1.635885  \n",
      "39          4.023474  0.472785     13.498775  0.492801  \n",
      "40          5.079876  0.869857     45.637827  1.012674  \n",
      "41          4.807577  0.755757     45.716177  0.864069  \n",
      "42          5.498111  1.334787      5.829510  1.347020  \n",
      "43          4.331821  0.206845      5.505422  0.227756  \n",
      "44          4.339260  0.281254      5.435983  0.298584  \n",
      "45          1.509962  0.127369      1.790012  0.165670  \n",
      "46          1.509085  0.080337      2.635510  0.099879  \n",
      "47          1.531556  0.075316      2.598564  0.087680  \n",
      "48          1.596468  0.224207      1.877601  0.243127  \n",
      "49          1.544126  0.156001      2.668313  0.171704  \n",
      "50          1.547031  0.345531      2.586653  0.349231  \n",
      "51          0.854121  0.346257      0.968891  0.356847  \n",
      "52          0.539319  0.167494      0.668435  0.184551  \n",
      "53          0.545440  0.114288      0.673086  0.139453  \n",
      "54          0.296850  0.069300      0.356188  0.091804  \n",
      "55          0.323700  0.080713      0.406535  0.101933  \n",
      "56          0.331892  0.073204      0.411319  0.098163  \n",
      "57          0.425500  0.072427      0.489385  0.093963  \n",
      "58          0.433718  0.084816      0.520313  0.099262  \n",
      "59          0.485662  0.166216      0.572326  0.187287  \n",
      "60          0.754893  0.429185      0.809339  0.429909  \n",
      "61          0.461150  0.133020      0.625472  0.130954  \n",
      "62          0.391327  0.100391      0.537099  0.123498  \n",
      "63          0.422933  0.483947      0.466155  0.488267  \n",
      "64          0.557565  0.475443      0.714910  0.484808  \n",
      "65          0.310391  0.124361      0.449519  0.146285  \n",
      "66          0.242394  0.088027      0.285183  0.107709  \n",
      "67          0.266109  0.131802      0.423473  0.175818  \n",
      "68          0.227838  0.084366      0.366172  0.102421  \n",
      "69          0.968803  0.512191      1.056856  0.532519  \n",
      "70          0.658402  0.425594      0.909947  0.422146  \n",
      "71          0.984415  0.694457      1.221669  0.708906  \n",
      "72          0.506267  0.793722      0.583277  0.793543  \n",
      "73          0.308761  0.122182      0.559831  0.152866  \n",
      "74          0.280195  0.099279      0.504596  0.124502  \n",
      "75          0.303429  0.125417      0.379308  0.140756  \n",
      "76          0.316690  0.101122      0.564470  0.128942  \n",
      "77          0.267932  0.086957      0.491308  0.108111  \n",
      "78         12.208756  1.296297     16.692272  1.319658  \n",
      "79         14.822791  0.884858     29.596584  0.936447  \n",
      "80         16.955673  2.497957     31.839952  2.529009  \n",
      "81          3.415783  0.695687      7.876544  0.711666  \n",
      "82          3.527019  0.721508     18.454461  0.744428  \n",
      "83          3.659035  0.743892     18.469734  0.749720  \n",
      "84          2.205651  0.462523      6.646646  0.444237  \n",
      "85          2.598038  0.457706     17.772061  0.476578  \n",
      "86          2.537161  0.442136     17.374944  0.602993  \n",
      "87         19.001903  2.683173     21.416110  2.648039  \n",
      "88         19.883983  4.034473     49.169409  4.243653  \n",
      "89         18.091831  4.363584     46.709645  4.866524  \n",
      "90          6.445033  0.553461      8.791729  0.545610  \n",
      "91          6.573742  0.693301     35.752524  0.903361  \n",
      "92          6.022368  0.636508     34.476832  1.215429  \n",
      "93          4.577775  0.474052      6.917756  0.497125  \n",
      "94          4.680593  0.207820     33.826058  0.742298  \n",
      "95          4.675500  0.271569     33.174644  0.780880  \n",
      "96          0.446951  0.113573      0.518861  0.132115  \n",
      "97          1.157451  0.803756      1.383936  0.817492  \n",
      "98          0.953026  0.646141      1.145795  0.675577  \n",
      "99          2.809193  0.692870      2.878058  0.709228  \n",
      "100         2.323811  0.610478      2.538542  0.619598  \n",
      "101         1.960134  0.902855      2.138488  0.896775  \n",
      "102         0.314583  0.254323      0.382507  0.275240  \n",
      "103         0.304170  0.224227      0.518190  0.258949  \n",
      "104         0.242470  0.109795      0.422235  0.131417  \n",
      "105        10.858690  1.389222     25.682767  1.398700  \n",
      "106         2.073165  0.227095      9.792069  0.218169  \n",
      "107         3.233670  0.864338     18.368198  0.974243  \n",
      "108         3.462593  0.660432     18.536416  0.881578  \n",
      "109         2.505627  0.548970     10.345016  0.571345  \n",
      "110         2.375969  0.313548     17.272846  0.647243  \n",
      "111         2.351864  0.290896     17.217801  0.634557  \n",
      "112         0.699851  0.185337      0.806551  0.197371  \n",
      "113         1.066641  0.507188      1.207838  0.535738  \n",
      "114         1.143465  0.441459      1.281996  0.463186  \n",
      "115         0.327477  0.061456      0.386333  0.083283  \n",
      "116         0.341393  0.062489      0.422296  0.086761  \n",
      "117         0.351577  0.085559      0.431627  0.117778  \n",
      "118         0.544823  0.131235      0.610756  0.143909  \n",
      "119         0.508341  0.074481      0.595542  0.097800  \n",
      "120         0.537485  0.122030      0.621501  0.134666  \n",
      "121         7.619172  1.390885     15.649862  1.434405  \n",
      "122         9.127014  1.287058     41.765481  1.367807  \n",
      "123        10.302437  1.645457     45.120475  1.741186  \n",
      "124         4.073663  0.885976     12.213618  0.932692  \n",
      "125         3.908502  0.389727     36.357840  0.547124  \n",
      "126         4.377665  0.381420     38.616742  0.591917  \n",
      "127         0.659984  0.132599      0.779637  0.143071  \n",
      "128         1.095886  0.496054      1.258417  0.513677  \n",
      "129         1.120942  0.404603      1.280210  0.410875  \n",
      "130         0.291088  0.050981      0.365678  0.077219  \n",
      "131         0.323452  0.066323      0.425384  0.093042  \n",
      "132         0.303002  0.055232      0.401989  0.081170  \n",
      "133         0.438337  0.074271      0.519647  0.093402  \n",
      "134         0.488703  0.077605      0.595681  0.106922  \n",
      "135         0.464225  0.075779      0.568437  0.101406  \n",
      "\n",
      "[136 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"p1_30supernodes_unmerged_fixed\"\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        # if dataset+\"_gps.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_gps_mas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps_mas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS-MAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_gps_tas.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps_tas.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS-TAS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gcn.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gcn_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gcn_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gcn_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gat_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gat_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_sage.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_sage.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphSAGE\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_sage_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_sage_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphSAGE-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_sage_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_sage_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphSAGE-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results_exp'+str(exp)+'_unweighted_fixed.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name method trial best_epoch      train_loss            \\\n",
      "                       count        min  max       mean       std   \n",
      "0         actor    NAG    20          6    8   0.000763  0.000014   \n",
      "1         actor    VCR    20          7   55   0.000731  0.000034   \n",
      "2     chameleon    NAG    20         11   12   0.000903  0.000037   \n",
      "3     chameleon    VCR    20         10   13   0.000835  0.000075   \n",
      "4      citeseer    NAG    20         13   15   0.000352  0.000017   \n",
      "5      citeseer    VCR    20         13   16   0.000248  0.000015   \n",
      "6     community    NAG    20         22   31   0.001196  0.000084   \n",
      "7     community    VCR    20         15   30   0.001621  0.000163   \n",
      "8      computer    NAG    20         12   24   0.000151  0.000023   \n",
      "9      computer    VCR    20         11   23   0.000117  0.000026   \n",
      "10         cora    NAG    20         17   23   0.000173  0.000039   \n",
      "11         cora    VCR    20         16   20   0.000200  0.000018   \n",
      "12      cornell    NAG    20         10   19   0.005009  0.002177   \n",
      "13      cornell    VCR    20         12   18   0.005195  0.001641   \n",
      "14        cycle    NAG    20         21   79   0.000214  0.000093   \n",
      "15        cycle    VCR    20         34  133   0.001275  0.000205   \n",
      "16         grid    NAG    20         34   93   0.000819  0.000065   \n",
      "17         grid    VCR    20         15  130   0.001031  0.000060   \n",
      "18        photo    NAG    20         16   24   0.000060  0.000016   \n",
      "19        photo    VCR    20         15   26   0.000071  0.000023   \n",
      "20       pubmed    NAG    20          6    9   0.000145  0.000011   \n",
      "21       pubmed    VCR    20          9  187   0.000119  0.000015   \n",
      "22        shape    NAG    20         33  106   0.002414  0.000201   \n",
      "23        shape    VCR    20         17  142   0.002993  0.000510   \n",
      "24     squirrel    NAG    20          5    7   0.001043  0.000031   \n",
      "25     squirrel    VCR    20          6    9   0.000969  0.000058   \n",
      "26        texas    NAG    20          8   17   0.007101  0.002068   \n",
      "27        texas    VCR    20         12   17   0.005602  0.001613   \n",
      "28         wiki    NAG    20         16   28   0.000209  0.000022   \n",
      "29         wiki    VCR    20         16   31   0.000207  0.000034   \n",
      "30    wisconsin    NAG    20         12   20   0.002884  0.001184   \n",
      "31    wisconsin    VCR    20         13   19   0.003325  0.000974   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.376276  0.017487        0.000799  ...            0.310526   \n",
      "1        0.402895  0.025159        0.000783  ...            0.330579   \n",
      "2        0.667223  0.021386        0.002361  ...            0.420562   \n",
      "3        0.675000  0.034077        0.002241  ...            0.468717   \n",
      "4        0.814221  0.007887        0.000948  ...            0.748135   \n",
      "5        0.874684  0.007466        0.000644  ...            0.842118   \n",
      "6        0.654286  0.023542        0.003202  ...            0.509714   \n",
      "7        0.525071  0.061614        0.003748  ...            0.438857   \n",
      "8        0.912616  0.014183        0.000209  ...            0.884351   \n",
      "9        0.934177  0.014690        0.000185  ...            0.904159   \n",
      "10       0.929727  0.014752        0.000632  ...            0.870975   \n",
      "11       0.919978  0.006480        0.000588  ...            0.874594   \n",
      "12       0.902747  0.074725        0.023689  ...            0.605556   \n",
      "13       0.898352  0.051404        0.024414  ...            0.576667   \n",
      "14       0.969425  0.022648        0.000334  ...            0.980876   \n",
      "15       0.664368  0.085730        0.002392  ...            0.698848   \n",
      "16       0.769593  0.036106        0.001536  ...            0.799511   \n",
      "17       0.656341  0.056721        0.002016  ...            0.679479   \n",
      "18       0.966418  0.010524        0.000111  ...            0.943201   \n",
      "19       0.959752  0.013864        0.000110  ...            0.943044   \n",
      "20       0.892154  0.009580        0.000207  ...            0.875350   \n",
      "21       0.915145  0.013496        0.000209  ...            0.878444   \n",
      "22       0.602857  0.038456        0.004452  ...            0.620286   \n",
      "23       0.505143  0.092227        0.005631  ...            0.537429   \n",
      "24       0.471750  0.021959        0.001152  ...            0.327385   \n",
      "25       0.519519  0.023092        0.001129  ...            0.355538   \n",
      "26       0.769231  0.087186        0.023095  ...            0.608889   \n",
      "27       0.865385  0.072795        0.020120  ...            0.675556   \n",
      "28       0.866846  0.014998        0.000373  ...            0.830171   \n",
      "29       0.868009  0.021752        0.000358  ...            0.837436   \n",
      "30       0.919200  0.046568        0.013408  ...            0.704839   \n",
      "31       0.904000  0.051258        0.013006  ...            0.722581   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.009851  0.000800  0.000006      0.316289  0.013191         5.387661   \n",
      "1   0.011812  0.000784  0.000009      0.331526  0.013033       419.633916   \n",
      "2   0.019421  0.002340  0.000056      0.428421  0.019097         1.949322   \n",
      "3   0.015648  0.002240  0.000057      0.472982  0.016412         3.790858   \n",
      "4   0.015337  0.000938  0.000043      0.749700  0.011564         1.607382   \n",
      "5   0.011704  0.001149  0.000056      0.721429  0.014105         3.506098   \n",
      "6   0.026985  0.003209  0.000110      0.500571  0.022026         2.122260   \n",
      "7   0.041470  0.003946  0.000181      0.427571  0.022862         3.838826   \n",
      "8   0.007998  0.000211  0.000015      0.883464  0.008950        11.576628   \n",
      "9   0.007733  0.000222  0.000080      0.889165  0.028476        12.172420   \n",
      "10  0.011272  0.000615  0.000058      0.871196  0.009735         1.310560   \n",
      "11  0.011777  0.000691  0.000054      0.858863  0.011346         2.741366   \n",
      "12  0.078939  0.024462  0.004370      0.603191  0.055772         1.248723   \n",
      "13  0.085148  0.024232  0.003636      0.563830  0.060770         1.414250   \n",
      "14  0.007808  0.000423  0.000159      0.975114  0.011034         2.548507   \n",
      "15  0.093732  0.002384  0.000397      0.684703  0.099253         4.587922   \n",
      "16  0.023141  0.001580  0.000106      0.790615  0.024916         2.402545   \n",
      "17  0.047149  0.002024  0.000131      0.670388  0.040533         5.703862   \n",
      "18  0.007232  0.000112  0.000012      0.942812  0.006552         6.872098   \n",
      "19  0.007741  0.000114  0.000015      0.942159  0.005834         7.722406   \n",
      "20  0.004840  0.000203  0.000007      0.876562  0.003754        13.707752   \n",
      "21  0.008971  0.000234  0.000013      0.864037  0.010480        24.582985   \n",
      "22  0.054384  0.004501  0.000301      0.616571  0.065806         2.272995   \n",
      "23  0.109187  0.005892  0.000901      0.510571  0.092462         3.001594   \n",
      "24  0.013818  0.001156  0.000015      0.323905  0.012683         4.243566   \n",
      "25  0.021195  0.001130  0.000018      0.353574  0.022013         4.276346   \n",
      "26  0.064244  0.022385  0.003163      0.627660  0.059981         1.575358   \n",
      "27  0.055098  0.019454  0.002660      0.667021  0.068780         1.690154   \n",
      "28  0.007757  0.000373  0.000019      0.830998  0.008146        10.326645   \n",
      "29  0.010915  0.000391  0.000054      0.827051  0.014967        11.124089   \n",
      "30  0.062380  0.014299  0.002256      0.665625  0.046848         1.596878   \n",
      "31  0.044894  0.013250  0.001361      0.710156  0.037758         2.165337   \n",
      "\n",
      "                total_runtime               \n",
      "            std          mean          std  \n",
      "0      0.199222      7.597710     0.288494  \n",
      "1   1846.141091    589.861845  1830.556591  \n",
      "2      0.320585      3.288498     0.379274  \n",
      "3      1.854273    173.588909   271.706174  \n",
      "4      0.083413      2.478277     0.141468  \n",
      "5      0.064763      6.350007     0.092600  \n",
      "6      0.144040      2.427892     0.168555  \n",
      "7      0.448482      5.474869     0.945093  \n",
      "8      0.820647     20.161626     1.099438  \n",
      "9      0.768966    226.987155   474.990152  \n",
      "10     0.070580      1.729644     0.086104  \n",
      "11     0.090674      4.537735     0.127959  \n",
      "12     0.247751      1.493559     0.279875  \n",
      "13     0.292545      8.321894     1.750383  \n",
      "14     0.326249      2.834959     0.340070  \n",
      "15     1.173534      5.507454     1.264707  \n",
      "16     0.347196      2.683241     0.375767  \n",
      "17     1.489744      8.814287     8.707507  \n",
      "18     0.451091     10.247845     0.528291  \n",
      "19     0.863380    185.391561   247.225985  \n",
      "20     1.085823     22.262305     1.209493  \n",
      "21    11.947871    623.362194   350.798489  \n",
      "22     0.458763      2.542705     0.471929  \n",
      "23     1.052617      3.981433     1.151549  \n",
      "24     0.247840      8.519116     0.414734  \n",
      "25     0.103709     38.292943    17.983239  \n",
      "26     0.072016      1.857669     0.115933  \n",
      "27     0.265117      8.383670     1.119010  \n",
      "28     0.906685     16.567856     1.041876  \n",
      "29     0.837332     57.021806    43.969448  \n",
      "30     0.095114      1.888826     0.115792  \n",
      "31     0.210149     10.047954     4.543134  \n",
      "\n",
      "[32 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"p1_30supernodes\"\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        # if dataset+\"_san.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_san.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag5 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"SAN\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_exphormer.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_exphormer.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"Exphormer\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        # if dataset+\"_gps.pkl\" in all_files:\n",
    "        #     res = directory_path+\"/\"+dataset+\"_gps.pkl\"\n",
    "        #     with open(res, 'rb') as f:\n",
    "        #         res = pickle.load(f)\n",
    "        #     flag6 = True\n",
    "        #     dataset_name.append(dataset)\n",
    "        #     trial.append(i)\n",
    "        #     method.append(\"GraphGPS\")\n",
    "        #     epoch = res[\"best_epoch\"]\n",
    "        #     best_epoch.append(epoch)\n",
    "        #     train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "        #     train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "        #     validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "        #     validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "        #     test_loss.append(res[\"test_loss\"])\n",
    "        #     test_accuracy.append(res[\"test_accuracy\"])\n",
    "        #     training_runtime.append(res[\"training_runtime\"])\n",
    "        #     total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_nag.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_nag.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_vcr.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_vcr.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"VCR\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results_exp'+str(exp)+'_unweighted1.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_name        method trial best_epoch      train_loss            \\\n",
      "                              count        min  max       mean       std   \n",
      "0         actor      GraphGPS    20         18   21   0.000311  0.000005   \n",
      "1         actor  GraphGPS-MAS    20          9   11   0.000240  0.000018   \n",
      "2         actor  GraphGPS-TAS    20          9   10   0.000249  0.000014   \n",
      "3     chameleon      GraphGPS    20         15   18   0.000312  0.000040   \n",
      "4     chameleon  GraphGPS-MAS    20         16   18   0.000308  0.000036   \n",
      "5     chameleon  GraphGPS-TAS    20         16   18   0.000318  0.000038   \n",
      "6      citeseer      GraphGPS    20         22   24   0.000167  0.000027   \n",
      "7      citeseer  GraphGPS-MAS    20         22   24   0.000179  0.000032   \n",
      "8      citeseer  GraphGPS-TAS    20         22   25   0.000170  0.000033   \n",
      "9     community      GraphGPS    20         17   27   0.001805  0.000039   \n",
      "10    community  GraphGPS-MAS    20         18   27   0.001767  0.000036   \n",
      "11    community  GraphGPS-TAS    20         18   27   0.001812  0.000030   \n",
      "12     computer      GraphGPS    20         53  126   0.000025  0.000003   \n",
      "13     computer  GraphGPS-MAS    20         51   85   0.000027  0.000003   \n",
      "14     computer  GraphGPS-TAS    20         54   81   0.000027  0.000003   \n",
      "15         cora      GraphGPS    20         33   38   0.000048  0.000010   \n",
      "16         cora  GraphGPS-MAS    20         33   38   0.000059  0.000013   \n",
      "17         cora  GraphGPS-TAS    20         33   40   0.000046  0.000015   \n",
      "18      cornell      GraphGPS    20         12   25   0.000909  0.000536   \n",
      "19      cornell  GraphGPS-MAS    20         13   28   0.000838  0.000556   \n",
      "20      cornell  GraphGPS-TAS    20         13   26   0.001061  0.000444   \n",
      "21        cycle      GraphGPS    20         40  155   0.001528  0.000051   \n",
      "22        cycle  GraphGPS-MAS    20         14  183   0.001548  0.000021   \n",
      "23        cycle  GraphGPS-TAS    20          4  109   0.001575  0.000016   \n",
      "24         grid      GraphGPS    20         38  199   0.001088  0.000015   \n",
      "25         grid  GraphGPS-MAS    20         38  161   0.001102  0.000007   \n",
      "26         grid  GraphGPS-TAS    20         38  140   0.001101  0.000009   \n",
      "27        photo      GraphGPS    20         35   57   0.000026  0.000006   \n",
      "28        photo  GraphGPS-MAS    20         35   56   0.000027  0.000006   \n",
      "29        photo  GraphGPS-TAS    20         35   87   0.000026  0.000007   \n",
      "30        shape      GraphGPS    20         52  148   0.002551  0.000237   \n",
      "31        shape  GraphGPS-MAS    20         43  105   0.003418  0.000162   \n",
      "32        shape  GraphGPS-TAS    20         53  117   0.003407  0.000135   \n",
      "33     squirrel      GraphGPS    20         13   16   0.000383  0.000018   \n",
      "34     squirrel  GraphGPS-MAS    20         13   15   0.000389  0.000016   \n",
      "35     squirrel  GraphGPS-TAS    20         10   15   0.000398  0.000027   \n",
      "36        texas      GraphGPS    20         15   53   0.000660  0.000545   \n",
      "37        texas  GraphGPS-MAS    20         15   37   0.000654  0.000677   \n",
      "38        texas  GraphGPS-TAS    20         16   41   0.000648  0.000505   \n",
      "39         wiki      GraphGPS    20         62  114   0.000064  0.000005   \n",
      "40         wiki  GraphGPS-MAS    20         58   94   0.000066  0.000007   \n",
      "41         wiki  GraphGPS-TAS    20         62   88   0.000066  0.000006   \n",
      "42    wisconsin      GraphGPS    20         14  143   0.000457  0.000446   \n",
      "43    wisconsin  GraphGPS-MAS    20         12   41   0.000360  0.000396   \n",
      "44    wisconsin  GraphGPS-TAS    20         14   34   0.000387  0.000345   \n",
      "\n",
      "   train_accuracy           validation_loss  ... validation_accuracy  \\\n",
      "             mean       std            mean  ...                mean   \n",
      "0        0.521947  0.011252        0.000759  ...            0.350816   \n",
      "1        0.790224  0.044984        0.000788  ...            0.330289   \n",
      "2        0.773026  0.035582        0.000790  ...            0.326763   \n",
      "3        0.920694  0.011799        0.001937  ...            0.556063   \n",
      "4        0.916960  0.012224        0.001925  ...            0.558875   \n",
      "5        0.915026  0.010842        0.001967  ...            0.546485   \n",
      "6        0.916627  0.009488        0.000913  ...            0.750000   \n",
      "7        0.910553  0.009743        0.000946  ...            0.733935   \n",
      "8        0.914913  0.010987        0.000923  ...            0.745969   \n",
      "9        0.443000  0.021640        0.003841  ...            0.407714   \n",
      "10       0.475571  0.019516        0.003818  ...            0.422286   \n",
      "11       0.437500  0.020440        0.003854  ...            0.400429   \n",
      "12       0.945826  0.007347        0.000093  ...            0.898924   \n",
      "13       0.942190  0.007123        0.000094  ...            0.897978   \n",
      "14       0.940685  0.007731        0.000093  ...            0.898255   \n",
      "15       0.985709  0.005257        0.000728  ...            0.838257   \n",
      "16       0.980096  0.006847        0.000753  ...            0.833456   \n",
      "17       0.985709  0.007174        0.000704  ...            0.843648   \n",
      "18       0.987363  0.011972        0.019031  ...            0.721111   \n",
      "19       0.991209  0.010456        0.019587  ...            0.704444   \n",
      "20       0.990659  0.010858        0.019425  ...            0.712222   \n",
      "21       0.562644  0.028124        0.003000  ...            0.583180   \n",
      "22       0.577241  0.017137        0.003041  ...            0.593779   \n",
      "23       0.573448  0.017097        0.003076  ...            0.597696   \n",
      "24       0.618293  0.030296        0.002160  ...            0.619218   \n",
      "25       0.587561  0.011525        0.002195  ...            0.581107   \n",
      "26       0.587073  0.009960        0.002193  ...            0.580293   \n",
      "27       0.973137  0.006835        0.000104  ...            0.944927   \n",
      "28       0.971516  0.006980        0.000105  ...            0.945868   \n",
      "29       0.972052  0.008526        0.000104  ...            0.946496   \n",
      "30       0.601429  0.078791        0.005167  ...            0.602000   \n",
      "31       0.427571  0.034787        0.006797  ...            0.427143   \n",
      "32       0.412286  0.035165        0.006923  ...            0.400000   \n",
      "33       0.653923  0.025390        0.001159  ...            0.346500   \n",
      "34       0.646981  0.021518        0.001154  ...            0.349885   \n",
      "35       0.632904  0.039644        0.001159  ...            0.346462   \n",
      "36       0.992308  0.006277        0.011844  ...            0.808889   \n",
      "37       0.993407  0.007479        0.014370  ...            0.764444   \n",
      "38       0.993407  0.008285        0.013950  ...            0.774444   \n",
      "39       0.873726  0.008639        0.000185  ...            0.827487   \n",
      "40       0.871556  0.013064        0.000187  ...            0.826034   \n",
      "41       0.869966  0.012194        0.000187  ...            0.824547   \n",
      "42       0.991200  0.010350        0.010056  ...            0.808065   \n",
      "43       0.990400  0.013636        0.009166  ...            0.820968   \n",
      "44       0.991200  0.011579        0.009941  ...            0.802419   \n",
      "\n",
      "             test_loss           test_accuracy           training_runtime  \\\n",
      "         std      mean       std          mean       std             mean   \n",
      "0   0.010601  0.000759  0.000009      0.354000  0.010868         4.979768   \n",
      "1   0.008245  0.000791  0.000009      0.328868  0.006989         5.916704   \n",
      "2   0.010657  0.000791  0.000007      0.326553  0.009233         5.918269   \n",
      "3   0.021147  0.001905  0.000069      0.575175  0.021609         1.778060   \n",
      "4   0.019695  0.001894  0.000072      0.572368  0.019733         2.096547   \n",
      "5   0.022925  0.001928  0.000066      0.564386  0.018646         2.135381   \n",
      "6   0.012626  0.000932  0.000049      0.749040  0.014736         2.539984   \n",
      "7   0.015926  0.000965  0.000046      0.737395  0.014676         3.288045   \n",
      "8   0.014227  0.000942  0.000042      0.746699  0.016423         3.235520   \n",
      "9   0.028946  0.003849  0.000073      0.414714  0.020166         1.074533   \n",
      "10  0.017749  0.003848  0.000082      0.430286  0.020360         1.375770   \n",
      "11  0.026517  0.003847  0.000074      0.406000  0.025452         1.263673   \n",
      "12  0.006092  0.000096  0.000005      0.896277  0.006522        21.202679   \n",
      "13  0.004345  0.000098  0.000006      0.894750  0.007353        23.870230   \n",
      "14  0.005433  0.000098  0.000006      0.890663  0.008731        23.704304   \n",
      "15  0.014705  0.000727  0.000053      0.843501  0.011976         1.464852   \n",
      "16  0.014028  0.000749  0.000051      0.838257  0.011918         3.057151   \n",
      "17  0.014387  0.000710  0.000051      0.845199  0.012667         3.064708   \n",
      "18  0.059224  0.018595  0.002662      0.706383  0.038805         0.377564   \n",
      "19  0.061643  0.019065  0.002763      0.700000  0.054311         0.549638   \n",
      "20  0.051728  0.018839  0.002176      0.698936  0.048457         0.618811   \n",
      "21  0.026174  0.003135  0.000173      0.561416  0.060695         0.608218   \n",
      "22  0.017708  0.003080  0.000069      0.567580  0.054756         1.518811   \n",
      "23  0.015033  0.003128  0.000092      0.574429  0.063038         1.154442   \n",
      "24  0.034406  0.002188  0.000036      0.606634  0.043627         0.735102   \n",
      "25  0.023067  0.002203  0.000025      0.581553  0.018219         1.800653   \n",
      "26  0.020878  0.002203  0.000022      0.581877  0.017620         1.928624   \n",
      "27  0.006347  0.000108  0.000011      0.945034  0.005269         5.986592   \n",
      "28  0.005207  0.000112  0.000010      0.942943  0.005760         6.798598   \n",
      "29  0.005807  0.000108  0.000017      0.944642  0.010266         6.517871   \n",
      "30  0.091057  0.007185  0.003125      0.506857  0.138043         0.589655   \n",
      "31  0.036419  0.007146  0.000425      0.428286  0.049033         0.596968   \n",
      "32  0.048629  0.007470  0.000905      0.416571  0.034080         0.576987   \n",
      "33  0.015648  0.001154  0.000019      0.351384  0.012748         2.550861   \n",
      "34  0.014233  0.001148  0.000018      0.355803  0.015811         3.007879   \n",
      "35  0.014636  0.001154  0.000019      0.351653  0.016339         3.028162   \n",
      "36  0.057859  0.012767  0.002897      0.815957  0.061073         0.454868   \n",
      "37  0.056495  0.014994  0.003030      0.776596  0.054573         0.437167   \n",
      "38  0.061294  0.015010  0.002607      0.772340  0.057382         0.456612   \n",
      "39  0.007395  0.000186  0.000008      0.826846  0.007458        20.946630   \n",
      "40  0.007241  0.000189  0.000009      0.824556  0.011095        16.552256   \n",
      "41  0.006697  0.000189  0.000008      0.824829  0.007948        16.779703   \n",
      "42  0.041171  0.011349  0.003905      0.777344  0.046978         0.481287   \n",
      "43  0.055602  0.009984  0.002249      0.800000  0.028043         0.446821   \n",
      "44  0.048493  0.010757  0.002415      0.781250  0.039268         0.455417   \n",
      "\n",
      "              total_runtime             \n",
      "          std          mean        std  \n",
      "0    1.439352      7.095579   1.464399  \n",
      "1    1.282459     12.462665   1.240216  \n",
      "2    1.214849     13.475296   1.320770  \n",
      "3    0.921536      3.611438   0.937130  \n",
      "4    0.930427      5.576713   0.834391  \n",
      "5    0.973972      5.798959   0.858852  \n",
      "6    0.886639      3.059069   0.900944  \n",
      "7    1.032737      5.090882   1.015219  \n",
      "8    1.103630      4.973473   1.087634  \n",
      "9    0.911545      1.304362   0.944660  \n",
      "10   0.711093      1.961553   0.734424  \n",
      "11   0.683696      1.787811   0.696124  \n",
      "12   3.097975     32.539682   3.043057  \n",
      "13  10.988951     63.937154  10.913545  \n",
      "14   9.451531     64.278348   9.295461  \n",
      "15   0.546013      1.891979   0.568229  \n",
      "16   1.088102      4.280394   1.126260  \n",
      "17   1.094697      4.295656   1.068695  \n",
      "18   0.068257      0.460441   0.096801  \n",
      "19   0.463137      0.690625   0.510144  \n",
      "20   0.398619      0.739622   0.421486  \n",
      "21   0.139200      0.730814   0.140317  \n",
      "22   1.282634      1.771481   1.290878  \n",
      "23   0.769465      1.389825   0.801116  \n",
      "24   0.226742      0.883092   0.262744  \n",
      "25   1.123141      2.129743   1.150659  \n",
      "26   1.236995      2.289178   1.242177  \n",
      "27   0.463608     11.135418   0.472832  \n",
      "28   1.814756     21.794828   2.210488  \n",
      "29   1.097238     21.113718   1.150460  \n",
      "30   0.111221      0.698955   0.133959  \n",
      "31   0.342065      0.857308   0.362990  \n",
      "32   0.223168      0.807600   0.230161  \n",
      "33   0.054940     10.746490   0.092199  \n",
      "34   0.795251     17.762650   0.974955  \n",
      "35   0.804550     18.132090   0.961909  \n",
      "36   0.102696      0.539320   0.121334  \n",
      "37   0.074960      0.544977   0.098212  \n",
      "38   0.073056      0.565723   0.095678  \n",
      "39   3.174935     31.218293   3.269364  \n",
      "40   1.325080     48.963168   1.542997  \n",
      "41   1.107629     51.119486   1.276677  \n",
      "42   0.122976      0.591092   0.138675  \n",
      "43   0.091524      0.606998   0.117372  \n",
      "44   0.086126      0.606689   0.110936  \n",
      "\n",
      "[45 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"p1_30supernodes_unmerged_fixed_new\"\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        if dataset+\"_gps.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_mas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_mas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-MAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "        if dataset+\"_gps_tas.pkl\" in all_files:\n",
    "            res = directory_path+\"/\"+dataset+\"_gps_tas.pkl\"\n",
    "            with open(res, 'rb') as f:\n",
    "                res = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GraphGPS-TAS\")\n",
    "            epoch = res[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(res[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(res[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(res[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(res[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(res[\"test_loss\"])\n",
    "            test_accuracy.append(res[\"test_accuracy\"])\n",
    "            training_runtime.append(res[\"training_runtime\"])\n",
    "            total_runtime.append(res[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{\n",
    "        col: ['mean', 'std'] \n",
    "        for col in df.columns \n",
    "        if col not in ['dataset_name', 'method', 'best_epoch', 'trial']\n",
    "    }\n",
    "}).reset_index()\n",
    "\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel('results_exp'+str(exp)+'_unweighted_gps.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
