{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"folder1\"\n",
    "folder = os.getcwd()+\"/\"+folder_name\n",
    "\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "dataset_name = []\n",
    "trial = []\n",
    "method = []\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "validation_loss = []\n",
    "validation_accuracy = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "best_epoch = []\n",
    "training_runtime = []\n",
    "total_runtime = []\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        flag1 = False\n",
    "        flag2 = False\n",
    "        flag3 = False\n",
    "        flag4 = False\n",
    "        flag5 = False\n",
    "        flag6 = False\n",
    "        if dataset+\"_nag.pkl\" in all_files:\n",
    "            nag = directory_path+\"/\"+dataset+\"_nag.pkl\"\n",
    "            with open(nag, 'rb') as f:\n",
    "                nag = pickle.load(f)\n",
    "            flag1 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"NAG\")\n",
    "            epoch = nag[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(nag[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(nag[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(nag[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(nag[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(nag[\"test_loss\"])\n",
    "            test_accuracy.append(nag[\"test_accuracy\"])\n",
    "            training_runtime.append(nag[\"training_runtime\"])\n",
    "            total_runtime.append(nag[\"total_runtime\"])\n",
    "        if dataset+\"_vcr.pkl\" in all_files:\n",
    "            vcr = directory_path+\"/\"+dataset+\"_vcr.pkl\"\n",
    "            with open(vcr, 'rb') as f:\n",
    "                vcr = pickle.load(f)\n",
    "            flag4 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"VCR\")\n",
    "            epoch = vcr[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(vcr[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(vcr[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(vcr[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(vcr[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(vcr[\"test_loss\"])\n",
    "            test_accuracy.append(vcr[\"test_accuracy\"])\n",
    "            training_runtime.append(vcr[\"training_runtime\"])\n",
    "            total_runtime.append(vcr[\"total_runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"folder2\"\n",
    "folder = os.getcwd()+\"/\"+folder_name\n",
    "\n",
    "exp = 1\n",
    "\n",
    "datasets = [\"actor\",\"chameleon\",\"citeseer\",\"community\",\"computer\",\"cora\",\"cornell\",\"cycle\",\"grid\",\"photo\",\"pubmed\",\"shape\",\"squirrel\",\"texas\",\"wiki\",\"wisconsin\"]\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        flag1 = False\n",
    "        flag2 = False\n",
    "        flag3 = False\n",
    "        flag4 = False\n",
    "        flag5 = False\n",
    "        flag6 = False\n",
    "        if dataset+\"_gcn.pkl\" in all_files:\n",
    "            gcn = directory_path+\"/\"+dataset+\"_gcn.pkl\"\n",
    "            with open(gcn, 'rb') as f:\n",
    "                gcn = pickle.load(f)\n",
    "            flag1 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GCN\")\n",
    "            epoch = gcn[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(gcn[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(gcn[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(gcn[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(gcn[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(gcn[\"test_loss\"])\n",
    "            test_accuracy.append(gcn[\"test_accuracy\"])\n",
    "            training_runtime.append(gcn[\"training_runtime\"])\n",
    "            total_runtime.append(gcn[\"total_runtime\"])\n",
    "        if dataset+\"_sage.pkl\" in all_files:\n",
    "            sage = directory_path+\"/\"+dataset+\"_sage.pkl\"\n",
    "            with open(sage, 'rb') as f:\n",
    "                sage = pickle.load(f)\n",
    "            flag2 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"SAGE\")\n",
    "            epoch = sage[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(sage[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(sage[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(sage[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(sage[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(sage[\"test_loss\"])\n",
    "            test_accuracy.append(sage[\"test_accuracy\"])\n",
    "            training_runtime.append(sage[\"training_runtime\"])\n",
    "            total_runtime.append(sage[\"total_runtime\"])\n",
    "        if dataset+\"_gat.pkl\" in all_files:\n",
    "            gat = directory_path+\"/\"+dataset+\"_gat.pkl\"\n",
    "            with open(gat, 'rb') as f:\n",
    "                gat = pickle.load(f)\n",
    "            flag2 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"GAT\")\n",
    "            epoch = gat[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(gat[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(gat[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(gat[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(gat[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(gat[\"test_loss\"])\n",
    "            test_accuracy.append(gat[\"test_accuracy\"])\n",
    "            training_runtime.append(gat[\"training_runtime\"])\n",
    "            total_runtime.append(gat[\"total_runtime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"folder3\"\n",
    "folder = os.getcwd()+\"/\"+folder_name\n",
    "\n",
    "exp = 1\n",
    "\n",
    "folders = [folder+\"/results/exp\"+str(exp)+\"_\"+str(i) for i in range(20)]\n",
    "\n",
    "for i in range(len(folders)):\n",
    "    directory_path = folders[i]\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_files.append(file)\n",
    "    for dataset in datasets:\n",
    "        flag1 = False\n",
    "        flag2 = False\n",
    "        flag3 = False\n",
    "        flag4 = False\n",
    "        flag5 = False\n",
    "        flag6 = False\n",
    "        if dataset+\"_cr_mas.pkl\" in all_files:\n",
    "            cr_mas = directory_path+\"/\"+dataset+\"_cr_mas.pkl\"\n",
    "            with open(cr_mas, 'rb') as f:\n",
    "                cr_mas = pickle.load(f)\n",
    "            flag5 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"CR-MAS\")\n",
    "            epoch = cr_mas[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(cr_mas[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(cr_mas[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(cr_mas[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(cr_mas[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(cr_mas[\"test_loss\"])\n",
    "            test_accuracy.append(cr_mas[\"test_accuracy\"])\n",
    "            training_runtime.append(cr_mas[\"training_runtime\"])\n",
    "            total_runtime.append(cr_mas[\"total_runtime\"])\n",
    "        if dataset+\"_cr_tas.pkl\" in all_files:\n",
    "            cr_tas = directory_path+\"/\"+dataset+\"_cr_tas.pkl\"\n",
    "            with open(cr_tas, 'rb') as f:\n",
    "                cr_tas = pickle.load(f)\n",
    "            flag6 = True\n",
    "            dataset_name.append(dataset)\n",
    "            trial.append(i)\n",
    "            method.append(\"CR-TAS\")\n",
    "            epoch = cr_tas[\"best_epoch\"]\n",
    "            best_epoch.append(epoch)\n",
    "            train_loss.append(cr_tas[\"training_results\"][0][epoch-1])\n",
    "            train_accuracy.append(cr_tas[\"training_results\"][1][epoch-1])\n",
    "            validation_loss.append(cr_tas[\"training_results\"][2][epoch-1])\n",
    "            validation_accuracy.append(cr_tas[\"training_results\"][3][epoch-1])\n",
    "            test_loss.append(cr_tas[\"test_loss\"])\n",
    "            test_accuracy.append(cr_tas[\"test_accuracy\"])\n",
    "            training_runtime.append(cr_tas[\"training_runtime\"])\n",
    "            total_runtime.append(cr_tas[\"total_runtime\"])\n",
    "\n",
    "data = {\n",
    "    \"dataset_name\": dataset_name,\n",
    "    \"trial\": trial,\n",
    "    \"method\": method,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"train_loss\": train_loss,\n",
    "    \"train_accuracy\": train_accuracy,\n",
    "    \"validation_loss\": validation_loss,\n",
    "    \"validation_accuracy\": validation_accuracy,\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_accuracy\": test_accuracy,\n",
    "    \"training_runtime\": training_runtime,\n",
    "    \"total_runtime\": total_runtime\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.groupby(['dataset_name', 'method']).agg({\n",
    "    'trial': ['count'],\n",
    "    'best_epoch': ['min', 'max'],\n",
    "    **{col: 'mean' for col in df.columns if col not in ['dataset_name', 'method', 'best_epoch', 'trial']}\n",
    "}).reset_index()\n",
    "cwd = os.getcwd()\n",
    "split_text = cwd.split('version')\n",
    "df.to_excel(folder+'/results_exp'+str(exp)+'_ver'+split_text[-1]+'_'+folder_name+'.xlsx', index=True)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)\n",
    "\n",
    "df_nag = df[df['method'] == 'NAG']\n",
    "df_vcr = df[df['method'] == 'VCR']\n",
    "df_gcn = df[df['method'] == 'GCN']\n",
    "df_sage = df[df['method'] == 'SAGE']\n",
    "df_gat = df[df['method'] == 'GAT']\n",
    "df_cr_mas = df[df['method'] == 'CR-MAS']\n",
    "df_cr_tas = df[df['method'] == 'CR-TAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in ['test_accuracy']:\n",
    "    plt.scatter(df_nag['dataset_name'], df_nag[res], label=\"NAG\", alpha=0.5)\n",
    "    plt.scatter(df_vcr['dataset_name'], df_vcr[res], label=\"VCR\", alpha=0.5, color='black')\n",
    "    plt.scatter(df_cr_mas['dataset_name'], df_cr_mas[res], label=\"CR-MAS\", alpha=0.5)\n",
    "    plt.scatter(df_cr_tas['dataset_name'], df_cr_tas[res], label=\"CR-TAS\", alpha=0.5)\n",
    "    plt.scatter(df_gcn['dataset_name'], df_gcn[res], label=\"GCN\", alpha=0.5)\n",
    "    plt.scatter(df_sage['dataset_name'], df_sage[res], label=\"SAGE\", alpha=0.5)\n",
    "    plt.scatter(df_gat['dataset_name'], df_gat[res], label=\"GAT\", alpha=0.5)\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel(res)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in ['test_loss']:\n",
    "    plt.scatter(df_nag['dataset_name'], df_nag[res], label=\"NAG\", alpha=0.5)\n",
    "    plt.scatter(df_vcr['dataset_name'], df_vcr[res], label=\"VCR\", alpha=0.5, color='black')\n",
    "    plt.scatter(df_cr_mas['dataset_name'], df_cr_mas[res], label=\"CR-MAS\", alpha=0.5)\n",
    "    plt.scatter(df_cr_tas['dataset_name'], df_cr_tas[res], label=\"CR-TAS\", alpha=0.5)\n",
    "    plt.scatter(df_gcn['dataset_name'], df_gcn[res], label=\"GCN\", alpha=0.5)\n",
    "    plt.scatter(df_sage['dataset_name'], df_sage[res], label=\"SAGE\", alpha=0.5)\n",
    "    plt.scatter(df_gat['dataset_name'], df_gat[res], label=\"GAT\", alpha=0.5)\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel(res)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = [df_nag,df_vcr,df_cr_mas,df_cr_tas,df_gcn,df_sage,df_gat]\n",
    "colors = ['#1f77b4','black','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b','#e377c2']\n",
    "labels = ['NAG','VCR','CR-MAS','CR-TAS','GCN','SAGE','GAT']\n",
    "for data in datasets:\n",
    "    for df,c,l in list(zip(all_dfs,colors,labels)):\n",
    "        df_dump = df\n",
    "        if data in list(df_dump['dataset_name']):\n",
    "            df_dump = df_dump[df_dump['dataset_name']==data]\n",
    "            min_epoch = df_dump[('best_epoch', 'min')].iloc[0]\n",
    "            max_epoch = df_dump[('best_epoch', 'max')].iloc[0]\n",
    "            if data == \"actor\":\n",
    "                plt.plot([data,data], [min_epoch,max_epoch], label=l, alpha=0.5, color=c)\n",
    "            else:\n",
    "                plt.plot([data,data], [min_epoch,max_epoch], alpha=0.5, color=c)\n",
    "            plt.scatter([data,data], [min_epoch,max_epoch], alpha=0.5, color=c)\n",
    "plt.xlabel('Dataset Name')\n",
    "plt.ylabel('Best Epoch (Min-Max)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(bbox_to_anchor=(1.02, 0.5), loc='center left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
